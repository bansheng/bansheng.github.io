<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>AutoMLè‡ªåŠ¨æœºå™¨å­¦ä¹ </title>
    <url>/2020/11/01/01-AutoML/</url>
    <content><![CDATA[<p>wiki definition: AutoML is the process of automating the end-to-end
process of applying appropriate data-preprocessing, feature engineering,
model selection, and model evaluation to solve the certain task</p>
<ul>
<li>Google AutoML</li>
<li><a href="https://arxiv.org/abs/1611.01578">Neural Architecture
Search with Reinforcement Learning</a></li>
</ul>
<p>We will introduce NAS from two perspectives.</p>
<ul>
<li>The first is the structures of the model.
<ul>
<li>entire structure</li>
<li>cell-based structure</li>
<li>hierarchical structure</li>
<li>morphism-based structure</li>
</ul></li>
<li>The second is hyperparameter optimization (HPO) for designing the
model structure.
<ul>
<li>Reinforcement Learning</li>
<li>Evolutionary Algorithms</li>
<li>Gradient-based</li>
<li>Bayesian Optimization</li>
</ul></li>
</ul>
<p>AutoML</p>
<ul>
<li>data preparation</li>
<li>feature engineering</li>
<li>model generation</li>
<li>model evaluation</li>
</ul>
<h2 id="data-preparation">1. Data preparation</h2>
<h3 id="data-collection">1.1 data collection</h3>
<ol type="1">
<li>data synthesis
<ul>
<li>augment the exsiting dataset CV: cropping, flipping, padding,
rotation and resize, etc. Library: torchvision augmentor</li>
<li>data warping generates additional samples by applying transformation
on data-space</li>
<li>synthetic over-sampling creates additional samples in
feature-space.</li>
<li>For text data, synonym insertion is a common way of
augmentingåŒä¹‰è¯æ’å…¥</li>
<li>first translate the text into some foreign language, and then
translate it back to the original language</li>
<li>non-domain-specific data augmentation strategy that uses noising in
RNNs</li>
<li>back-translation</li>
<li>data simulator <strong>OpenAI Gym</strong> is a popular toolkit that
provides various simulation environment</li>
<li>GAN</li>
</ul></li>
<li>data searching(search for web data)
<ul>
<li>On the one hand, sometimes the <strong>search results do not exactly
match the keywords</strong>.(filter unrelated data)</li>
<li>The other problem is that web data may <strong>have wrong labels or
even no labels.</strong>(learning-based <strong>self-labeling</strong>
method, åˆ†ä¸ºself-training, co-training, co-learning)</li>
<li>the distribution of web data can be extremely different from the
target dataset, which would increase the difficulty of training the
model.(fine-tune these web data)</li>
<li>dataset inbalance(SMOTE, combines boosting method with data
generation)</li>
</ul></li>
</ol>
<h3 id="data-cleaning">1.2 data cleaning</h3>
<p>redundant, incomplete, or incorrect data</p>
<p>standardization, scaling, binarization of quantitative
characteristic, one-hot encoding qualitative characteristic, and filling
missing values with mean value, etc.</p>
<h2 id="feature-engneering">2. feature engneering</h2>
<ul>
<li>feature selection å‡å°‘å†—ä½™ç‰¹å¾</li>
<li>extraction å‡å°‘ç‰¹å¾çš„ç»´åº¦</li>
<li>construction å±•å¼€åŸå§‹ç‰¹å¾ç©ºé—´</li>
</ul>
<h3 id="feature-selection">2.1 feature selection</h3>
<p><img src="https://s2.loli.net/2022/02/08/qla6Yzn7WjADF15.png" /></p>
<p>search strategy</p>
<ul>
<li>complete
<ul>
<li>exhaustive</li>
<li>non-exhaustive</li>
</ul></li>
<li>heuristic
<ul>
<li>Sequential Forward Selection(SFS)</li>
<li>Sequential Backward Selection(SBS)</li>
<li>Bidirectional Search(BS)</li>
</ul></li>
<li>random search algorithm
<ul>
<li>Simulated Annealing(SA)</li>
<li>Genetic Algorithms(GA)</li>
</ul></li>
</ul>
<p>subset evaluation</p>
<ul>
<li>filter method scores each feature according to divergence or
correlation, and then select features by a threshold</li>
<li>Wrapper method classifies the sample set with the selected feature
subset, the classification accuracy is used as the criterion to measure
the quality of the feature subset</li>
<li>embedded method performs variable selection as part of the learning
procedure. Regularization, decision tree, <strong>DL</strong></li>
</ul>
<h3 id="feature-construction">2.2 feature construction</h3>
<h4 id="definition">definition</h4>
<p><strong>constructs new features</strong> from the basic feature space
or raw data to help enhance the robustness and generalization of the
model, and its essence is to increase the representative ability of
original features.</p>
<h4 id="å¸¸ç”¨æ–¹æ³•-preprocessing-transformation">å¸¸ç”¨æ–¹æ³• preprocessing
transformation</h4>
<p>åŒ…æ‹¬</p>
<ul>
<li>standardization</li>
<li>normalization</li>
<li>feature discretization</li>
</ul>
<h4 id="è‡ªåŠ¨åŒ–æ£€ç´¢">è‡ªåŠ¨åŒ–æ£€ç´¢</h4>
<p>äººåŠ›å¾ˆéš¾æ£€ç´¢æ‰€æœ‰å¯èƒ½ some automatic feature construction methods have
been proposed</p>
<p>These algorithms mainly aim to automate <strong>the process of
searching and evaluating the operation
combination</strong>å®ç°æ“ä½œç»„åˆæœç´¢å’Œè¯„ä»·çš„è‡ªåŠ¨åŒ–</p>
<p>searching ç®—æ³•</p>
<ul>
<li>decision tree-based methods</li>
<li>genetic algorithm éœ€è¦pre-defined operation space</li>
<li>annotation-based approaches
ä¸éœ€è¦ï¼Œå°†domainçŸ¥è¯†ä»¥æ³¨é‡Šçš„å½¢å¼ä¸è®­ç»ƒç¤ºä¾‹ä¸€èµ·ä½¿ç”¨
å¼•å…¥äº†äº¤äº’å¼ç‰¹å¾ç©ºé—´æ„å»ºåè®®ï¼Œå­¦ä¹ è€…è¯†åˆ«å‡ºç‰¹å¾ç©ºé—´çš„ä¸è¶³åŒºåŸŸï¼Œå¹¶ä¸é¢†åŸŸä¸“å®¶åä½œï¼Œé€šè¿‡ç°æœ‰çš„è¯­ä¹‰èµ„æºå¢åŠ æè¿°æ€§</li>
</ul>
<h3 id="feature-extraction">2.3 feature extraction</h3>
<p>a dimensionality reduction process through some mapping functions</p>
<p>mapping function</p>
<ul>
<li>Principal Component Analysis(PCA)</li>
<li>Independent COmponent Analysis(ICA)</li>
<li>isomap</li>
<li>nonlinear dimensionality reduction</li>
<li>Linear discriminant analysis(LDA)</li>
<li><strong>feed-forward neural networks approach</strong></li>
</ul>
<h2 id="model-generation">3. model generation</h2>
<p>two types of approaches for model selection:</p>
<ul>
<li>traditional model selection
<ul>
<li>SVM</li>
<li>KNN</li>
<li>decision tree</li>
<li>K-means</li>
</ul></li>
<li>NAS</li>
</ul>
<p>ä¸»è¦ä»‹ç»NAS</p>
<h3 id="model-structures">3.1 model structures</h3>
<p>The model is generated by selecting and combining a set of primitive
operations, which are pre-defined in the search space. The operations
can be broadly divided into convolution, pooling, concatenation,
elemental addition, skip connection, etc.</p>
<ol type="1">
<li><p>entire structure
ç¼ºç‚¹ï¼šå¤ªæ·±ï¼Œæœç´¢ç©ºé—´å¤ªå¤§ï¼Œæ¶ˆè€—æ—¶é—´å’Œè®¡ç®—èµ„æºï¼Œæ‰¾åˆ°çš„modelçš„transferabilityå·®ï¼Œæ„å‘³ç€å°çš„æ•°æ®é›†ä¸Šæ‰¾åˆ°çš„æ¨¡å‹åœ¨å®Œæ•´æ•°æ®é›†ä¸Šè¡¨ç°å¾ˆå·®</p></li>
<li><p>Cell-based structure å…ˆç”Ÿæˆcellï¼Œå†è¿èµ·æ¥ <img
src="https://s2.loli.net/2022/02/08/lXtrU6DbuFhz3pa.png" />
ä¼˜ç‚¹ï¼šæœç´¢ç©ºé—´å¤§å¤§å‡å°ï¼Œå¹¶ä¸”æ›´å®¹æ˜“ä»å°datasetä¸Šè½¬æ¢åˆ°å¤§çš„datasetä¸Š(ç®€å•å åŠ cells))
åˆ†æˆä¸¤çº§ï¼š</p>
<ul>
<li>inner:cell level, selects the operation and connection for each
node</li>
<li>outter level:network level, controls the spatial resolution
changes</li>
</ul></li>
<li><p>Hierarchical structure for a hierarchical structure, there are
many levels, each with a fixed number of cells. The higher-level cell is
generated by incorporating lower-level cell iteratively. <img
src="https://s2.loli.net/2022/02/08/tyW2gcCQA8XVIko.png" />
å¯ä»¥å‘ç°æ›´å¤šå¤æ‚ã€çµæ´»çš„ç½‘ç»œç»“æ„ç±»å‹ã€‚</p></li>
<li><p>Network Morphism based structure transferring the information
stored in an existing neural network into a new neural network
ä»ç°æœ‰ç½‘ç»œåˆ°æ–°ç½‘ç»œ ä¿è¯æ€§èƒ½ä¸ä½äºåŸæœ‰ç½‘ç»œ</p></li>
</ol>
<h3 id="hyperparameter-optimizationhpo">3.2 hyperparameter
optimization(HPO)</h3>
<ol type="1">
<li><p>Grid &amp; Random Search æœ€å¹¿æ³›ä½¿ç”¨çš„ <img
src="https://s2.loli.net/2022/02/08/7QgozVqm4BS6dPe.png" /></p></li>
<li><p>Reinforcement Learning åˆ†ä¸ºä¸¤éƒ¨åˆ†</p>
<ul>
<li>controller:RNN, used to generate different child networks at
different epoch</li>
<li>reward network:trains and evaluates the generated child networks and
uses the reward (e.g. accuracy) to update RNN controller.</li>
<li>ç¼ºç‚¹ï¼šè®­ç»ƒæ—¶é—´é•¿ï¼Œèµ„æºéœ€æ±‚å¤§</li>
<li>ENAS:å­æ¶æ„è¢«çœ‹åšæ˜¯é¢„å®šä¹‰æœç´¢ç©ºé—´çš„å­å›¾ï¼Œå…±äº«å‚æ•°ï¼Œä»è€Œé¿å…ä»é›¶å¼€å§‹åˆ°æ”¶æ•›åœ°è®­ç»ƒæ¯ä¸ªå­æ¨¡å‹</li>
</ul></li>
<li><p>Evolutionary Algorithm é€šç”¨çš„åŸºäºç§ç¾¤çš„å…ƒå¯å‘å¼ä¼˜åŒ–ç®—æ³•ï¼Œ
æœ‰ä¸¤ç§ç±»å‹çš„ç¼–ç æ–¹æ¡ˆ:ç›´æ¥ç¼–ç å’Œé—´æ¥ç¼–ç ã€‚direct, indirect
ç›´æ¥ç¼–ç æ˜¯ä¸€ç§å¹¿æ³›ä½¿ç”¨çš„æ–¹æ³•ï¼Œå®ƒæ˜¾å¼åœ°æŒ‡å®šäº†è¡¨ç°å‹ï¼šGenetic CNN</p>
<ul>
<li>selection é€‰æ‹©
<ul>
<li>fitness selection</li>
<li>rank selection</li>
<li>Tournament selection</li>
</ul></li>
<li>crossover æ‚äº¤</li>
<li>mutation çªå˜</li>
<li>update æ›´æ–°</li>
</ul>
<p><img
src="https://s2.loli.net/2022/02/08/EzichSUZ8lHJVLy.png" /></p></li>
<li><p>Bayesian Optimization</p>
<ul>
<li>BO</li>
<li>Sequential model-based optimization(SMBO)</li>
<li>Bayesian Optimization-based Hyperband (BOHB)</li>
</ul></li>
<li><p>Gradient Descent</p></li>
</ol>
<h2 id="model-estimation">4. model estimation</h2>
<h3 id="low-fidelity">4.1 low fidelity</h3>
<p>On the one hand, we can reduce the number of images or the resolution
of images (for image classification tasks)
åœ¨å­é›†ä¸Šé¢è®­ç»ƒ,åœ¨ä½ç²¾åº¦è®­ç»ƒé›†ä¸Šé¢è®­ç»ƒ On the other hand, low fidelity
model evaluation can be realized by reducing the model size, such as
training with less number of filters per layer
å‡å°‘ç½‘ç»œçš„å¤§å°ï¼Œæ¯”å¦‚æ¯å±‚çš„filterçš„æ•°ç›®</p>
<h3 id="transfer-learning">4.2 Transfer learning</h3>
<ul>
<li>Transfer Neural AutoML uses knowledge from prior tasks to speed up
network design</li>
<li>ENAS shares parameters among child networks</li>
<li>The network morphism based algorithms inherit the weights of
previous architectures</li>
</ul>
<h3 id="surrogateä»£ç†">4.3 Surrogateä»£ç†</h3>
<p>ä¸€èˆ¬æ¥è¯´ï¼Œä¸€æ—¦è·å¾—äº†ä¸€ä¸ªè‰¯å¥½çš„è¿‘ä¼¼ï¼Œå°±å¾ˆå®¹æ˜“æ‰¾åˆ°æœ€ä½³é…ç½®ï¼Œè€Œä¸æ˜¯ç›´æ¥ä¼˜åŒ–åŸæ¥æ˜‚è´µçš„ç›®æ ‡ã€‚
PNAS</p>
<p>this method is not applicable when the optimization space is too
large and hard to quantize, and the evaluation of each configuration is
extremely expensive</p>
<h3 id="early-stopping">4.4 Early stopping</h3>
<p>is now being used to speed up model evaluation by <strong>stopping
the evaluations which predicted to perform poorly on the validation
set</strong></p>
<h2 id="nas-performance-summary">5. NAS PERFORMANCE SUMMARY</h2>
<p><img src="https://s2.loli.net/2022/02/08/EI2y6sAf8vUdchb.png" /></p>
<h2 id="future-work">6. future work</h2>
<ol type="1">
<li>Complete AutoML Pipeline æ•°æ®éƒ¨åˆ†</li>
<li>Interpretability</li>
<li>Reproducibility</li>
<li>Flexible Encoding Scheme</li>
<li>More Area cnn: image classification rnn: language modeling more</li>
<li>Lifelong Learn</li>
</ol>
]]></content>
      <categories>
        <category>Survey</category>
      </categories>
      <tags>
        <tag>AutoML</tag>
      </tags>
  </entry>
  <entry>
    <title>DARTS å¯å¾®åˆ†æ¶æ„æœç´¢</title>
    <url>/2020/11/01/02-DARTS/</url>
    <content><![CDATA[<h2 id="darts">1. DARTS</h2>
<p>the computation procedure for an architecture (or a cell in it) is
represented as a directed acyclic graph. è¡¨ç¤ºä¸ºæœ‰å‘å›¾ã€‚</p>
<h3 id="search-space">1.1 search space</h3>
<p>å¯»æ‰¾ä¸€ä¸ªè®¡ç®—cellï¼Œä½œä¸ºæœ€åæ¶æ„çš„å»ºé€ æ¨¡å—ã€‚å­¦ä¹ å‡ºæ¥çš„cellå¯ä»¥å åŠ èµ·æ¥ç»„æˆcnnï¼Œæˆ–è€…é€’å½’è¿æ¥èµ·æ¥ç»„æˆrnnã€‚</p>
<p>cellæ˜¯ç”±Nä¸ªæœ‰åºåºåˆ—nodeç»„æˆçš„æœ‰å‘æ— ç¯å›¾ã€‚æ¯ä¸€æ¡edgeéƒ½æ˜¯ä¸€ä¸ªè®¡ç®—ã€‚æˆ‘ä»¬å‡è®¾è¿™ä¸ªcellæœ‰ä¸¤ä¸ªinputå’Œä¸€ä¸ªoutputï¼Œå¯¹äºcnnï¼Œå®ƒå°±æ˜¯å‰é¢ä¸¤ä¸ªå±‚çš„è¾“å‡ºï¼Œå¯¹äºrnnï¼Œå®ƒæ˜¯ä¸Šä¸ªstepçš„stateä»¥åŠè¿™ä¸ªstepçš„Inputã€‚cellçš„è¾“å‡ºæ˜¯é€šè¿‡å¯¹æ‰€æœ‰ä¸­é—´èŠ‚ç‚¹åº”ç”¨reductionå¾—åˆ°çš„ã€‚</p>
<p>æ‰€æœ‰ä¸­é—´èŠ‚ç‚¹çš„è®¡ç®—ä¾èµ–å‰ç½®èŠ‚ç‚¹ã€‚ <span class="math display">\[
x^{(j)} = \sum_{i&lt;j}o^{(i,j)}(x^{(i)})
\]</span> æ³¨æ„zero operationä¹Ÿæ˜¯å¯ä»¥è¢«å…è®¸çš„edgeç±»å‹ã€‚</p>
<h3 id="continuous-relaxation-and-optimization">1.2 continuous
relaxation and optimization</h3>
<p>æ‰¾åˆ°æ¯ä¸€ä¸ªæ“ä½œå¯¹åº”çš„æƒé‡çŸ©é˜µ<span
class="math inline">\(\alpha^{(i,j)}\)</span>ï¼Œè¿™æ ·æ‰€æœ‰çš„æƒé‡çŸ©é˜µé›†åˆä¸º<span
class="math inline">\(\alpha\)</span>ï¼Œæˆ‘ä»¬å°†NASçš„ä»»åŠ¡å‡å°ä¸ºå­¦ä¹ ä¸€ä¸ªè¿ç»­å˜é‡çš„é›†åˆ<span
class="math inline">\(\alpha\)</span>ã€‚</p>
<p>DARTSä½¿ç”¨çš„æ˜¯<strong>GD</strong>æ¥ä¼˜åŒ–validation lossã€‚ç›¸ä¼¼çš„æœ‰RL(<a
href="">Learning transferable architectures for scalable image
recognition</a>)ï¼ŒEA(<a href="">Hierarchical representations for
efficient architecture search</a>)</p>
<p>NASçš„ç›®æ ‡æ˜¯æ‰¾åˆ°<span
class="math inline">\(\alpha^*\)</span>ä½¿å¾—validation loss<span
class="math inline">\(L_{val}(w^*, \alpha^*)\)</span>æœ€å°ï¼Œ<span
class="math inline">\(w^*\)</span>æ˜¯ä½¿å¾—training loss<span
class="math inline">\(L_{train}(w, \alpha^*)\)</span>æœ€å°çš„wã€‚ <span
class="math display">\[
min_{\alpha} L_{val}(w^*(\alpha), \alpha) \\
s.t. w^*(\alpha) = argmin_w L_{train}(w, \alpha)
\]</span> <img
src="https://s2.loli.net/2022/02/08/QWc1fC3shg4q2tb.png" /></p>
<h3 id="approximate-architecture-gradient">1.3 approximate architecture
gradient</h3>
<p><span class="math display">\[
\begin{aligned} &amp; \nabla_{\alpha} \mathcal{L}_{v a
l}\left(w^{*}(\alpha), \alpha\right) \\ \approx &amp; \nabla_{\alpha}
\mathcal{L}_{v a l}\left(w-\xi \nabla_{w} \mathcal{L}_{t r a i n}(w,
\alpha), \alpha\right) \end{aligned}
\]</span></p>
<p>è¿ç”¨chain ruleã€‚å°†ä¸Šå¼è¿›ä¸€æ­¥å¤„ç†ã€‚ <span class="math display">\[
\triangledown_\alpha L_{val}(w&#39;, \alpha - \xi
\triangledown^2_{\alpha, w} L_{train}(w, \alpha)
\triangledown_{w&#39;}L_{val}(w&#39;, \alpha))
\]</span> å…¶ä¸­çš„<span class="math inline">\(w&#39; = w -
\xi\triangledown_w L_{train}(w, \alpha)\)</span>æŒ‡çš„å°±æ˜¯one-step forward
modelã€‚</p>
<p>ä½¿ç”¨the finite difference approximation(æœ‰é™å·®åˆ†è¿‘ä¼¼)å¯ä»¥å‡å°‘å¤æ‚åº¦ã€‚
<span class="math display">\[
\epsilon æ˜¯æå°é‡ \\
w^{\pm} = w \pm \epsilon \triangledown_{w&#39;}L_{val}(w&#39;, \alpha)
\\
\xi \triangledown^2_{\alpha, w} L_{train}(w, \alpha)
\triangledown_{w&#39;}L_{val}(w&#39;, \alpha)) \approx
\frac{\triangledown_\alpha L_{train}(w^{+}, \alpha) -
\triangledown_\alpha L_{train}(w^{-}, \alpha)}{2\xi}
\]</span> å°†<span class="math inline">\(\xi =
0\)</span>ä½œä¸ºä¸€é˜¶è¿‘ä¼¼ï¼Œå°†<span class="math inline">\(\xi &gt;
0\)</span>ä½œä¸ºä¸¤é˜¶è¿‘ä¼¼ã€‚</p>
<h3 id="deriving-discrete-architecture">1.4 deriving discrete
architecture</h3>
<p>åœ¨æ‰€æœ‰é0çš„å€™é€‰operationsä¿ç•™top-k strongest
operationsï¼Œä¸ºäº†ä½¿å¾—å‡ºçš„ç½‘ç»œå¯ä»¥å’Œç°æœ‰ç½‘ç»œæ¯”è¾ƒï¼Œæˆ‘ä»¬é€‰æ‹©k=2 for cnn, k=1
for rnnã€‚</p>
<p>ä¸ºä»€ä¹ˆä¸ä½¿ç”¨zero operationå‘¢ï¼Ÿ</p>
<ol type="1">
<li>ä¸ºäº†ä¸ç°æœ‰æ¨¡å‹è¿›è¡Œå…¬å¹³çš„æ¯”è¾ƒï¼Œæˆ‘ä»¬éœ€è¦æ¯ä¸ªèŠ‚ç‚¹æ°å¥½æœ‰kæ¡éé›¶çš„å¼•å…¥è¾¹</li>
<li>å› ä¸ºå¢åŠ é›¶æ“ä½œçš„logitsåªä¼šå½±å“ç»“æœèŠ‚ç‚¹è¡¨ç¤ºçš„è§„æ¨¡ï¼Œç”±äºBNå¤„ç†çš„å­˜åœ¨è€Œä¸ä¼šè€Œå½±å“æœ€ç»ˆçš„åˆ†ç±»ç»“æœ</li>
</ol>
<h2 id="experiments-and-results">2. Experiments and results</h2>
<h3 id="architecture-search">2.1 architecture search</h3>
<h4 id="search-for-convolutional-cells-on-cifar-10">2.1.1 search for
convolutional cells on cifar-10</h4>
<p>åŒ…å«8ç§operationã€‚ 3 Ã— 3 and 5 Ã— 5 separable convolutions, 3 Ã— 3 and
5 Ã— 5 dilated separable convolutions, 3 Ã— 3 max pooling, 3 Ã— 3 average
pooling, identity, and zeroã€‚</p>
<p>We use the ReLU-Conv-BN order for convolutional operations, and each
separable convolution is always applied twice</p>
<p>åœ¨æ•´ä¸ªç½‘ç»œçš„1/3å’Œ2/3å¤„ï¼Œè®¾ç«‹reduce cellã€‚ç¼©å°ç©ºé—´åˆ†è¾¨ç‡ã€‚</p>
<h4 id="searching-for-recurrent-cells-for-penn-treebank">2.1.2 searching
for recurrent cells for penn treebank</h4>
<p>operationçš„ç§ç±»ï¼šlinear transformations followed by one of tanh,
relu, sigmoid activations, as well as the identity mapping and the
<em>zero</em> operation.</p>
<p>æ€»å…±12ä¸ªnodeï¼Œæœ€åˆçš„intermediate nodeæ˜¯ç”±ä¸¤ä¸ªinput
nodeé€šè¿‡çº¿æ€§å˜æ¢ï¼Œæ±‚å’Œï¼Œç„¶åä¼ è¿‡ä¸€ä¸ªtanhæ¿€æ´»å‡½æ•°å¾—åˆ°çš„ã€‚</p>
<h3 id="architecture-evaluation">2.2 architecture evaluation</h3>
<p><strong>å¯»æ‰¾å¤šæ¬¡ï¼Œé¿å…åˆå§‹åŒ–çš„å½±å“</strong>
ã€‚ä»cifar-10ä¸Šè¿ç§»åˆ°imagenetä¸Šï¼Œä»PTBä¸Šè¿ç§»åˆ°wikitext-2ä¸Šã€‚</p>
]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>NAS</tag>
      </tags>
  </entry>
  <entry>
    <title>hierarchical representations for efficient architecture search</title>
    <url>/2020/11/01/04-HREAS/</url>
    <content><![CDATA[<p>åˆ†å±‚è®¾è®¡ï¼Œåº•å±‚ä¸ºä¸€ä¸ªä¸ªæœ€åŸºæœ¬çš„è®¡ç®—æ“ä½œï¼Œé¡¶å±‚ä¸ºæ•´ä½“æ¶æ„ã€‚</p>
<p><img src="https://s2.loli.net/2022/02/08/O3EAIcUJZo7nKma.png" /></p>
<h2 id="evolutionary-architecture-search">evolutionary architecture
search</h2>
<h3 id="mutation">mutation</h3>
<p>æ‰¾åˆ°non-primitive level
l&gt;=2ï¼Œé€‰æ‹©è¿™ä¸ªlevelé‡Œé¢çš„ä¸€ä¸ªmotifï¼Œé€‰æ‹©motifé‡Œé¢çš„ä¸¤ä¸ªèŠ‚ç‚¹ï¼ŒæŠŠä¸¤ä¸ªèŠ‚ç‚¹ä¸­é—´çš„è¾¹ç½®æ¢ä¸ºå¦ä¸€ç§è¾¹(ä¸‰ç§æƒ…å†µï¼Œ1.æ–°å¢è¾¹ï¼›2.å»é™¤è¾¹ï¼›3.ç½®æ¢è¾¹)ã€‚</p>
<h3 id="initialization">initialization</h3>
<p>åŸå‹åˆå§‹åŒ–çš„å¤„ç†</p>
<ol type="1">
<li>å…ˆæŠŠæ‰€æœ‰çš„è¾¹ç½®æ¢ä¸ºidentity</li>
<li>æ‰§è¡Œå¾ˆå¤§æ•°ç›®(e.g. 1000)æ¬¡çš„mutation</li>
</ol>
<h3 id="search-algorithm">search algorithm</h3>
<p>Tournament selection</p>
<p>ä»åˆå§‹çš„éšæœºåŸå‹é›†åˆä¸­ï¼Œtournament selectioné€‰å‡ºæœ€promising
åŸå‹ï¼ŒæŠŠå®ƒçš„mutatedåä»£æ”¾åˆ°é›†åˆä¸­ï¼Œé‡å¤è¿™ä¸ªè¿‡ç¨‹ï¼Œé›†åˆä¸­çš„åŸå‹è¡¨ç°ä¼šéšæ—¶é—´ç¼“æ…¢ä¼˜åŒ–ã€‚é€‰æ‹©åŸå‹é›†åˆä¸­åœ¨validation
setä¸Šé¢è¡¨ç°æœ€å¥½çš„genotypeä½œä¸ºä¸€æ®µæ—¶é—´è¿›åŒ–çš„æœ€åè¾“å‡ºã€‚</p>
<p>randon search</p>
<p>ä¸åŒäºtournament selectionï¼Œrandom
searchéšæœºé€‰æ‹©é›†åˆä¸­çš„åŸå‹è¿›è¡Œçªå˜ï¼Œè¿™æ ·çªå˜çš„è¿‡ç¨‹å¯ä»¥å¹¶è¡Œï¼Œå‡å°‘äº†search
time</p>
<h3 id="implementation">implementation</h3>
<p>å¼‚æ­¥çš„
ä¸€ä¸ªcontrollerè´Ÿè´£æ‰§è¡Œæ‰€æœ‰åŸå‹çš„è¿›åŒ–ï¼Œå…¶ä½™çš„workerè´Ÿè´£å¯¹åŸå‹çš„è¡¨ç°åševaluationã€‚Architectures
are trained from scratch for a fixed number of steps with random weight
initializationã€‚</p>
]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>NAS</tag>
      </tags>
  </entry>
  <entry>
    <title>ENAS</title>
    <url>/2020/02/09/03-ENAS/</url>
    <content><![CDATA[<h2
id="efficient-neural-architecture-search-via-parameter-sharing">Efficient
Neural Architecture Search via Parameter Sharing</h2>
<p>an RNN controller is trained in a loop: the controller first samples
a candidate architecture, i.e. a child model, and then trains it to
convergence to measure its performance on the task of desire.</p>
<h2 id="è®­ç»ƒ">0. è®­ç»ƒ</h2>
<p>åˆ†ä¸ºä¸¤ä¸ªç½‘ç»œï¼Œcontrolleré€‰æ‹©è®¾è®¡å­ç½‘ç»œçš„æ¶æ„ï¼Œ
å­ç½‘ç»œæ˜¯ä¸€ä¸ªentireç½‘ç»œçš„ä¸€ä¸ªå­å›¾</p>
<p>åˆ†ä¸ºä¸¤ç§å‚æ•° RNNçš„å‚æ•°<span class="math inline">\(\theta\)</span>
sampleç½‘ç»œçš„<span class="math inline">\(w\)</span> åˆ†åˆ«ä½¿ç”¨adam
åœ¨validation setè®­ç»ƒ SGDåœ¨training setä¸Šé¢è®­ç»ƒ</p>
<h2 id="rnn-cellsçš„è®¾è®¡">1. RNN cellsçš„è®¾è®¡</h2>
<p>controllerè®¾è®¡</p>
<ol type="1">
<li>å½“å‰èŠ‚ç‚¹è¿æ¥çš„å‰ä¸€ä¸ªèŠ‚ç‚¹</li>
<li>ä½¿ç”¨ä»€ä¹ˆæ¿€æ´»å‡½æ•°(relu, sigmod, tanh, identity)4ç§</li>
</ol>
<p><img src="https://s2.loli.net/2022/02/08/YzISjdOGJL9Flke.png" /></p>
<p>search space:the search space has<span class="math inline">\(4N Ã—
N!\)</span>configurations. In our experiments, N = 12,</p>
<h2 id="cnnçš„è®¾è®¡">2. cnnçš„è®¾è®¡</h2>
<p>controllerè®¾è®¡</p>
<ol type="1">
<li>å½“å‰èŠ‚ç‚¹è¿æ¥çš„å‰ä¸€ä¸ªèŠ‚ç‚¹</li>
<li>ä½¿ç”¨ä»€ä¹ˆè®¡ç®—å‡½æ•°(<code>conv3*3, conv5*5, sep3*3, sep5*5, maxpooling3*3, average pooling3*3</code>)6ç§</li>
</ol>
<p><img src="https://s2.loli.net/2022/02/08/LfFwBabU9i1AvhS.png" /></p>
<p>search space: Making the described set of decisions for a total of L
times, we can sample a network of L layers. Since all decisions are
independent, there are 6L Ã— 2L(Lâˆ’1)/2 networks in the search space. In
our experiments, L = 12, resulting in 1.6 Ã— 1029 possible networks.</p>
<h2 id="cnn-cellsè®¾è®¡">3. cnn cellsè®¾è®¡</h2>
<p>controllerè®¾è®¡</p>
<ol type="1">
<li>ä¸¤ä¸ªå‰ç½®è¿æ¥çš„èŠ‚ç‚¹</li>
<li>ä¸¤æ¡è¾¹çš„è®¡ç®—ç§ç±»(<code>identity, sep3*3, spe5*5, avepooling3*3, maxpooling3*3</code>)
5ç§</li>
</ol>
<p><img src="https://s2.loli.net/2022/02/08/ZMcOLn3kFSYilJs.png" /></p>
<p>search space: Finally, we estimate the complexity of this search
space. At node i (3 â‰¤ i â‰¤ B), the controller can select any two nodes
from the i âˆ’ 1 previous nodes, and any two operations from 5 operations.
As all decisions are independent, there are (5 Ã— (B âˆ’ 2)!)2 possible
cells. Since we independently sample for a convolutional cell and a
reduction cell, the final size of the search space is (5 Ã— (B âˆ’ 2)!) .
With B = 7 as in our experiments, the search space can realize 1.3 Ã—
1011 final networks, making it significantly smaller than the search
space for entire convolutional networks</p>
]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>NAS</tag>
      </tags>
  </entry>
  <entry>
    <title>ICLR2020éƒ¨åˆ†NASæŠ•ç¨¿è®ºæ–‡è§£è¯»</title>
    <url>/2020/11/01/05-ICLR2020_NAS_papers/</url>
    <content><![CDATA[<h2
id="stabilizing-darts-with-amended-grarident-estimation-on-architectural-parameters">1.stabilizing
DARTS with Amended grarident estimation on architectural parameters</h2>
<p>å°†dartsçš„lossåˆ†ä¸ºä¸¤ä¸ªéƒ¨åˆ†ï¼Œå¯¹ç¬¬äºŒä¸ªéƒ¨åˆ†è¿›è¡Œäº†æ¨è¯ï¼Œæå‡ºäº†æ–°çš„ä¸€ç§æ•°å­¦å½¢å¼å»è¿‘ä¼¼è¿™ä¸ªlossï¼Œå¹¶è¿›è¡Œäº†solidçš„æ•°å­¦è¯æ˜ã€‚</p>
<p><span class="math display">\[\begin{equation}
\mathbf{g}_{2}^{\prime}=-\left.\left.\eta \cdot
\nabla_{\boldsymbol{\alpha}, \boldsymbol{\omega}}^{2} \mathcal{L}_{\text
{train }}(\boldsymbol{\omega},
\boldsymbol{\alpha})\right|_{\omega=\boldsymbol{\omega}^{*}\left(\boldsymbol{\alpha}_{t}\right),
\boldsymbol{\alpha}=\boldsymbol{\alpha}_{t}} \cdot \mathbf{H} \cdot
\nabla_{\boldsymbol{\omega}} \mathcal{L}_{\text {val
}}(\boldsymbol{\omega},
\boldsymbol{\alpha})\right|_{\boldsymbol{\omega}=\boldsymbol{\omega}^{*}\left(\boldsymbol{\alpha}_{t}\right),
\boldsymbol{\alpha}=\boldsymbol{\alpha}_{t}}
\end{equation}\]</span></p>
<p>æå‡ºDARTSçš„äºŒé˜¶åå¯¼çš„æ›´åˆç†çš„è¿‘ä¼¼ï¼Œä¸‹é¢è¿™ä¸ªå…¬å¼ï¼Œç¬¬ä¸€ä¸ªéƒ¨åˆ†ç§°ä¸º<span
class="math inline">\(g_1\)</span>ï¼Œé€šè¿‡æ¢¯åº¦çš„åå‘ä¼ æ’­å¾—åˆ°ã€‚ç¬¬äºŒéƒ¨åˆ†ç§°ä¸º<span
class="math inline">\(g_2\)</span>ï¼Œæ›´åˆç†çš„è¿‘ä¼¼ä¸º<span
class="math inline">\(g_2&#39;\)</span>ã€‚ <span class="math display">\[
\begin{aligned}
\nabla_{\boldsymbol{\alpha}}
\mathcal{L}_{\mathrm{val}}\left(\boldsymbol{\omega}^{\star}(\boldsymbol{\alpha}),
\boldsymbol{\alpha}\right)|_{\boldsymbol{\alpha}=\boldsymbol{\alpha}_{t}}
=&amp; \nabla_{\boldsymbol{\alpha}}
\mathcal{L}_{\mathrm{val}}(\boldsymbol{\omega},
\boldsymbol{\alpha})|_{\boldsymbol{\omega}=\boldsymbol{\omega}^{*}\left(\boldsymbol{\alpha}_{t}\right),
\boldsymbol{\alpha}=\boldsymbol{\alpha}_{t}} -
\\
&amp; \nabla_{\boldsymbol{\alpha}, \boldsymbol{\omega}}^{2}
\mathcal{L}_{\mathrm{train}}(\boldsymbol{\omega},
\boldsymbol{\alpha})|_{\omega=\boldsymbol{\omega}^{*}
\left(\boldsymbol{\alpha}_{t}\right),
\boldsymbol{\alpha}=\boldsymbol{\alpha}_{t}} \cdot \mathbf{H}^{-1} \cdot
\nabla_{\boldsymbol{\omega}}
\mathcal{L}_{\mathrm{val}}(\boldsymbol{\omega},
\boldsymbol{\alpha})|_{\omega=\boldsymbol{\omega}^{*}\left(\boldsymbol{\alpha}_{t}\right),
\boldsymbol{\alpha}=\boldsymbol{\alpha}_{t}}
\end{aligned}
\]</span> <span class="math display">\[
\begin{aligned}
\left\langle\mathbf{g}_{2}^{\prime},
\mathbf{g}_{2}\right\rangle=&amp;\left.\left.\eta \cdot \nabla_{\omega}
\mathcal{L}_{\mathrm{val}}(\boldsymbol{\omega},
\boldsymbol{\alpha})\right|_{\omega=\omega^{*}\left(\boldsymbol{\alpha}_{t}\right),
\boldsymbol{\alpha}=\boldsymbol{\alpha}_{t}} ^{\top} \cdot
\mathbf{H}^{-1} \cdot \nabla_{\boldsymbol{\omega},
\boldsymbol{\alpha}}^{2}
\mathcal{L}_{\mathrm{train}}(\boldsymbol{\omega},
\boldsymbol{\alpha})\right|_{\omega=\boldsymbol{\omega}^{*}\left(\boldsymbol{\alpha}_{t}\right),
\boldsymbol{\alpha}=\boldsymbol{\alpha}_{t}} \\
&amp;\left.\left.\nabla_{\boldsymbol{\alpha}, \boldsymbol{\omega}}^{2}
\mathcal{L}_{\mathrm{train}}(\boldsymbol{\omega},
\boldsymbol{\alpha})\right|_{\omega=\boldsymbol{\omega}^{*}\left(\boldsymbol{\alpha}_{t}\right),
\boldsymbol{\alpha}=\boldsymbol{\alpha}_{t}} \cdot \mathbf{H} \cdot
\nabla_{\boldsymbol{\omega}}
\mathcal{L}_{\mathrm{val}}(\boldsymbol{\omega},
\boldsymbol{\alpha})\right|_{\omega=\omega^{*}\left(\boldsymbol{\alpha}_{t}\right),
\boldsymbol{\alpha}=\boldsymbol{\alpha}_{t}}
\end{aligned}
\]</span> å¹¶è¯æ˜<span class="math inline">\(g_2&#39;\)</span>ä¸<span
class="math inline">\(g_2\)</span>çš„ä¹˜ç§¯æ’å¤§äº0ï¼Œä¹Ÿå°±æ˜¯å¤¹è§’å°äº90åº¦ã€‚</p>
<h2
id="darts-improved-differentiable-architecture-search-with-early-stopping">2.
DARTS+: Improved Differentiable Architecture Search with Early
Stopping</h2>
<p>éšç€epochæ•°é‡çš„å¢å¤šï¼ŒDARTSå€¾å‘äºskip-connectionï¼Œé€ æˆæ¨¡å‹çš„è¡¨ç°ä¸‹é™</p>
<p>æå‡ºä¸€ç§æå‰åœæ­¢è®­ç»ƒçš„æ ‡å‡†ï¼Œè®©æ¨¡å‹æœç´¢æå‰åœæ­¢ã€‚</p>
<ol type="1">
<li>å½“æ¨¡å‹ä¸­å‡ºç°ä¸¤ä¸ªskip-connectionçš„æ—¶å€™</li>
<li>å½“æ¨¡å‹ä¸­çš„<span
class="math inline">\(\alpha\)</span>å‚æ•°çš„æ’åˆ—é¡ºåºä¸å†å‘ç”Ÿæ”¹å˜çš„æ—¶å€™(<span
class="math inline">\(\alpha\)</span>çš„å€¼æ˜¯å„ä¸ªPrimitivesçš„æ¦‚ç‡)</li>
</ol>
<h2 id="pc-darts">3. PC-DARTS</h2>
<p>uses partial- channel connections to reduce search time,</p>
<p><img src="https://s2.loli.net/2022/02/08/UXSkptfxLQnYilV.png" /></p>
<ol type="1">
<li><p>Partial Channel Connections</p>
<p>åªå°†1/K
çš„channelsä½¿ç”¨primitivesè¿æ¥ï¼Œå…¶ä½™çš„channelsé€‰æ‹©ç›´æ¥è¿æ¥ï¼Œä¹Ÿå°±æ˜¯ï¼Œä»<span
class="math inline">\(node_i\)</span>åˆ°<span
class="math inline">\(node_j\)</span>çš„è¾¹ä¸­ï¼Œé€‰å‡ºä¸€éƒ¨åˆ†channelä½¿ç”¨éidentityçš„æ–¹å¼è¿æ¥ï¼Œå…¶ä½™çš„ä½¿ç”¨identityï¼Œç»è¿‡éidentityæ–¹å¼çš„channelä¹˜ä»¥softmaxä»¥åçš„<span
class="math inline">\(\alpha\)</span>æƒé‡ç›¸åŠ ï¼Œå†å’ŒåŸæ¥çš„channelä¸€èµ·concatã€‚<strong>è¿™æ ·åšçš„å¤„ç†ï¼Œæ˜¯å¸Œæœ›å ç”¨çš„å†…å­˜æ›´å°ï¼Œä½¿ç”¨æ›´å¤§çš„batch_sizeï¼Œæå‡è®­ç»ƒå’Œæ¨¡å‹è¡¨ç°ã€‚</strong></p>
<p>å‰Šå¼±äº†weight-freeæ“ä½œçš„å½±å“ã€‚</p></li>
<li><p>Edge Normalization</p>
<p><span class="math inline">\(node_i\)</span>å‰é¢æ‰€æœ‰çš„<span
class="math inline">\(node\)</span>éƒ½éœ€è¦è¾“å‡ºåˆ°å®ƒï¼Œè®¾è®¡æƒé‡<span
class="math inline">\(\beta\)</span>ï¼Œä¹˜ä»¥è¿™äº›è¾¹ï¼Œå¾—åˆ°<span
class="math inline">\(node_i\)</span>çš„å€¼ã€‚</p></li>
</ol>
<h2 id="p-darts">4. P-DARTS</h2>
<p>å°†layerçš„æ•°ç›®æ…¢æ…¢å¢åŠ ã€‚</p>
<p><img src="https://s2.loli.net/2022/02/08/KfydxUwRnXJpDVq.png" /></p>
<ol type="1">
<li>searching for 25 epochs instead of 50 epochs,</li>
<li>adopting <em>dropout</em> after <em>skip-connect</em>s</li>
<li>manually reducing the number of <em>skip-connect</em>s to two</li>
</ol>
<p>ä¿®å‰ª<em>skip-connection</em>çš„æ•°ç›®æ“ä½œåªèƒ½å‘ç”Ÿåœ¨ç¬¬ä¸€ä¸ª</p>
<h2 id="searching-for-a-robust-neural-architecture-in-four-gpu-hours">5.
Searching for A Robust Neural Architecture in Four GPU Hours</h2>
<p><img src="https://s2.loli.net/2022/02/08/er6QUMHciAq45nd.png" /></p>
<p>æ¯æ¬¡åªè®¡ç®—æœ€å¤§æƒé‡çš„æ¢¯åº¦ï¼ŒåªBPæœ€å¤§æƒé‡çš„æ¢¯åº¦ï¼Œä»¥æ­¤æ¥å‡å°‘è®¡ç®—é‡å’ŒGPUæ˜¾å­˜ã€‚</p>
<h2 id="proxylessnas">6. ProxylessNAS</h2>
<p>ProxylessNAS
ä¸åŒäºä»¥å‰çš„åœ¨ä»£ç†æ•°æ®é›†ä¸Šé¢è¿›è¡Œæœç´¢ä»¥åè½¬ç§»åˆ°å¤§æ•°æ®é›†ç±»ä¼¼ImageNetä¸Šé¢è¿›è¡Œè®­ç»ƒæµ‹è¯•ï¼Œè€Œæ˜¯ç›´æ¥åœ¨å¤§æ•°æ®é›†ä¸Šé¢è¿›è¡Œæœç´¢ï¼Œå®ƒçš„æœç´ çš„ç®—å­æ•°ç›®è¢«å¤§å¤§å‡å°‘ä»¥å‡å°æœç´¢çš„ç©ºé—´ï¼Œé™ä½æœç´¢çš„éš¾åº¦ã€‚</p>
<h2 id="snas">7. SNAS</h2>
<p>SNASæ•…äº‹è®²çš„ä¸ä¸€æ ·ï¼Œä½†æ˜¯æœ¬è´¨ä¸Šæ¥è¯´ï¼Œè·ŸDARTSåŸºæœ¬ä¸€æ ·çš„åŸç†ï¼Œå³ä½¿ç”¨operationçš„åŠ æƒå’Œæ¥ä»£æ›¿å•ç‹¬çš„operationã€‚
å®ƒä½¿ç”¨äº†gumble-softmax
trickï¼Œ<strong>ä½¿ç”¨æ¦‚ç‡é‡‡æ ·å‡ºçš„æƒå€¼è€Œä¸æ˜¯å›ºå®šçš„æƒå€¼æ¥è®¡ç®—åŠ æƒå’Œ</strong>ï¼ŒåŒæ—¶å¢åŠ temperatureï¼Œä½¿å¾—é‡‡æ ·å‡ºçš„æƒå€¼æ›´åŠ æ¥è¿‘one-hotçš„æƒå€¼ï¼Œæ¥æ‹Ÿåˆå•ç‹¬çš„operationã€‚</p>
<p>SNASè®ºæ–‡é‡Œé¢è¯æ˜äº†ï¼Œä½¿ç”¨è¿™ç§æ–¹å¼é‡‡æ ·è¿›è¡Œä¼˜åŒ–çš„è¿‡ç¨‹ï¼Œè¿‘ä¼¼ç­‰ä»·äºå¼ºåŒ–å­¦ä¹ é‡‡æ ·ç½‘ç»œå­¦ä¹ è¿›è¡Œä¼˜åŒ–çš„è¿‡ç¨‹</p>
<p><img src="https://s2.loli.net/2022/02/08/TVlXyQ7DapMkLiC.png" /></p>
]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>NAS</tag>
      </tags>
  </entry>
  <entry>
    <title>Neural Architecture Search: A Survey</title>
    <url>/2020/11/01/06-NAS-Survey/</url>
    <content><![CDATA[<p>ç›®å‰å­˜åœ¨çš„åº”ç”¨ image classification object detection semantic
segmentation</p>
<p>NAS can be seen as subfield of AutoML (Hutter et al., 2019) and has
significant overlap with hyperparameter optimization (Feurer and Hutter,
2019) and meta-learning (Vanschoren, 2019). AutoMLçš„å­é¢†åŸŸ
NASä¸å…ƒå­¦ä¹ å’Œè¶…å‚æ•°ä¼˜åŒ–æœ‰å¾ˆå¤šé‡åˆçš„åœ°æ–¹</p>
<p>NASçš„æ–¹æ³•åˆ†ä¸ºä¸‰ç±»ï¼š</p>
<ol type="1">
<li>search space</li>
<li>search strategy</li>
<li>performance estimation strategy</li>
</ol>
<p><img src="https://s2.loli.net/2022/02/08/1csTrtfijkH9E4C.png" /></p>
<ul>
<li>Search Space. åŸåˆ™ä¸Šå®šä¹‰äº†å“ªäº›æ¶æ„å¯ä»¥è¢«è¡¨ç¤ºï¼Œå…ˆéªŒçŸ¥è¯†ç¼©å°äº†search
spaceï¼ŒåŒæ—¶ä¹Ÿå¯èƒ½æ¼æ‰è¶…å‡ºäººç±»è®¤çŸ¥çš„æ¶æ„</li>
<li>Search
Strategy.æœç´¢ç­–ç•¥è¯¦ç»†æè¿°äº†å¦‚ä½•æ¢ç´¢æœç´¢ç©ºé—´(é€šå¸¸æ˜¯æŒ‡æ•°çº§å¤§çš„ï¼Œç”šè‡³æ˜¯æ— ç•Œçš„)ã€‚å®ƒåŒ…å«äº†ç‰©ç†çš„æ¢ç´¢-åˆ©ç”¨æƒè¡¡ï¼Œå› ä¸ºä¸€æ–¹é¢ï¼Œå¿«é€Ÿæ‰¾åˆ°æ€§èƒ½è‰¯å¥½çš„æ¶æ„æ˜¯å¯å–çš„ï¼Œè€Œå¦ä¸€æ–¹é¢ï¼Œåº”è¯¥é¿å…è¿‡æ—©åœ°æ”¶æ•›åˆ°æ¬¡ä¼˜æ¶æ„çš„åŒºåŸŸã€‚</li>
<li>Performance Estimation Strategy.
ç®€å•çš„å¯¹æ‰€æœ‰æ•°æ®è¿›è¡Œæ ‡å‡†è®­ç»ƒå’Œæµ‹è¯•ï¼Œä½†æ˜¯è¿™ç§æ–¹æ¡ˆè®¡ç®—å¤ªè¿‡æ˜‚è´µï¼Œå¹¶ä¸”é™åˆ¶äº†å¯ä»¥ç ”ç©¶çš„ä½“ç³»ç»“æ„çš„æ•°é‡</li>
</ul>
<h2 id="search-space">1. search space</h2>
<h3 id="chain-structured-neural-network-architecture">chain-structured
neural network architecture</h3>
<p><img src="https://s2.loli.net/2022/02/08/xBnSYOeg3GVafry.png" />
æœç´¢ç©ºé—´çš„å½±å“å› ç´ </p>
<ol type="1">
<li>å±‚çš„æ•°ç›®</li>
<li>æ¯ä¸€å±‚çš„ç§ç±» pooling, conv, skip-connection, etc</li>
<li>è¶…å‚æ•°</li>
</ol>
<h3 id="cell-based-model">cell-based model</h3>
<p><img src="https://s2.loli.net/2022/02/08/P2AJEhNYIbfxSXv.png" /></p>
<ul>
<li>normal cell</li>
<li>reduction cell</li>
</ul>
<p>ä¼˜ç‚¹ï¼š</p>
<ol type="1">
<li>The size of the search space is drastically reduced
æœç´¢ç©ºé—´å¤§å¤§å‡å°</li>
<li>Architectures built from cells can more easily be transferred or
adapted to other data sets by simply varying the number of cells and
filters used within a model å¯ç§»æ¤æ€§æ¯”è¾ƒå¥½</li>
<li>Creating architectures by repeating building blocks has proven a
useful design prin- ciple in general, such as repeating an LSTM block in
RNNs or stacking a residual block.
å·²ç»è¯æ˜å åŠ ç½‘ç»œæ˜¯æœ‰æ•ˆçš„è®¾è®¡å‡†åˆ™ï¼Œå¦‚LSTMï¼ŒRNNï¼Œres-block</li>
</ol>
<h3 id="macro-architecture">macro-architecture</h3>
<p>how many cells shall be used and how should they be connected to
build the actual model</p>
<h2 id="search-strategy">2. search strategy</h2>
<ul>
<li>random search</li>
<li>Bayesian optimization</li>
<li>evolutionary methods</li>
<li>reinforcement learning (RL)</li>
<li>gradient-based methods.</li>
</ul>
<ol type="1">
<li><p>no interaction with an environment occurs during this sequential
process (no external state is observed, and there are no intermediate
rewards) å°†æ¶æ„å–æ ·çš„è¿‡ç¨‹å½“åšsingle
actionçš„çº¿æ€§ç”Ÿæˆè¿‡ç¨‹ï¼Œå°†RLé—®é¢˜è½¬æ¢ä¸ºæ— çŠ¶æ€å¤šæ­¦è£…å¼ºç›—é—®é¢˜ã€‚</p></li>
<li><p>frame NAS as a sequential decision process</p></li>
<li><p>deal with variable-length network architectures <strong>use a
bi-directional LSTM to encode architectures into a fixed-length
representation</strong></p></li>
<li><p>ä½¿ç”¨gradient-based
methodå»ä¼˜åŒ–æƒé‡ï¼Œä½¿ç”¨è¿›åŒ–ç®—æ³•ä»…ä»…å»ä¼˜åŒ–ç¥ç»ç½‘ç»œçš„æ¶æ„</p></li>
<li><p>Neuro-evolutionaryæ–¹æ³•ä¸åŒçš„åœ°æ–¹åœ¨äºhow they sample parents,
update populations, and generate offsprings</p>
<p><a href="https://arxiv.org/abs/1804.09081">Efficient multi-objective
neural architecture search via lamarckian evolution.</a>
åä»£ä»çˆ¶ç½‘ç»œä¸­ç»§æ‰¿æƒé‡</p>
<p><a href="https://arxiv.org/pdf/1703.01041.pdf">Large-scale evolution
of image classifiers</a> åä»£ä»çˆ¶ç½‘ç»œä¸­ç»§æ‰¿æ²¡æœ‰è¢«çªå˜å½±å“çš„æƒé‡</p></li>
<li><p>Monte Carlo Tree Search. hill climbing</p></li>
<li><p>optimize both the network weights and the network architecture by
alternating gradient descent steps on training data for weights and on
validation data for architectural parameters such as.
äº¤æ›¿ä½¿ç”¨æ¢¯åº¦ä¸‹é™æ³•ï¼Œåœ¨è®­ç»ƒé›†ä¸Šè®­ç»ƒæƒé‡ï¼Œåœ¨éªŒè¯é›†ä¸Šæ›´æ”¹æ¶æ„å‚æ•°</p></li>
<li><p>åœ¨å¯èƒ½çš„æ“ä½œé›†åˆä¸Šé¢ä¼˜åŒ–å¸¦å‚çš„åˆ†å¸ƒ</p></li>
<li><p>ä¼˜åŒ–å±‚çš„è¶…å‚æ•°å’Œè¿æ¥æ¨¡å¼</p></li>
</ol>
<h2 id="performance-estimation-strategy">3. Performance Estimation
Strategy</h2>
<p><img src="https://s2.loli.net/2022/02/08/HdpxLUvrX9DFSyZ.png" /></p>
<h2 id="directions">4. directions</h2>
<p>äººç±»å®šä¹‰æœç´¢ç©ºé—´çš„å¤§å°ç›¸æ¯”è¾ƒå¯»æ‰¾æ€§èƒ½æ›´å¥½çš„ç½‘ç»œæ¶æ„æ›´ç®€å•ï¼Œä½†åŒæ—¶ä¹Ÿé™åˆ¶äº†NASä¸å¤ªå¯èƒ½æ‰¾åˆ°æœ¬è´¨ä¸Šä¼˜äºç°åœ¨æ¶æ„çš„ç½‘ç»œæ¶æ„</p>
<p>åº”ç”¨åœ¨image restoration semantic segmentation reinforcement learning
ç­‰ç­‰ä¸Šé¢</p>
<p>GAN sensor, fusion</p>
<p>multi-task problems multi-objective problems</p>
<p>extending one-shot NAS to generate different architectures depending
on the task or instance on-the-fly.</p>
<p>search spaceçš„é€‰æ‹©</p>
<p>æ›´åŠ ç»†ç²’åº¦cellçš„æ„å»ºï¼Œèƒ½å¦å¤§å¤§åŠ å¼ºNASçš„èƒ½åŠ›</p>
<p>æ–°çš„æ•°æ®é›†ï¼šNas-bench-101: Towards reproducible neural architecture
search</p>
<p>Learning Augmentation Policies from Data</p>
]]></content>
      <categories>
        <category>Survey</category>
      </categories>
      <tags>
        <tag>NAS</tag>
      </tags>
  </entry>
  <entry>
    <title>Graph Neural Networks: A review of methods and applications</title>
    <url>/2020/06/15/07-gnn-review1/</url>
    <content><![CDATA[<h2
id="graph-neural-networks-a-review-of-methods-and-applications">Graph
Neural Networks: A review of methods and applications</h2>
<h2 id="introduction">1. introduction</h2>
<ol type="1">
<li>social science (social networks)</li>
<li>natural science (physical systems</li>
<li>protein-protein interaction networks</li>
<li>knowledge graphs</li>
</ol>
<p>å¸¸è§çš„æ¬§å‡ é‡Œå¾—ç»“æ„åŒ–æ•°æ®ä¸»è¦åŒ…å«ï¼š</p>
<p>1Dï¼šå£°éŸ³ï¼Œæ—¶é—´åºåˆ—ç­‰ï¼› 2Dï¼šå›¾åƒç­‰ï¼› 3Dï¼šè§†é¢‘ï¼Œé«˜å…‰è°±å›¾åƒç­‰ï¼›</p>
<h3 id="motivation">1.1 motivation</h3>
<ol type="1">
<li>CNN
<ul>
<li>å±€éƒ¨è¿æ¥</li>
<li>å…±äº«æƒé‡</li>
<li>å¤šå±‚ç½‘ç»œ</li>
</ul></li>
<li>graph embedding
<ul>
<li>åœ¨ encoder
ä¸­ï¼ŒèŠ‚ç‚¹ä¹‹é—´æ²¡æœ‰å…±äº«å‚æ•°ï¼Œè¿™å¯¼è‡´è®¡ç®—æ•ˆç‡ä½ä¸‹ï¼Œå› ä¸ºè¿™æ„å‘³ç€å‚æ•°çš„æ•°é‡éšç€èŠ‚ç‚¹çš„æ•°é‡çº¿æ€§å¢é•¿</li>
<li>ç›´æ¥åµŒå…¥æ–¹æ³•ç¼ºä¹æ³›åŒ–èƒ½åŠ›ï¼Œè¿™æ„å‘³ç€å®ƒä»¬æ— æ³•å¤„ç†åŠ¨æ€å›¾å½¢æˆ–æ¨å¹¿åˆ°æ–°å›¾å½¢</li>
</ul></li>
</ol>
<h3 id="ä¼˜ç‚¹">1.2 ä¼˜ç‚¹</h3>
<ol type="1">
<li><p>CNN å’Œ RNN
è¿™æ ·çš„æ ‡å‡†ç¥ç»ç½‘ç»œæ— æ³•å¤„ç†æ²¡æœ‰è‡ªç„¶èŠ‚ç‚¹é¡ºåºçš„ä¸è§„åˆ™å›¾æ•°æ®ï¼Œè€Œ GNN
åœ¨æ¯ä¸ªèŠ‚ç‚¹ä¸Šåˆ†åˆ«ä¼ æ’­ï¼Œå¿½ç•¥äº†èŠ‚ç‚¹çš„è¾“å…¥é¡ºåºã€‚å³ï¼ŒGNN
çš„è¾“å‡ºå¯¹äºèŠ‚ç‚¹çš„è¾“å…¥é¡ºåºæ˜¯ä¸å˜çš„ã€‚</p></li>
<li><p>å›¾ä¸­çš„è¾¹è¡¨ç¤ºäº†ä¸¤ä¸ªèŠ‚ç‚¹ä¹‹é—´çš„ä¾èµ–å…³ç³»çš„ä¿¡æ¯ã€‚åœ¨æ ‡å‡†çš„ç¥ç»ç½‘ç»œä¸­ï¼Œè¿™äº›ä¾èµ–ä¿¡æ¯åªæ˜¯ä½œä¸ºèŠ‚ç‚¹çš„ç‰¹å¾ã€‚ç„¶åï¼ŒGNN
å¯ä»¥é€šè¿‡å›¾å½¢ç»“æ„è¿›è¡Œä¼ æ’­ï¼Œè€Œä¸æ˜¯å°†å…¶ä½œä¸ºç‰¹å¾çš„ä¸€éƒ¨åˆ†ã€‚é€šå¸¸ï¼ŒGNN
é€šè¿‡å…¶é‚»åŸŸçš„çŠ¶æ€çš„<strong>åŠ æƒå’Œ</strong>æ¥æ›´æ–°èŠ‚ç‚¹çš„éšè—çŠ¶æ€ã€‚</p></li>
<li><p>æ¨ç†æ˜¯é«˜çº§äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªéå¸¸é‡è¦çš„ç ”ç©¶è¯¾é¢˜ï¼Œäººè„‘ä¸­çš„æ¨ç†è¿‡ç¨‹å‡ ä¹éƒ½æ˜¯åŸºäºä»æ—¥å¸¸ç»éªŒä¸­æå–çš„å›¾å½¢ã€‚æ ‡å‡†ç¥ç»ç½‘ç»œå·²ç»æ˜¾ç¤ºå‡ºé€šè¿‡å­¦ä¹ æ•°æ®åˆ†å¸ƒæ¥ç”Ÿæˆåˆæˆå›¾åƒå’Œæ–‡æ¡£çš„èƒ½åŠ›ï¼ŒåŒæ—¶å®ƒä»¬ä»ç„¶æ— æ³•ä»å¤§å‹å®éªŒæ•°æ®ä¸­å­¦ä¹ æ¨ç†å›¾ã€‚ç„¶è€Œï¼ŒGNN
æ¢ç´¢ä»åœºæ™¯å›¾ç‰‡å’Œæ•…äº‹æ–‡æ¡£ç­‰éç»“æ„æ€§æ•°æ®ç”Ÿæˆå›¾å½¢ï¼Œè¿™å¯ä»¥æˆä¸ºè¿›ä¸€æ­¥é«˜çº§ AI
çš„å¼ºå¤§ç¥ç»æ¨¡å‹ã€‚</p></li>
</ol>
<h2 id="æ¨¡å‹">2. æ¨¡å‹</h2>
<h3 id="é™åˆ¶">2.1 é™åˆ¶</h3>
<p>è™½ç„¶å®éªŒç»“æœè¡¨æ˜ GNN æ˜¯ä¸€ç§ç”¨äºå»ºæ¨¡ç»“æ„æ•°æ®çš„å¼ºå¤§æ¶æ„ï¼Œä½†åŸå§‹ GNN
ä»ç„¶å­˜åœ¨ä¸€äº›å±€é™æ€§ã€‚</p>
<ol type="1">
<li>å¯¹äºå›ºå®šç‚¹æ¥è¿­ä»£æ›´æ–°èŠ‚ç‚¹çš„éšè—çŠ¶æ€æ˜¯ååˆ†ä½æ•ˆçš„ã€‚å¦‚æœæ”¾å®½å›ºå®šç‚¹çš„å‡è®¾ï¼Œå¯ä»¥è®¾è®¡ä¸€ä¸ªå¤šå±‚
GNN æ¥è·å¾—èŠ‚ç‚¹åŠå…¶é‚»åŸŸçš„ç¨³å®šè¡¨ç¤ºã€‚</li>
<li>GNN
åœ¨è¿­ä»£ä¸­ä½¿ç”¨ç›¸åŒçš„å‚æ•°ï¼Œè€Œå¤§å¤šæ•°æµè¡Œçš„ç¥ç»ç½‘ç»œåœ¨ä¸åŒçš„å±‚ä¸­ä½¿ç”¨ä¸åŒçš„å‚æ•°æ¥è¿›è¡Œåˆ†å±‚ç‰¹å¾æå–ã€‚æ­¤å¤–ï¼ŒèŠ‚ç‚¹éšè—çŠ¶æ€çš„æ›´æ–°æ˜¯ä¸€ä¸ªé¡ºåºè¿‡ç¨‹ï¼Œå¯ä»¥åˆ©ç”¨
RNN å†…æ ¸ï¼Œå¦‚ GRU å’Œ LSTMï¼Œæ¥è¿›ä¸€æ­¥ä¼˜åŒ–ã€‚</li>
<li>å­˜åœ¨ä¸€äº›è¾¹ç¼˜ï¼ˆedgesï¼‰çš„ä¿¡æ¯ç‰¹å¾æ— æ³•åœ¨åŸå§‹ GNN
ä¸­æœ‰æ•ˆå»ºæ¨¡ã€‚ä¾‹å¦‚ï¼ŒçŸ¥è¯†å›¾ä¸­çš„è¾¹ç¼˜å…·æœ‰å…³ç³»ç±»å‹ï¼Œå¹¶ä¸”é€šè¿‡ä¸åŒè¾¹ç¼˜çš„æ¶ˆæ¯ä¼ æ’­åº”æ ¹æ®å…¶ç±»å‹è€Œä¸åŒã€‚æ­¤å¤–ï¼Œå¦‚ä½•å­¦ä¹ è¾¹ç¼˜çš„éšè—çŠ¶æ€ä¹Ÿæ˜¯ä¸€ä¸ªé‡è¦é—®é¢˜ã€‚</li>
<li>å¦‚æœæˆ‘ä»¬ä¸“æ³¨äºèŠ‚ç‚¹çš„è¡¨ç¤ºè€Œä¸æ˜¯å›¾å½¢ï¼Œåˆ™ä¸é€‚åˆä½¿ç”¨å›ºå®šç‚¹ï¼Œå› ä¸ºå›ºå®šç‚¹ä¸­çš„è¡¨ç¤ºåˆ†å¸ƒå°†åœ¨å€¼ä¸Šéå¸¸å¹³æ»‘å¹¶ä¸”ç”¨äºåŒºåˆ†æ¯ä¸ªèŠ‚ç‚¹çš„ä¿¡æ¯é‡è¾ƒå°‘ã€‚</li>
</ol>
<h3 id="gnnçš„-å˜ä½“">2.2 GNNçš„ å˜ä½“</h3>
<h4 id="å›¾ç±»å‹">2.2.1 å›¾ç±»å‹</h4>
<p>åœ¨åŸå§‹çš„ GNN
ä¸­ï¼Œè¾“å…¥çš„å›¾å½¢åŒ…æ‹¬å¸¦æœ‰æ ‡ç­¾ä¿¡æ¯çš„èŠ‚ç‚¹å’Œæ— å‘çš„è¾¹ï¼Œè¿™æ˜¯ä¸€ç§æœ€ç®€å•çš„å›¾å½¢å¼ã€‚ä½†åœ¨ç°å®ç”Ÿæ´»ä¸­ï¼Œå­˜åœ¨å¤šç§å›¾çš„å˜ä½“ï¼Œä¸»è¦åŒ…æ‹¬æœ‰å‘å›¾ã€å¼‚æ„å›¾å’Œå¸¦æœ‰è¾¹ä¿¡æ¯çš„å›¾ã€‚</p>
<ol type="1">
<li>æœ‰å‘å›¾ï¼šå³å›¾ä¸­çš„è¾¹æ˜¯å­˜åœ¨æ–¹å‘çš„ã€‚æœ‰å‘è¾¹å¯ä»¥å¸¦æ¥æ¯”æ— å‘è¾¹æ›´å¤šçš„ä¿¡æ¯ã€‚</li>
<li>å¼‚æ„å›¾ï¼šå³å›¾ä¸­å­˜åœ¨å¤šç§ç±»å‹çš„èŠ‚ç‚¹ã€‚å¤„ç†å¼‚æ„å›¾çš„æœ€ç®€å•æ–¹æ³•æ˜¯å°†æ¯ä¸ªèŠ‚ç‚¹çš„ç±»å‹è½¬æ¢ä¸ºä¸åŸå§‹ç‰¹å¾è¿æ¥çš„
one-hot ç‰¹å¾å‘é‡ã€‚</li>
<li>å¸¦æœ‰è¾¹ä¿¡æ¯çš„å›¾ï¼šå³å›¾ä¸­çš„æ¯æ¡è¾¹ä¹Ÿå­˜åœ¨æƒé‡æˆ–ç±»å‹ç­‰ä¿¡æ¯ã€‚è¿™ç§ç±»å‹çš„å›¾æœ‰ä¸¤ç§è§£å†³åŠæ³•ï¼Œä¸€ç§æ˜¯å°†å›¾å½¢è½¬åŒ–ä¸ºäºŒéƒ¨å›¾ï¼ŒåŸå§‹è¾¹ä¹Ÿä½œä¸ºèŠ‚ç‚¹ï¼Œå¹¶å°†å…¶åˆ†å‰²æˆä¸¤æ¡æ–°çš„è¾¹ï¼Œåˆ†åˆ«è¿æ¥åŸå§‹è¾¹çš„ä¸¤ç«¯èŠ‚ç‚¹ï¼›ç¬¬äºŒç§æ–¹æ³•æ˜¯è°ƒæ•´ä¸åŒçš„æƒé‡çŸ©é˜µï¼Œä»¥ä¾¿åœ¨ä¸åŒç±»å‹çš„è¾¹ç¼˜ä¸Šä¼ æ’­ã€‚</li>
</ol>
<p><img src="https://s2.loli.net/2022/02/08/U5n17s9Ode3Pbiq.png" /></p>
<h4 id="ä¼ æ’­ç±»å‹">2.2.2 ä¼ æ’­ç±»å‹</h4>
<p>å¯¹äºè·å–èŠ‚ç‚¹æˆ–è€…è¾¹çš„éšè—çŠ¶æ€ï¼Œç¥ç»ç½‘ç»œä¸­çš„ä¼ æ’­æ­¥éª¤å’Œè¾“å‡ºæ­¥éª¤è‡³å…³é‡è¦ã€‚åœ¨ä¼ æ’­æ­¥éª¤æ–¹é¢çš„æ”¹è¿›ä¸»è¦æœ‰å·ç§¯ã€æ³¨æ„åŠ›æœºåˆ¶ã€é—¨æœºåˆ¶å’Œè·³è·ƒè¿æ¥ï¼ˆskip
connectionï¼‰ï¼Œè€Œåœ¨è¾“å‡ºæ­¥éª¤é€šå¸¸éµå¾ªç®€å•çš„å‰é¦ˆç¥ç»ç½‘ç»œè®¾ç½®ã€‚</p>
<ol type="1">
<li>å·ç§¯ã€‚Graph Convolutional
Networkï¼ˆGCNï¼‰å¸Œæœ›å°†å·ç§¯æ“ä½œåº”ç”¨åœ¨å›¾ç»“æ„æ•°æ®ä¸Šï¼Œä¸»è¦åˆ†ä¸º Spectral Method
å’Œ Spatial Methodï¼ˆNon-spectral Methodï¼‰ä¸¤ç±»ã€‚Spectral Method
å¸Œæœ›ä½¿ç”¨è°±åˆ†è§£çš„æ–¹æ³•ï¼Œåº”ç”¨å›¾çš„æ‹‰æ™®æ‹‰æ–¯çŸ©é˜µåˆ†è§£è¿›è¡ŒèŠ‚ç‚¹çš„ä¿¡æ¯æ”¶é›†ã€‚Spatial
Method ç›´æ¥ä½¿ç”¨å›¾çš„æ‹“æ‰‘ç»“æ„ï¼Œæ ¹æ®å›¾çš„é‚»å±…ä¿¡æ¯è¿›è¡Œä¿¡æ¯æ”¶é›†ã€‚</li>
<li>æ³¨æ„åŠ›æœºåˆ¶ã€‚Graph Attention Network
è‡´åŠ›äºå°†æ³¨æ„åŠ›æœºåˆ¶åº”ç”¨åœ¨å›¾ä¸­çš„ä¿¡æ¯æ”¶é›†é˜¶æ®µã€‚</li>
<li>é—¨æœºåˆ¶ã€‚è¿™äº›å˜ä½“å°†é—¨æœºåˆ¶åº”ç”¨äºèŠ‚ç‚¹æ›´æ–°é˜¶æ®µã€‚Gated graph neural
network å°† GRU æœºåˆ¶åº”ç”¨äºèŠ‚ç‚¹æ›´æ–°ã€‚å¾ˆå¤šå·¥ä½œè‡´åŠ›äºå°† LSTM
åº”ç”¨äºä¸åŒç±»å‹çš„å›¾ä¸Šï¼Œæ ¹æ®å…·ä½“æƒ…å¢ƒçš„ä¸åŒï¼Œå¯ä»¥åˆ†ä¸º Tree LSTMã€Graph LSTM
å’Œ Sentence LSTM ç­‰ã€‚</li>
<li>æ®‹å·®è¿æ¥ã€‚æ³¨æ„åˆ°å †å å¤šå±‚å›¾ç¥ç»ç½‘ç»œå¯èƒ½å¼•èµ·ä¿¡æ¯å¹³æ»‘çš„é—®é¢˜ï¼Œå¾ˆå¤šå·¥ä½œå°†æ®‹å·®æœºåˆ¶åº”ç”¨äºå›¾ç¥ç»ç½‘ç»œä¸­ï¼Œæ–‡ä¸­ä»‹ç»äº†
Highway GNN å’Œ Jump Knowledge Network ä¸¤ç§ä¸åŒçš„å¤„ç†æ–¹å¼</li>
</ol>
<p><img src="https://s2.loli.net/2022/02/08/KS7JX1uljVzvcbA.png" /></p>
<h4 id="è®­ç»ƒæ–¹æ³•">2.2.3 è®­ç»ƒæ–¹æ³•</h4>
<p>åŸå§‹å›¾å·ç§¯ç¥ç»ç½‘ç»œåœ¨è®­ç»ƒå’Œä¼˜åŒ–æ–¹æ³•ä¸­å…·æœ‰è‹¥å¹²ç¼ºç‚¹ã€‚ä¾‹å¦‚ï¼Œ</p>
<ol type="1">
<li>GCN
éœ€è¦å®Œæ•´çš„å›¾æ‹‰æ™®æ‹‰æ–¯ç®—å­ï¼Œè¿™å¯¹äºå¤§å›¾æ¥è¯´æ˜¯<strong>è®¡ç®—æˆæœ¬ååˆ†é«˜</strong>ã€‚</li>
<li>è€Œä¸”ï¼Œå±‚ ğ¿ çš„èŠ‚ç‚¹çš„åµŒå…¥æ˜¯é€šè¿‡å±‚ <span
class="math inline">\(ğ¿âˆ’1\)</span>
çš„æ‰€æœ‰è¯¥èŠ‚ç‚¹çš„é‚»å±…æ¥è¿›è¡Œè®¡ç®—çš„ã€‚å› æ­¤ï¼Œå•ä¸ªèŠ‚ç‚¹çš„æ„ŸçŸ¥åŸŸç›¸å¯¹äºå±‚æ•°å‘ˆæŒ‡æ•°å¢é•¿ï¼Œ<strong>å•ä¸ªèŠ‚ç‚¹çš„è®¡ç®—æ¢¯åº¦æˆæœ¬å¾ˆé«˜</strong>ã€‚</li>
<li>æœ€åï¼ŒGCN
é’ˆå¯¹å›ºå®šå›¾å½¢è¿›è¡Œç‹¬ç«‹è®­ç»ƒï¼Œ<strong>ç¼ºä¹å½’çº³å­¦ä¹ çš„èƒ½åŠ›</strong>ã€‚</li>
</ol>
<h3 id="é€šç”¨æ¡†æ¶">2.3 é€šç”¨æ¡†æ¶</h3>
<p>é™¤äº†æå‡ºå›¾ç¥ç»ç½‘ç»œçš„ä¸åŒå˜ä½“ä¹‹å¤–ï¼Œä¸€äº›ç ”ç©¶äººå‘˜ä»ç¥ç»ç½‘ç»œçš„æ¡†æ¶å…¥æ‰‹ï¼Œæå‡ºäº†ä¸€äº›é€šç”¨æ¡†æ¶ï¼Œæ—¨åœ¨å°†ä¸åŒæ¨¡å‹é›†æˆåˆ°ä¸€ä¸ªå•ä¸€æ¡†æ¶ä¸­ã€‚ä¸»è¦åŒ…æ‹¬
Message Passing Neural Networksï¼ˆMPNNï¼‰ã€Non-local Neural
Networksï¼ˆNLNNï¼‰ä»¥åŠ Graph Networkï¼ˆGNï¼‰ç­‰ã€‚</p>
<ol type="1">
<li><p>Message Passing Neural Networks
é’ˆå¯¹å›¾ç»“æ„çš„ç›‘ç£å­¦ä¹ æ¡†æ¶ï¼ŒMPNNæ¡†æ¶æŠ½è±¡äº†å‡ ç§æœ€æµè¡Œçš„å›¾å½¢ç»“æ„æ•°æ®æ¨¡å‹ï¼ˆå¦‚å›¾å·ç§¯ä¸­çš„å…‰è°±æ–¹æ³•å’Œéå…‰è°±æ–¹æ³•ï¼Œé—¨æ§ç¥ç»ç½‘ç»œï¼Œäº¤äº’ç½‘ç»œï¼Œåˆ†å­å›¾å·ç§¯ï¼Œæ·±åº¦å¼ é‡ç¥ç»ç½‘ç»œç­‰ï¼‰ä¹‹é—´çš„å…±æ€§ï¼Œ</p></li>
<li><p>Non-local Neural Networks
NLNNåˆ©ç”¨æ·±åº¦å­¦ä¹ æ•æ‰é•¿èŒƒå›´çš„ä¾èµ–å…³ç³»ï¼Œè¿™æ˜¯å¯¹éå±€éƒ¨å¹³å‡è¿ç®—çš„ä¸€ç§æ³›åŒ–ï¼Œéå±€éƒ¨è¿ç®—é€šè¿‡è®¡ç®—å¯¹æ‰€æœ‰ä½ç½®çš„ç‰¹å¾çš„åŠ æƒå’Œæ¥å¾—åˆ°å½“å‰ä½ç½®çš„å½±å“ï¼Œæ­¤å¤„çš„ä½ç½®é›†åˆå¯ä»¥æ˜¯ç©ºé—´ã€æ—¶é—´æˆ–è€…æ—¶ç©ºã€‚</p></li>
<li><p>Graph Networks GNè¢«æå‡ºæ¥æ³›åŒ–å’Œæ‰©å±•å¤šç§å›¾ç¥ç»ç½‘ç»œï¼Œä»¥åŠ MPNN å’Œ
NLNN æ–¹æ³•ã€‚æœ¬æ–‡ä¸»è¦ä»‹ç»äº†å›¾çš„å®šä¹‰ã€GN blockã€æ ¸å¿ƒ GN
è®¡ç®—å•å…ƒã€è®¡ç®—æ­¥éª¤å’ŒåŸºæœ¬è®¾è®¡åŸåˆ™ã€‚è¯¦ç»†çš„å†…å®¹æ‰©å±•ä¼šå¦å¤–å†™åˆ°ä¸“é—¨é’ˆå¯¹è¯¥æ–‡çŒ®çš„é˜…è¯»ç¬”è®°å½“ä¸­ã€‚</p></li>
</ol>
<h2 id="åº”ç”¨">3. åº”ç”¨</h2>
<p><img src="https://s2.loli.net/2022/02/08/Yq8MQOcyP7D1tZ4.png" /></p>
<h2 id="å¼€æ”¾æ€§é—®é¢˜">4. å¼€æ”¾æ€§é—®é¢˜</h2>
<h3 id="æµ…å±‚ç»“æ„">4.1 æµ…å±‚ç»“æ„</h3>
<p>ä¼ ç»Ÿçš„æ·±åº¦ç¥ç»ç½‘ç»œå¯ä»¥å †å æ•°ç™¾å±‚ä»¥è·å¾—æ›´å¥½çš„æ€§èƒ½ï¼Œå› ä¸ºæ›´æ·±çš„ç»“æ„å…·æœ‰æ›´å¤šçš„å‚æ•°ï¼Œä»è€Œèƒ½å¤Ÿæ˜¾è‘—æé«˜è¡¨ç¤ºèƒ½åŠ›ã€‚è€Œå›¾ç¥ç»ç½‘ç»œé€šå¸¸éƒ½å¾ˆæµ…ï¼Œå¤§å¤šæ•°ä¸è¶…è¿‡ä¸‰å±‚ã€‚æ­£å¦‚
[5] ä¸­çš„å®éªŒæ‰€ç¤ºï¼Œå †å å¤šä¸ª GCN
å±‚å°†å¯¼è‡´è¿‡åº¦å¹³æ»‘ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œæ‰€æœ‰é¡¶ç‚¹å°†æ”¶æ•›åˆ°ç›¸åŒçš„å€¼ã€‚å°½ç®¡ä¸€äº›ç ”ç©¶äººå‘˜è®¾æ³•è§£å†³äº†è¿™ä¸ªé—®é¢˜ï¼Œä½†å®ƒä»ç„¶æ˜¯
GNN çš„æœ€å¤§é™åˆ¶ã€‚è®¾è®¡çœŸæ­£çš„æ·±åº¦ GNN
å¯¹äºæœªæ¥çš„ç ”ç©¶æ¥è¯´æ˜¯ä¸€ä¸ªä»¤äººå…´å¥‹çš„æŒ‘æˆ˜ï¼Œå¹¶å°†å¯¹ç†è§£ GNN
åšå‡ºç›¸å½“å¤§çš„è´¡çŒ®ã€‚</p>
<h3 id="åŠ¨æ€å›¾ç»“æ„">4.2 åŠ¨æ€å›¾ç»“æ„</h3>
<p>å¦ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„é—®é¢˜æ˜¯å¦‚ä½•å¤„ç†å…·æœ‰åŠ¨æ€ç»“æ„çš„å›¾å½¢ã€‚é™æ€å›¾æ˜¯ç¨³å®šçš„ï¼Œå› æ­¤å¯ä»¥å®¹æ˜“åœ°å»ºæ¨¡ï¼Œè€ŒåŠ¨æ€å›¾åˆ™å¼•å…¥å˜åŒ–çš„ç»“æ„ã€‚å½“è¾¹å’ŒèŠ‚ç‚¹å‡ºç°æˆ–æ¶ˆå¤±æ—¶ï¼ŒGNN
æ— æ³•è‡ªé€‚åº”åœ°æ›´æ”¹ã€‚ åŠ¨æ€ GNN æ­£åœ¨ç§¯æç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬è®¤ä¸ºå®ƒæ˜¯ä¸€èˆ¬ GNN
çš„ç¨³å®šæ€§å’Œé€‚åº”æ€§çš„é‡è¦é‡Œç¨‹ç¢‘ã€‚</p>
<h3 id="éç»“æ„åŒ–åœºæ™¯">4.3 éç»“æ„åŒ–åœºæ™¯</h3>
<p>è™½ç„¶æˆ‘ä»¬å·²ç»è®¨è®ºäº† GNN
åœ¨éç»“æ„åœºæ™¯ä¸­çš„åº”ç”¨ï¼Œä½†æˆ‘ä»¬å‘ç°æ²¡æœ‰æœ€ä½³æ–¹æ³•å¯ä»¥ä»åŸå§‹æ•°æ®ç”Ÿæˆå›¾å½¢ã€‚å› æ­¤ï¼Œæ‰¾åˆ°æœ€ä½³å›¾å½¢ç”Ÿæˆæ–¹æ³•å°†æä¾›
GNN å¯ä»¥åšå‡ºè´¡çŒ®çš„æ›´å¹¿æ³›çš„é¢†åŸŸã€‚</p>
<h3 id="å¯ä¼¸ç¼©æ€§">4.4 å¯ä¼¸ç¼©æ€§</h3>
<p>å¦‚ä½•åœ¨ç¤¾äº¤ç½‘ç»œæˆ–æ¨èç³»ç»Ÿç­‰ç½‘ç»œè§„æ¨¡æ¡ä»¶ä¸‹åº”ç”¨åµŒå…¥æ–¹æ³•å¯¹äºå‡ ä¹æ‰€æœ‰å›¾å½¢åµŒå…¥ç®—æ³•æ¥è¯´éƒ½æ˜¯ä¸€ä¸ªè‡´å‘½çš„é—®é¢˜ï¼Œè€Œ
GNN ä¹Ÿä¸ä¾‹å¤–ã€‚æ‰©å±• GNN
å¾ˆå›°éš¾ï¼Œå› ä¸ºè®¸å¤šæ ¸å¿ƒæ­¥éª¤åœ¨å¤§æ•°æ®ç¯å¢ƒä¸­çš„è®¡ç®—æˆæœ¬éƒ½ååˆ†é«˜ã€‚</p>
]]></content>
      <categories>
        <category>Survey</category>
      </categories>
      <tags>
        <tag>GNN</tag>
      </tags>
  </entry>
  <entry>
    <title>meta-learning_nas</title>
    <url>/2020/06/18/08-meta-learning-nas/</url>
    <content><![CDATA[<h2
id="towards-fast-adaptation-of-neural-architectures-with-meta-learning">1.
Towards fast adaptation of neural architectures with meta learning</h2>
<p><a href="https://openreview.net/forum?id=r1eowANFvr">ICLR2020</a></p>
<p>æ–‡ç« çš„çš„ä¸»è¦æ€æƒ³æ˜¯ï¼Œåœ¨meta-learningçš„settingä¸Šé¢ï¼Œé€šè¿‡ä¸åŒçš„taskï¼Œå­¦ä¹ ä¸€ä¸ªå¯ä»¥æ³›åŒ–çš„architectureï¼Œç„¶ååœ¨queryé›†ä¸Šé¢è¿›è¡Œfune-tuningï¼Œå¾®è°ƒè¿™ä¸ªç»“æ„ï¼Œä½¿å¾—è¯¥ç»“æ„å¯¹ä¸åŒtest
taskæœ‰è‰¯å¥½çš„é€‚ç”¨æ€§ã€‚ <img
src="https://s2.loli.net/2022/02/08/WdiwUbqfGHBDFO5.png" /></p>
<p>åœ¨mini-imagenetä¸Šé¢5-wayçš„ç»“æœ <img
src="https://s2.loli.net/2022/02/08/DjiUZRg9dThlMSP.png" /></p>
<h2 id="auto-meta-automated-gradient-based-meta-learner-search">2.
Auto-Meta: Automated Gradient Based Meta Learner Search</h2>
<p><a
href="https://arxiv.org/abs/1806.06927">https://arxiv.org/abs/1806.06927</a>
NIPS2018 workshop</p>
<p>ä¹Ÿæ˜¯æ„é€ cellå»stackèµ·æ¥ï¼Œè·å–æ•´ä¸ªçš„networkï¼Œä½†æ˜¯ä¸€å¼€å§‹çš„cellå¹¶ä¸æ˜¯æ•´ä¸ªçš„supernetï¼Œè€Œæ˜¯åœ¨æœç´¢çš„è¿‡ç¨‹ä¸­ï¼Œé€æ­¥å¾€è¿™ä¸ªcellé‡Œé¢å»æ·»åŠ opetatorï¼Œ<strong>ç„¶åä½¿ç”¨ä¸€ä¸ªpredictorå»é¢„æµ‹è¿™ä¸ªcellçš„æ€§èƒ½</strong>ï¼Œé€‰æ‹©top
kæ€§èƒ½çš„cellç»„æˆç½‘ç»œè¿›è¡Œæµ‹è¯•ã€‚ <img
src="https://s2.loli.net/2022/02/08/vZe5xTgW9UGLHEJ.png" /></p>
<h2 id="meta-architecture-search">3. Meta Architecture Search</h2>
<p><img src="https://s2.loli.net/2022/02/08/GRloLut4PFAKsin.png" /></p>
<p>æœ¬æ–‡ä»Bayesiançš„è§’åº¦ï¼Œæ¨ç†äº†ä¸€éNASçš„åŸç†ï¼Œæå‡ºç”¨Coupled Variational
Bayes (CVB)å»ç”Ÿæˆå‚æ•°çš„è¡¨è¾¾ï¼ŒåŒæ—¶è¿›è¡Œäº†æ¨ç†ï¼ˆhard
mathï¼‰ã€‚æœ¬è´¨ä¸Šæ¥è¯´ï¼Œè¿™ç¯‡å·¥ä½œåŸºæœ¬ä¸Šè¿˜æ˜¯dartsï¼Œä¸è¿‡å®ƒé¦–å…ˆå°†meta
learningçš„åœ¨imagenetä¸Šé¢è·å–çš„å…ˆéªŒçŸ¥è¯†æ‹¿å‡ºæ¥æ”¾åˆ°å…¶ä»–ä»»åŠ¡ä¸Šå»trainã€‚
é¦–å…ˆä½¿ç”¨gumble_softmaxed darts(å‚è§SNAS)ï¼Œå–å¾—meta
networkçš„archå’Œinitï¼Œç„¶åé’ˆå¯¹ä¸åŒä»»åŠ¡è¿›è¡Œfine tuningã€‚ <img
src="08-meta-learning-nas/04-meta_architecture_search.png"
alt="meta as" /></p>
<h2
id="metadapt-meta-learned-task-adaptive-architecture-for-few-shot-classification">MetAdapt:
Meta-Learned Task-Adaptive Architecture for Few-Shot Classification</h2>
<p><a
href="https://arxiv.org/abs/1912.00412">https://arxiv.org/abs/1912.00412</a></p>
<p>åœ¨dartsçš„åŸºç¡€ä¸Šï¼Œæå‡ºäº†ä¸€ä¸ªMetAdapt
Controllersï¼Œå°±æ˜¯è¯´ï¼Œå¯¹äºä¸åŒçš„taskï¼Œäº§ç”Ÿä¸åŒçš„å åŠ æƒé‡ <img
src="https://s2.loli.net/2022/02/08/7ZFXxTMz5uiRHD8.png" /></p>
<h2
id="meta-learning-of-neural-architectures-for-few-shot-learning">Meta-Learning
of Neural Architectures for Few-Shot Learning</h2>
<p><a
href="https://arxiv.org/abs/1911.11090">https://arxiv.org/abs/1911.11090</a>
æå‡ºäº†gradient-based NAS + meta learning
ç»“åˆçš„æ¡†æ¶ï¼Œç›´æ¥æƒ³æŠŠæ‰€æœ‰æ–¹æ³•éƒ½æ¡†åˆ°è‡ªå·±ä¸‹é¢ã€‚ <img
src="https://s2.loli.net/2022/02/08/Y95WIqhJoeTRkAU.png" /></p>
]]></content>
      <categories>
        <category>Survey</category>
      </categories>
      <tags>
        <tag>NAS, meta-learning</tag>
      </tags>
  </entry>
  <entry>
    <title>string_pattern</title>
    <url>/2020/07/15/09-string-pattern/</url>
    <content><![CDATA[<h2 id="å­—ç¬¦ä¸²åŒ¹é…ç®—æ³•">1.1 å­—ç¬¦ä¸²åŒ¹é…ç®—æ³•</h2>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">algorithm</th>
<th style="text-align: center;"><span
class="math inline">\(T_{best}\)</span></th>
<th style="text-align: center;"><span
class="math inline">\(T_{avg}\)</span></th>
<th style="text-align: center;"><span
class="math inline">\(T_{worst}\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">1. æœ´ç´ åŒ¹é…ç®—æ³•</td>
<td style="text-align: center;">O(nm)</td>
<td style="text-align: center;">O(nm)</td>
<td style="text-align: center;">O(nm)</td>
</tr>
<tr class="even">
<td style="text-align: left;">2. Robin-Karp ç®—æ³•</td>
<td style="text-align: center;">O(n)</td>
<td style="text-align: center;">O(nm)</td>
<td style="text-align: center;">O(nm)</td>
</tr>
<tr class="odd">
<td style="text-align: left;">3. KMPç®—æ³•</td>
<td style="text-align: center;">O(n+m)</td>
<td style="text-align: center;">O(n+m)</td>
<td style="text-align: center;">O(n+m)</td>
</tr>
</tbody>
</table>
<h3 id="æœ´ç´ åŒ¹é…ç®—æ³•">1.1.1 æœ´ç´ åŒ¹é…ç®—æ³•</h3>
<p>æš´åŠ›æ±‚è§£</p>
<h3 id="robin-karpç®—æ³•">1.1.2 Robin-Karpç®—æ³•</h3>
<p>å…ˆæ˜¯è®¡ç®—ä¸¤ä¸ªå­—ç¬¦ä¸²çš„å“ˆå¸Œå€¼ï¼Œç„¶åé€šè¿‡æ¯”è¾ƒè¿™ä¸¤ä¸ªå“ˆå¸Œå€¼çš„å¤§å°æ¥åˆ¤æ–­æ˜¯å¦å‡ºç°åŒ¹é…ã€‚
é€‰æ‹©ä¸€ä¸ªåˆé€‚çš„å“ˆå¸Œå‡½æ•°å¾ˆé‡è¦ã€‚å‡è®¾æ–‡æœ¬ä¸²ä¸ºt[0, n)ï¼Œæ¨¡å¼ä¸²ä¸ºp[0, m)ï¼Œå…¶ä¸­
<span class="math inline">\(0&lt;m&lt;n\)</span>ï¼Œ<span
class="math inline">\(Hash(t[i,j])\)</span>ä»£è¡¨å­—ç¬¦ä¸²t[i,
j]çš„å“ˆå¸Œå€¼ã€‚</p>
<p>å½“ <span class="math inline">\(Hash(t[0,
m-1])!=Hash(p[0,m-1])\)</span> æ—¶ï¼Œæˆ‘ä»¬å¾ˆè‡ªç„¶çš„ä¼šæŠŠ <span
class="math inline">\(Hash(t[1, m])\)</span>
æ‹¿è¿‡æ¥ç»§ç»­æ¯”è¾ƒã€‚åœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­ï¼Œè‹¥æˆ‘ä»¬é‡æ–°è®¡ç®—å­—ç¬¦ä¸²t[1,
m]çš„å“ˆå¸Œå€¼ï¼Œè¿˜éœ€è¦ O(n) çš„æ—¶é—´å¤æ‚åº¦ï¼Œä¸åˆ’ç®—ã€‚è§‚å¯Ÿåˆ°å­—ç¬¦ä¸²t[0,
m-1]ä¸t[1, m]ä¸­æœ‰ m-1
ä¸ªå­—ç¬¦æ˜¯é‡åˆçš„ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥é€‰ç”¨<strong>æ»šåŠ¨å“ˆå¸Œå‡½æ•°</strong>ï¼Œé‚£ä¹ˆé‡æ–°è®¡ç®—çš„æ—¶é—´å¤æ‚åº¦å°±é™ä¸º
O(1)ã€‚</p>
<p>Rabin-Karp ç®—æ³•é€‰ç”¨çš„æ»šåŠ¨å“ˆå¸Œå‡½æ•°ä¸»è¦æ˜¯åˆ©ç”¨<span
class="math inline">\(Rabin
fingerprint\)</span>çš„æ€æƒ³ï¼Œä¸¾ä¸ªä¾‹å­ï¼Œè®¡ç®—å­—ç¬¦ä¸²t[0, m -
1]çš„å“ˆå¸Œå€¼çš„å…¬å¼å¦‚ä¸‹ï¼Œ</p>
<p><span
class="math display">\[Hash(t[0,mâˆ’1])=t[0]âˆ—b_{mâˆ’1}+t[1]âˆ—b_{mâˆ’2}+...+t[mâˆ’1]âˆ—b_0\]</span></p>
<p>å…¶ä¸­çš„ b_k å¯ä»¥æ˜¯ä¸€ä¸ªå¸¸æ•°ï¼Œåœ¨ Rabin-Karp
ç®—æ³•ä¸­ï¼Œæˆ‘ä»¬ä¸€èˆ¬å–å€¼ä¸º256ï¼Œå› ä¸ºä¸€ä¸ªå­—ç¬¦çš„æœ€å¤§å€¼ä¸è¶…è¿‡255ã€‚ä¸Šé¢çš„å…¬å¼è¿˜æœ‰ä¸€ä¸ªé—®é¢˜ï¼Œå“ˆå¸Œå€¼å¦‚æœè¿‡å¤§å¯èƒ½ä¼šæº¢å‡ºï¼Œå› æ­¤æˆ‘ä»¬è¿˜éœ€è¦å¯¹å…¶å–æ¨¡ï¼Œè¿™ä¸ªå€¼åº”è¯¥å°½å¯èƒ½å¤§ï¼Œä¸”æ˜¯è´¨æ•°ï¼Œè¿™æ ·å¯ä»¥å‡å°å“ˆå¸Œç¢°æ’çš„æ¦‚ç‡ï¼Œåœ¨è¿™é‡Œæˆ‘ä»¬å°±å–
101ã€‚</p>
<p>åˆ™è®¡ç®—å­—ç¬¦ä¸²t[1, m]çš„å“ˆå¸Œå€¼å…¬å¼å¦‚ä¸‹ï¼Œ</p>
<p><span
class="math display">\[Hash(t[1,m])=(Hash(t[0,mâˆ’1])âˆ’t[0]âˆ—b_{mâˆ’1})âˆ—b+t[m]âˆ—b_0\]</span></p>
<h3 id="kmpç®—æ³•">1.1.3 KMPç®—æ³•</h3>
<p>KMPç®—æ³•çš„ç²¾é«“åœ¨äºï¼Œå¯¹äºä¸€ä¸ªä¸åŒ¹é…çš„å­ä¸²ï¼Œæˆ‘ä»¬å°†æ•´ä¸ªæ¨¡å¼ä¸²å‘åé¢ç§»åŠ¨æ›´å¤šçš„ä½æ•°è€Œä¸æ˜¯1ï¼Œæ¥åŠ é€Ÿå­ä¸²çš„è¯†åˆ«ï¼Œè¿™ä¸ªç§»åŠ¨æ­¥æ•°è·Ÿåªéœ€è¦æ ¹æ®æ¨¡å¼å­ä¸²è®¡ç®—ä¸€æ¬¡å°±å¯ä»¥å¾—åˆ°ã€‚</p>
<p><a
href="http://www.ruanyifeng.com/blog/2013/05/Knuth%E2%80%93Morris%E2%80%93Pratt_algorithm.html">é˜®ä¸€å³°KMPç®—æ³•</a></p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co">#KMP</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> kmp_match(s, p):</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>    m <span class="op">=</span> <span class="bu">len</span>(s)<span class="op">;</span> n <span class="op">=</span> <span class="bu">len</span>(p)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>    cur <span class="op">=</span> <span class="dv">0</span><span class="co">#èµ·å§‹æŒ‡é’ˆcur</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>    table <span class="op">=</span> partial_table(p)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> cur<span class="op">&lt;=</span>m<span class="op">-</span>n:</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n):</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> s[i<span class="op">+</span>cur]<span class="op">!=</span>p[i]:</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>                cur <span class="op">+=</span> <span class="bu">max</span>(i <span class="op">-</span> table[i<span class="op">-</span><span class="dv">1</span>], <span class="dv">1</span>)<span class="co">#æœ‰äº†éƒ¨åˆ†åŒ¹é…è¡¨,æˆ‘ä»¬ä¸åªæ˜¯å•çº¯çš„1ä½1ä½å¾€å³ç§»,å¯ä»¥ä¸€æ¬¡ç§»åŠ¨å¤šä½</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>                <span class="cf">break</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="va">True</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="va">False</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="co">#éƒ¨åˆ†åŒ¹é…è¡¨</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> partial_table(p):</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>    <span class="co">&#39;&#39;&#39;partial_table(&quot;ABCDABD&quot;) -&gt; [0, 0, 0, 0, 1, 2, 0]&#39;&#39;&#39;</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>    prefix <span class="op">=</span> <span class="bu">set</span>()</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>    postfix <span class="op">=</span> <span class="bu">set</span>()</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>    ret <span class="op">=</span> [<span class="dv">0</span>]</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>,<span class="bu">len</span>(p)):</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>        prefix.add(p[:i])</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>        postfix <span class="op">=</span> &#123;p[j:i<span class="op">+</span><span class="dv">1</span>] <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>,i<span class="op">+</span><span class="dv">1</span>)&#125;</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>        ret.append(<span class="bu">len</span>((prefix<span class="op">&amp;</span>postfix <span class="kw">or</span> &#123;<span class="st">&#39;&#39;</span>&#125;).pop()))</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> ret</span></code></pre></div>
]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>string</tag>
      </tags>
  </entry>
  <entry>
    <title>è”é‚¦å­¦ä¹ æ¦‚è¿°</title>
    <url>/2020/11/01/10-FL/</url>
    <content><![CDATA[<h2 id="overview">1. Overview</h2>
<h3 id="é—®é¢˜å®šä¹‰">1.1 é—®é¢˜å®šä¹‰</h3>
<p><img src="https://s2.loli.net/2022/02/08/83DClsfSqIRK7gk.png" />
ç®€å•æ¥è¯´ï¼Œå°±æ˜¯è¯´è”é‚¦å­¦ä¹ çš„ç›®æ ‡æ˜¯è®­ç»ƒä¸€ä¸ª"å°½å¯èƒ½æ¥è¿‘æŠŠå„ä¸ªèŠ‚ç‚¹æ•°æ®èšåˆèµ·æ¥è®­ç»ƒ"çš„æ¨¡å‹ã€‚</p>
<h3 id="å…¸å‹åº”ç”¨">1.2 å…¸å‹åº”ç”¨</h3>
<ul>
<li>smart phone</li>
<li>Organizations</li>
<li>internet of things ç‰©è”ç½‘ æ”¶é›†å„ç§æ¨¡æ€çš„ä¿¡æ¯</li>
</ul>
<h3 id="ä¸»è¦æŒ‘æˆ˜">1.3 ä¸»è¦æŒ‘æˆ˜</h3>
<ol type="1">
<li>expensive communication
<ul>
<li>reducing the total number of communication rounds</li>
<li>reducing the size of transmitted messages at each round.</li>
</ul></li>
<li>systems heterogeneity
<ul>
<li>only a small fraction of the devices being active at once</li>
<li>anticipate a low amount of participation</li>
<li>tolerate heterogeneous hardware</li>
<li>be robust to dropped devices in the network.</li>
</ul></li>
<li>Statistical Heterogeneity
<ul>
<li>independent and identically distributed</li>
<li>Both the multi-task and meta-learning perspectives enable
personalized or device-specific modeling, which is often a more natural
approach to handle the statistical heterogeneity of the data.</li>
</ul></li>
<li>Privacy Concern
<ul>
<li>secure multiparty computation or differential privacy</li>
<li>at the cost of reduced model performance or system efficiency.</li>
</ul></li>
</ol>
<h2 id="related-and-current-work">2. related and current work</h2>
<h3 id="communication-efficiency">2.1 Communication-efficiency</h3>
<ol type="1">
<li>local updating methods</li>
<li>compression schemes</li>
<li>decentralized training</li>
</ol>
<h3 id="systems-heterogeneity">2.2 Systems Heterogeneity</h3>
<h3 id="statistical-heterogeneity">2.3 Statistical Heterogeneity</h3>
<h4 id="modeling-heterogeneous-data">2.3.1 Modeling heterogeneous
Data</h4>
<ul>
<li>fairness</li>
<li>accountability</li>
<li>interpretability</li>
</ul>
<h4 id="convergence-guarantees-for-non-iid-data">2.3.2 Convergence
Guarantees for Non-IID Data</h4>
<p>Indeed, when data is not identically distributed across devices in
the network, methods such as <strong>FedAvg</strong> have been shown to
diverge in practice</p>
<p>Parallel SGD and related variants</p>
<p>FedProx</p>
<h3 id="ptivacy">2.4 Ptivacy</h3>
<h4 id="privacy-in-machine-learning">2.4.1 privacy in Machine
learning</h4>
<p>differential privacyï¼š strong information theoretic guarantees,
algorithmic simplicity, and relatively small systems overhead</p>
<p>homomorphic encryptionåŒæ€åŠ å¯†</p>
<h4 id="privacy-in-federated-learning">2.4.2 Privacy in Federated
Learning</h4>
<p>è®¡ç®—å»‰ä»·ï¼Œäº¤æµé«˜æ•ˆï¼Œå…è®¸ä¸¢å¤±device--ä¸èƒ½å¯¹accuracyåšå¾ˆå¤§è®©æ­¥</p>
<ol type="1">
<li><p>Secure Multi-party Computation (SMC) å®‰å…¨çš„å¤šæ–¹è®¡ç®—
å„æ–¹é™¤äº†è¾“å…¥å’Œè¾“å‡ºå¤–ä¸€æ— æ‰€çŸ¥</p>
<ul>
<li>å¤æ‚çš„è®¡ç®—åè®®</li>
<li>å¦‚æœæä¾›å®‰å…¨ä¿è¯ï¼Œåˆ™éƒ¨åˆ†çŸ¥è¯†å…¬å¼€å¯èƒ½è¢«è®¤ä¸ºæ˜¯å¯ä»¥æ¥å—çš„</li>
</ul>
<p>è¦æ±‚å‚ä¸è€…çš„æ•°æ®åœ¨éå†²çªæœåŠ¡å™¨ä¹‹é—´ç§˜å¯†å…±äº«</p></li>
<li><p>Differential Privacy å·®å¼‚éšç§
å‘æ•°æ®æ·»åŠ å™ªéŸ³ï¼Œæˆ–ä½¿ç”¨å½’çº³æ–¹æ³•é®ç›–æŸäº›æ•æ„Ÿå±æ€§ï¼Œç›´åˆ°ç¬¬ä¸‰æ–¹æ— æ³•åŒºåˆ†ä¸ªäºº</p>
<ul>
<li>æ•°æ®ä¹Ÿè¢«ä¼ è¾“åˆ°ç»™äº†å…¶ä»–äºº</li>
<li>æ¶‰åŠå‡†ç¡®æ€§å’Œéšç§ä¹‹é—´çš„æƒè¡¡</li>
</ul></li>
<li><p>Homomorphic Encryption åŒæ€åŠ å¯†
åœ¨æœºå™¨å­¦ä¹ æœŸé—´é€šè¿‡åŠ å¯†æœºåˆ¶ä¸‹çš„å‚æ•°äº¤æ¢æ¥ä¿æŠ¤ç”¨æˆ·æ•°æ®éšç§</p>
<ul>
<li>æ•°æ®å’Œæ¨¡å‹æœ¬èº«ä¸ä¼ è¾“</li>
<li>å‡†ç¡®æ€§ä¸ç§å¯†æ€§ä¹‹é—´çš„æƒè¡¡</li>
</ul></li>
</ol>
<h2 id="future-directions">3. future directions</h2>
<ol type="1">
<li>Extreme communication schemes
<ul>
<li>one- shot or divide-and-conquer communication schemes</li>
<li>one-shot/few-shot heuristics</li>
</ul></li>
<li>Communication reduction and the Pareto frontier
<ul>
<li>local updatding æœ¬åœ°æ›´æ–°</li>
<li>model compression æ¨¡å‹å‹ç¼©</li>
</ul></li>
<li>Novel models of asynchrony
<ul>
<li>ä»»ä½•è®¾å¤‡åœ¨ä»»ä½•è¿­ä»£ä¸­éƒ½æœ‰å¯èƒ½å¤±è”</li>
<li>è®¾å¤‡éšæ—¶é€šè¿‡<strong>äº‹ä»¶é©±åŠ¨</strong>å’Œcentral serveräº¤æ¢ä¿¡æ¯</li>
</ul></li>
<li>Heterogeneity diagnostics
<ul>
<li>æ˜¯å¦å­˜åœ¨ç®€å•çš„è¯Šæ–­æ–¹æ³•æ¥é¢„å…ˆå¿«é€Ÿç¡®å®šè”åˆç½‘ç»œçš„å¼‚æ„ç¨‹åº¦?</li>
<li>èƒ½å¦å¼€å‘å‡ºç±»ä¼¼çš„è¯Šæ–­æ–¹æ³•æ¥é‡åŒ–ä¸ç³»ç»Ÿç›¸å…³çš„å¼‚è´¨æ€§çš„æ•°é‡</li>
<li>å¯ä»¥åˆ©ç”¨ç°æœ‰çš„æˆ–æ–°çš„å¼‚æ„å®šä¹‰è¿›ä¸€æ­¥æ”¹è¿›è”é‚¦ä¼˜åŒ–æ–¹æ³•çš„æ”¶æ•›æ€§å—?</li>
</ul></li>
<li>Granular privacy constraints
<ul>
<li>thus providing a weaker form of privacy in exchange for more
accurate models</li>
</ul></li>
<li>Beyond supervised learning
<ul>
<li>scalability, heterogeneity, and privacy.</li>
</ul></li>
<li>Productionizing federated learning
<ul>
<li>å®é™…è½åœ°çš„é—®é¢˜ concept drift</li>
<li>diurnal variations è®¾å¤‡ä¸åŒæ—¶é—´è¡¨ç°ä¸åŒ</li>
<li>cold start problems è®¾å¤‡æ–°åŠ å…¥</li>
</ul></li>
<li>Benchmarks
<ul>
<li>reproducibility of empirical results and the dissemination of new
solutions for federated learning.</li>
</ul></li>
</ol>
]]></content>
      <categories>
        <category>Survey</category>
      </categories>
      <tags>
        <tag>Federated Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>A Comprehensive Survey on Graph Neural Networks</title>
    <url>/2020/11/01/11-GNN-survey2/</url>
    <content><![CDATA[<h2 id="ç®€ä»‹">1 ç®€ä»‹</h2>
<p>æ¬§å¼æ•°æ®ï¼šå›¾ç‰‡ï¼Œæ–‡æœ¬ï¼Œè¯­è¨€ï¼Œè§†é¢‘ éæ¬§å¼æ•°æ®ï¼šå›¾</p>
<p>å›¾æ•°æ®ä¸è§„åˆ™ï¼Œæ¯ä¸ªå›¾çš„æ— åºèŠ‚ç‚¹å¤§å°æ˜¯å¯å˜çš„ï¼Œä¸”æ¯ä¸ªç»“ç‚¹æœ‰ä¸åŒæ•°é‡çš„é‚»å±…ç»“ç‚¹ï¼Œå› æ­¤ä¸€äº›é‡è¦çš„æ“ä½œå¦‚å·ç§¯èƒ½å¤Ÿåœ¨å›¾åƒæ•°æ®ä¸Šè½»æ˜“è®¡ç®—ï¼Œä½†æ˜¯ä¸é€‚ç”¨äºå›¾æ•°æ®ï¼Œå¯è§å›¾æ•°æ®çš„å¤æ‚æ€§ç»™ç°æœ‰çš„æœºå™¨å­¦ä¹ ç®—æ³•å¸¦æ¥äº†å·¨å¤§çš„æŒ‘æˆ˜
ã€‚æ­¤å¤–ï¼Œç°æœ‰çš„æœºå™¨å­¦ä¹ ç®—æ³•å‡è®¾æ•°æ®ä¹‹é—´æ˜¯ç›¸äº’ç‹¬ç«‹çš„ï¼Œä½†æ˜¯ï¼Œå›¾æ•°æ®ä¸­æ¯ä¸ªç»“ç‚¹éƒ½é€šè¿‡ä¸€äº›å¤æ‚çš„è¿æ¥ä¿¡æ¯ä¸å…¶ä»–é‚»å±…ç›¸å…³ï¼Œè¿™äº›è¿æ¥ä¿¡æ¯ç”¨äºæ•è·æ•°æ®ä¹‹é—´çš„ç›¸äº’ä¾èµ–å…³ç³»ï¼ŒåŒ…æ‹¬ï¼Œå¼•ç”¨ï¼Œå…³ç³»ï¼Œäº¤äº’ã€‚</p>
<ol type="1">
<li>Graph attention networksï¼ˆå›¾æ³¨æ„åŠ›ç½‘ç»œ)</li>
<li>Graph autoencodersï¼ˆå›¾è‡ªç¼–ç ï¼‰</li>
<li>Graph generative networksï¼ˆå›¾ç”Ÿæˆç½‘ç»œï¼‰</li>
<li>Graph spatial-temporal networksï¼ˆå›¾æ—¶ç©ºç½‘ç»œ</li>
</ol>
<p>GNN vs å›¾åµŒå…¥</p>
<p>ç½‘ç»œåµŒå…¥è‡´åŠ›äº<strong>åœ¨ä¸€ä¸ªä½ç»´å‘é‡ç©ºé—´è¿›è¡Œç½‘ç»œèŠ‚ç‚¹è¡¨ç¤ºï¼ŒåŒæ—¶ä¿æŠ¤ç½‘ç»œæ‹“æ‰‘ç»“æ„å’ŒèŠ‚ç‚¹çš„ä¿¡æ¯</strong>ï¼Œä¾¿äºåç»­çš„å›¾åƒåˆ†æä»»åŠ¡ï¼ŒåŒ…æ‹¬åˆ†ç±»ï¼Œèšç±»ï¼Œæ¨èç­‰ï¼Œèƒ½å¤Ÿä½¿ç”¨ç®€å•ç°æˆçš„æœºå™¨å­¦ä¹ ç®—æ³•ï¼ˆä¾‹å¦‚ï¼Œä½¿ç”¨SVMåˆ†ç±»ï¼‰ã€‚è®¸å¤šç½‘ç»œåµŒå…¥ç®—æ³•éƒ½æ˜¯å…¸å‹çš„æ— ç›‘ç£ç®—æ³•ï¼Œå®ƒä»¬å¯ä»¥å¤§è‡´åˆ†ä¸ºä¸‰ç§ç±»å‹ï¼Œå³ï¼Œ</p>
<ol type="1">
<li>çŸ©é˜µåˆ†è§£</li>
<li>éšæœºæ¸¸èµ°</li>
<li>æ·±åº¦å­¦ä¹ </li>
</ol>
<p><img src="https://s2.loli.net/2022/02/08/KJHiDeqxzIypEda.png" /></p>
<h2 id="gnnåˆ†ç±»åŠæ¡†æ¶">2 GNNåˆ†ç±»åŠæ¡†æ¶</h2>
<p>äº”ç§ç±»å‹ GCN GAN GAE GGN GSTN</p>
<h3 id="åˆ†ç±»">2.1 åˆ†ç±»</h3>
<h4 id="gcn">2.1.1 GCN</h4>
<p>GCNså°†ä¼ ç»Ÿæ•°æ®çš„å·ç§¯ç®—å­æ³›åŒ–åˆ°å›¾æ•°æ®ï¼Œè¿™ä¸ªç®—æ³•çš„å…³é”®æ˜¯å­¦ä¹ ä¸€ä¸ªå‡½æ•°<span
class="math inline">\(f\)</span>ï¼Œèƒ½å¤Ÿç»“åˆ<span
class="math inline">\(v_i\)</span>é‚»å±…èŠ‚ç‚¹çš„ç‰¹å¾<span
class="math inline">\(X_j\)</span>å’Œå…¶æœ¬èº«ç‰¹å¾<span
class="math inline">\(X_i\)</span>ç”Ÿæˆ<span
class="math inline">\(v_i\)</span>çš„æ–°è¡¨ç¤º.</p>
<p><img src="https://s2.loli.net/2022/02/08/LQsn6CPGMKwiTIX.png" /> <img
src="https://s2.loli.net/2022/02/08/lJX7qUViS8F5hk3.png" /></p>
<h4 id="gan">2.1.2 GAN</h4>
<p>GANä¸GCNç±»ä¼¼ï¼Œè‡´åŠ›äºå¯»æ‰¾ä¸€ä¸ªèšåˆå‡½æ•°ï¼Œèåˆå›¾ä¸­ç›¸é‚»çš„èŠ‚ç‚¹ï¼Œéšæœºæ¸¸åŠ¨å’Œå€™é€‰æ¨¡å‹ï¼Œå­¦ä¹ ä¸€ç§æ–°çš„è¡¨ç¤ºã€‚<strong>å…³é”®åŒºåˆ«æ˜¯ï¼šGANä½¿ç”¨æ³¨æ„åŠ›æœºåˆ¶ä¸ºæ›´é‡è¦çš„èŠ‚ç‚¹ï¼Œæ­¥æˆ–è€…æ¨¡å‹åˆ†é…æ›´å¤§çš„æƒé‡ï¼Œæƒé‡ä¸ªç½‘ç»œä¸€èµ·å­¦ä¹ ã€‚</strong>ä¸‹å›¾å±•ç¤ºäº†GCNå’ŒGANåœ¨èšåˆé‚»å±…èŠ‚ç‚¹ä¿¡æ¯æ—¶å€™çš„ä¸åŒã€‚</p>
<p><img src="https://s2.loli.net/2022/02/08/dXy6H2wcZxfbDOR.png" /></p>
<h4 id="gae">2.1.3 GAE</h4>
<p>GAEæ˜¯ä¸€ç§æ— ç›‘ç£å­¦ä¹ æ¡†æ¶ï¼Œé€šè¿‡ç¼–ç å™¨å­¦ä¹ ä¸€ç§ä½ç»´ç‚¹å‘é‡ï¼Œç„¶åé€šè¿‡è§£ç å™¨é‡æ„å›¾æ•°æ®ã€‚GAEæ˜¯ä¸€ç§å¸¸ç”¨çš„å­¦ä¹ å›¾åµŒå…¥çš„æ–¹æ³•ï¼Œæ—¢é€‚ç”¨äºæ— å±æ€§ä¿¡æ¯çš„æ™®é€šå›¾ï¼Œè¿˜é€‚ç”¨äºæ˜¯æœ‰å±æ€§å›¾ã€‚å¯¹äºæ™®é€šçš„å›¾ï¼Œå¤§å¤šæ•°ç®—æ³•ç›´æ¥é¢„å…ˆå¾—åˆ°ä¸€ä¸ªé‚»æ¥çŸ©é˜µï¼Œæˆ–è€…æ„å»ºä¸€ä¸ªä¿¡æ¯ä¸°å¯Œçš„çŸ©é˜µï¼Œä¹Ÿå°±æ˜¯ç‚¹å¯¹äº’ä¿¡æ¯çŸ©é˜µï¼Œæˆ–è€…é‚»æ¥çŸ©é˜µå¡«å……è‡ªç¼–ç æ¨¡å‹ï¼Œå¹¶æ•è·ä¸€é˜¶å’ŒäºŒé˜¶ä¿¡æ¯ã€‚å¯¹äºå±æ€§å›¾ï¼Œå›¾è‡ªç¼–ç æ¨¡å‹åˆ©ç”¨GCNä½œä¸ºä¸€ä¸ªæ„å»ºå—ç”¨äºç¼–ç ï¼Œå¹¶ä¸”é€šè¿‡é“¾è·¯é¢„æµ‹è§£ç å™¨é‡æ„ç»“æ„ä¿¡æ¯ã€‚</p>
<h4 id="ggn">2.1.4 GGN</h4>
<p>GGNæ—¨åœ¨ä»æ•°æ®ä¸­ç”Ÿæˆå¯ä¿¡çš„ä¿¡æ¯ï¼Œç”Ÿæˆç»™å®šå›¾ç»éªŒåˆ†å¸ƒçš„å›¾ä»æ ¹æœ¬ä¸Šæ¥è¯´æ˜¯å…·æœ‰æŒ‘æˆ˜æ€§çš„ï¼Œä¸»è¦å› ä¸ºå›¾æ˜¯å¤æ‚çš„æ•°æ®ç»“æ„ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œç ”ç©¶å‘˜æ¢ç´¢äº†å°†äº¤æ›¿å½¢æˆèŠ‚ç‚¹å’Œè¾¹ä½œä¸ºç”Ÿæˆè¿‡ç¨‹çš„å› ç´ ï¼Œå¹¶å€ŸåŠ©ä½œä¸ºè®­ç»ƒè¿‡ç¨‹ã€‚GGNä¸€ä¸ªå¾ˆæœ‰å‰é€”çš„åº”ç”¨é¢†åŸŸæ˜¯åŒ–åˆç‰©åˆæˆã€‚åœ¨åŒ–å­¦å›¾ä¸­ï¼Œè§†åŸå­ä¸ºèŠ‚ç‚¹ï¼ŒåŒ–å­¦é”®ä¸ºè¾¹ï¼Œä»»åŠ¡æ˜¯å‘ç°å…·æœ‰ä¸€å®šåŒ–å­¦å’Œç‰©ç†æ€§è´¨çš„å¯åˆæˆçš„æ–°åˆ†å­ã€‚</p>
<h4 id="gstn">2.1.5 GSTN</h4>
<p>GSTNä»æ—¶ç©ºå›¾ä¸­å­¦ä¹ ä¸å¯è§çš„æ¨¡å¼ï¼Œåœ¨äº¤é€šé¢„æµ‹å’Œäººç±»æ´»åŠ¨é¢„æµ‹ç­‰åº”ç”¨ä¸­è¶Šæ¥è¶Šé‡è¦ã€‚ä¾‹å¦‚ï¼Œåº•å±‚é“è·¯äº¤é€šç½‘ç»œæ˜¯ä¸€ä¸ªè‡ªç„¶å›¾ï¼Œå…¶ä¸­æ¯ä¸ªå…³é”®ä½ç½®æ˜¯ä¸€ä¸ªèŠ‚ç‚¹ï¼Œå®ƒçš„äº¤é€šæ•°æ®æ˜¯è¢«è¿ç»­ç›‘æµ‹çš„ã€‚é€šè¿‡å»ºç«‹æœ‰æ•ˆçš„GSTNï¼Œèƒ½å¤Ÿå‡†ç¡®é¢„æµ‹æ•´ä¸ªäº¤é€šçš„ç³»ç»Ÿçš„äº¤é€šçŠ¶æ€ã€‚GSTNçš„æ ¸å¿ƒè§‚ç‚¹æ˜¯ï¼Œ<strong>åŒæ—¶è€ƒè™‘ç©ºé—´ä¾èµ–æ€§å’Œæ—¶é—´ä¾èµ–æ€§ã€‚</strong>
ç›®å‰å¾ˆå¤šæ–¹æ³•ä½¿ç”¨GCNsæ•è·ä¾èµ–æ€§ï¼ŒåŒæ—¶ä½¿ç”¨RNN,æˆ–è€…CNNå»ºæ¨¡æ—¶é—´ä¾èµ–å…³ç³»ã€‚</p>
<h3 id="æ¡†æ¶">2.2 æ¡†æ¶</h3>
<ol type="1">
<li>node_level
è¾“å‡ºç”¨äº<strong>ç‚¹å›å½’å’Œåˆ†ç±»ä»»åŠ¡</strong>ã€‚å›¾å·ç§¯æ¨¡å‹ç›´æ¥ç»™å®šèŠ‚ç‚¹çš„æ½œåœ¨è¡¨ç¤ºï¼Œç„¶åä¸€ä¸ªå¤šå±‚æ„ŸçŸ¥æœºæˆ–è€…softmaxå±‚ç”¨ä½œGCNæœ€åä¸€å±‚ã€‚</li>
<li>Edge-level
è¾“å‡ºä¸<strong>è¾¹åˆ†ç±»å’Œé“¾è·¯é¢„æµ‹ä»»åŠ¡</strong>ç›¸å…³ã€‚ä¸ºäº†é¢„æµ‹ä¸€æ¡è¾¹çš„æ ‡ç­¾æˆ–è€…è¿æ¥å¼ºåº¦ï¼Œé™„åŠ å‡½æ•°ä»å›¾å·ç§¯æ¨¡å‹ä¸­æå–ä¸¤ä¸ªèŠ‚ç‚¹çš„æ½œåœ¨è¡¨ç¤ºä½œä¸ºè¾“å…¥ã€‚</li>
<li>Graph-level
è¾“å‡ºå’Œ<strong>å›¾åˆ†ç±»ä»»åŠ¡</strong>ç›¸å…³ï¼Œæ± åŒ–æ¨¡å—ç”¨äºæ± åŒ–ä¸€ä¸ªå›¾ä¸ºå­å›¾æˆ–è€…å¯¹èŠ‚ç‚¹è¡¨ç¤ºæ±‚å’Œ/æ±‚å¹³å‡ï¼Œä»¥è·å¾—å›¾çº§åˆ«ä¸Šçš„ç´§å‡‘è¡¨ç¤ºã€‚</li>
</ol>
<p>ç«¯åˆ°ç«¯è®­ç»ƒæ¡†æ¶ï¼šGCNå¯ä»¥åœ¨ç«¯åˆ°ç«¯å­¦ä¹ æ¡†æ¶ä¸­è¿›è¡Œ(åŠ)ç›‘ç£æˆ–æ— ç›‘ç£çš„è®­ç»ƒï¼Œå–å†³äºå­¦ä¹ ä»»åŠ¡å’Œæ ‡ç­¾ä¿¡æ¯çš„å¯ç”¨æ€§ã€‚</p>
<ol type="1">
<li>node-level
åŠç›‘ç£åˆ†ç±»ã€‚ç»™å®šä¸€ä¸ªéƒ¨åˆ†èŠ‚ç‚¹è¢«æ ‡è®°è€Œå…¶ä»–èŠ‚ç‚¹æœªæ ‡è®°çš„ç½‘ç»œï¼ŒGCNå¯ä»¥å­¦ä¹ ä¸€ä¸ªé²æ£’çš„æ¨¡å‹ï¼Œæœ‰æ•ˆåœ°è¯†åˆ«æœªæ ‡è®°èŠ‚ç‚¹çš„ç±»æ ‡ç­¾ã€‚ä¸ºæ­¤ï¼Œå¯ä»¥æ„å»ºä¸€ä¸ªç«¯åˆ°ç«¯çš„å¤šåˆ†ç±»æ¡†æ¶ï¼Œé€šè¿‡å åŠ å‡ ä¸ªå›¾å½¢å·ç§¯å±‚ï¼Œç´§è·Ÿç€ä¸€ä¸ªsoftmaxå±‚ã€‚</li>
<li>graph-level
ç›‘ç£åˆ†ç±»ã€‚ç»™å®šä¸€ä¸ªå›¾æ•°æ®é›†ï¼Œå›¾çº§åˆ†ç±»æ—¨åœ¨é¢„æµ‹æ•´ä¸ªå›¾çš„ç±»æ ‡ç­¾(s)ï¼Œç«¯åˆ°ç«¯å­¦ä¹ æ¡†æ¶ï¼Œé€šè¿‡ç»“åˆGCNå’Œæ± åŒ–è¿‡ç¨‹å®ç°ã€‚å…·ä½“çš„ï¼Œé€šè¿‡GCNè·å¾—æ¯ä¸ªå›¾é‡Œæ¯ä¸ªèŠ‚ç‚¹å›ºå®šç»´æ•°çš„ç‰¹å¾è¡¨ç¤ºï¼Œç„¶åï¼Œé€šè¿‡æ± åŒ–æ±‚å›¾ä¸­æ‰€æœ‰èŠ‚ç‚¹çš„è¡¨ç¤ºå‘é‡çš„å’Œï¼Œä»¥å¾—åˆ°æ•´ä¸ªå›¾çš„è¡¨ç¤ºã€‚æœ€åï¼ŒåŠ ä¸Šå¤šå±‚æ„ŸçŸ¥æœºå’Œsoftmaxå±‚ï¼Œå¯ä»¥æ„é€ ä¸€ä¸ªç«¯åˆ°ç«¯çš„å›¾åˆ†ç±»ã€‚å›¾5ï¼ˆaï¼‰å±•ç¤ºäº†è¿™æ ·ä¸€ä¸ªè¿‡ç¨‹ã€‚</li>
<li>æ— ç›‘ç£å›¾åµŒå…¥ã€‚å›¾ä¸­æ²¡æœ‰æ ‡ç­¾æ•°æ®çš„æ—¶å€™ï¼Œå¯ä»¥åœ¨ç«¯åˆ°ç«¯çš„æ¡†æ¶ä¸­ä»¥æ— ç›‘ç£çš„æ–¹å¼å­¦ä¹ ä¸€ç§å›¾åµŒå…¥ã€‚è¿™äº›ç®—æ³•ä»¥ä¸¤ç§æ–¹å¼åˆ©ç”¨è¾¹çº§ä¿¡æ¯ã€‚ä¸€ç§ç®€å•çš„ï¼šåˆ©ç”¨è‡ªç¼–ç æ¡†æ¶ï¼Œç¼–ç å™¨åˆ©ç”¨GCNå°†å›¾åµŒå…¥åˆ°æ½œåœ¨çš„è¡¨ç¤ºä¸­ï¼Œè§£ç å™¨åˆ©ç”¨æ½œåœ¨çš„è¡¨ç¤ºé‡æ„å›¾ç»“æ„ã€‚å¦ä¸€ç§æ–¹å¼ï¼šåˆ©ç”¨è´Ÿé‡‡æ ·æ–¹æ³•ï¼ŒæŠ½å–ä¸€éƒ¨åˆ†èŠ‚ç‚¹å¯¹ä½œä¸ºè´Ÿå¯¹ï¼Œå›¾ä¸­å‰©ä½™çš„èŠ‚ç‚¹å¯¹ä½œä¸ºæ­£å¯¹ï¼Œä¹‹ååˆ©ç”¨é€»è¾‘å›å½’å±‚ï¼Œå½¢æˆä¸€ä¸ªç«¯åˆ°ç«¯çš„å­¦ä¹ æ¡†æ¶ã€‚</li>
</ol>
<h2 id="å›¾å·ç§¯ç½‘ç»œ">3. å›¾å·ç§¯ç½‘ç»œ</h2>
<p>åˆ†ä¸ºä¸¤ç±»</p>
<ol type="1">
<li>Spectral-basedæ–¹æ³•
ä»å›¾ä¿¡å·å¤„ç†çš„è§’åº¦å¼•å…¥æ»¤æ³¢å™¨æ¥å®šä¹‰å›¾å·ç§¯ï¼Œæ­¤ä½¿å›¾å·ç§¯è¢«è§£é‡Šä¸ºä»å›¾ä¿¡å·ä¸­å»é™¤å™ªå£°ã€‚</li>
<li>Spatial-basedçš„æ–¹æ³• å°†å›¾å·ç§¯è¡¨ç¤ºä¸ºæ¥è‡ªé‚»å±…èŠ‚ç‚¹çš„ç‰¹å¾ä¿¡æ¯çš„ç»“åˆ</li>
</ol>
<h3 id="åŸºäºå›¾è°±çš„gcn">3.1 åŸºäºå›¾è°±çš„GCN</h3>
<p><span class="math display">\[
x * G g_{\theta}=U g_{\theta} U^{T} x
\]</span></p>
<p>åŸºäºè°±çš„GCNéƒ½éµå¾ªè¿™ä¸ªå®šä¹‰ï¼Œä¸åŒçš„æ˜¯æ»¤æ³¢å™¨<span
class="math inline">\(g_{\theta}\)</span>çš„é€‰æ‹©ä¸åŒã€‚</p>
<p><strong>ç¼ºé™·</strong>
é¦–å…ˆï¼Œå¯¹å›¾çš„ä»»ä½•æ‰°åŠ¨éƒ½ä¼šå¯¼è‡´ç‰¹å¾åŸºçš„å˜åŒ–ã€‚å…¶æ¬¡ï¼Œå­¦ä¹ çš„è¿‡æ»¤å™¨ä¾èµ–äºä¸åŒé¢†åŸŸï¼Œè¿™æ„å‘³ç€å®ƒä»¬ä¸èƒ½åº”ç”¨äºå…·æœ‰ä¸åŒç»“æ„çš„å›¾ã€‚ç¬¬ä¸‰ï¼Œç‰¹å¾åˆ†è§£éœ€è¦<span
class="math inline">\(O(N^3)\)</span>è®¡ç®—å’Œ<span
class="math inline">\(O(N^2)\)</span>å†…å­˜</p>
<p>è°±æ–¹æ³•çš„ä¸€ä¸ªå¸¸è§ç¼ºç‚¹æ˜¯éœ€è¦å°†æ•´ä¸ªå›¾åŠ è½½åˆ°å†…å­˜ä¸­è¿›è¡Œå›¾å·ç§¯ï¼Œè¿™åœ¨å¤„ç†å¤§å›¾æ—¶æ•ˆç‡ä¸é«˜ã€‚</p>
<h3 id="åŸºäºç©ºé—´çš„gcn">3.2 åŸºäºç©ºé—´çš„GCN</h3>
<p>åˆ†ä¸ºåŸºäºå¾ªç¯å’ŒåŸºäºç»„åˆçš„GCNsã€‚åŸºäºå¾ªç¯çš„GCNä½¿ç”¨ä¸€ä¸ªç›¸åŒçš„GCLä¸ªæ›´æ–°éšå«è¡¨ç¤ºï¼ŒåŸºäºç»„åˆGCNåˆ™ä½¿ç”¨ä¸åŒçš„GCLæ›´æ–°éšå«è¡¨ç¤ºã€‚
<img src="https://s2.loli.net/2022/02/08/hTzZ3KFHLXjU6Wf.png" /></p>
<p><strong>åŸºäºå¾ªç¯çš„ç©ºé—´GCNs</strong>
åŸºäºé€’å½’çš„æ–¹æ³•çš„ä¸»è¦æ€æƒ³æ˜¯é€’å½’åœ°æ›´æ–°èŠ‚ç‚¹çš„æ½œåœ¨è¡¨ç¤ºï¼Œç›´åˆ°è¾¾åˆ°ç¨³å®šçš„ä¸åŠ¨ç‚¹ã€‚é€šè¿‡å¯¹å¾ªç¯å‡½æ•°æ–½åŠ çº¦æŸã€ä½¿ç”¨é—¨å¾ªç¯å•å…ƒæ¶æ„ã€å¼‚æ­¥å’Œéšæœºæ›´æ–°èŠ‚ç‚¹æ½œåœ¨è¡¨ç¤ºæ¥å®ç°ã€‚</p>
<p><strong>åŸºäºç»„åˆçš„ç©ºé—´GCNs</strong>
åŸºäºç»„åˆçš„æ–¹æ³•é€šè¿‡å åŠ å¤šä¸ªå›¾çš„å·ç§¯å±‚æ¥æ›´æ–°èŠ‚ç‚¹çš„è¡¨ç¤ºã€‚</p>
<h3 id="å›¾æ± æ¨¡å—">3.3 å›¾æ± æ¨¡å—</h3>
<h3 id="åŸºäºå…‰è°±å’Œç©ºé—´çš„gcnsçš„å¯¹æ¯”">3.4 åŸºäºå…‰è°±å’Œç©ºé—´çš„GCNsçš„å¯¹æ¯”</h3>
<ol type="1">
<li>æ•ˆç‡
åŸºäºå…‰è°±çš„æ–¹æ³•çš„è®¡ç®—é‡ä¼šéšç€å›¾çš„å¤§å°æ€¥å‰§å¢åŠ ï¼Œå› ä¸ºæ¨¡å‹éœ€è¦åŒæ—¶è®¡ç®—ç‰¹å¾å‘é‡æˆ–è€…åŒæ—¶å¤„ç†å¤§å›¾ï¼Œè¿™å°±ä½¿å¾—æ¨¡å‹å¾ˆéš¾å¯¹å¤§å›¾è¿›è¡Œå¹¶è¡Œå¤„ç†æˆ–ç¼©æ”¾ã€‚åŸºäºç©ºé—´çš„å›¾æ–¹æ³•ç”±äºç›´æ¥å¯¹å›¾åŸŸçš„é‚»å±…èŠ‚ç‚¹è¿›è¡Œèšåˆï¼Œæ‰€ä»¥æœ‰æ½œåŠ›å¤„ç†å¤§å›¾ï¼Œæ–¹æ³•æ˜¯å¯¹ä¸€ä¸ªbatchæ•°æ®è®¡ç®—è€Œä¸æ˜¯åœ¨æ•´ä¸ªå›¾ä¸Šè®¡ç®—ã€‚å¦‚æœé‚»å±…èŠ‚ç‚¹çš„æ•°é‡å¢åŠ ï¼Œèƒ½å¤Ÿé€šè¿‡é‡‡æ ·æŠ€æœ¯æé«˜æ•ˆç‡ã€‚</li>
<li>é€šç”¨æ€§
åŸºäºå…‰è°±çš„å›¾æ–¹æ³•å‡è®¾å›¾æ˜¯å›ºå®šçš„ï¼Œå› æ­¤å¯¹æ–°çš„æˆ–è€…ä¸åŒçš„å›¾æ³›åŒ–æ€§èƒ½å¾ˆå·®ã€‚åŸºäºç©ºé—´çš„æ–¹æ³•åœ¨æ¯ä¸ªèŠ‚ç‚¹ä¸Šè¿›è¡Œå±€éƒ¨å›¾å·ç§¯ï¼Œæƒå€¼å¯ä»¥å¾ˆå®¹æ˜“åœ°åœ¨ä¸åŒåœ°ä½ç½®å’Œç»“æ„ä¹‹é—´å…±äº«ã€‚</li>
<li>çµæ´»æ€§
åŸºäºè°±çš„æ¨¡å‹åªé€‚ç”¨äºæ— å‘å›¾ï¼Œè°±æ–¹æ³•ç”¨äºæœ‰å‘å›¾çš„å”¯ä¸€æ–¹æ³•æ˜¯uå°†æœ‰å‘å›¾è½¬æ¢ä¸ºæ— å‘å›¾ï¼Œå› ä¸ºæ²¡æœ‰æœ‰å‘å›¾çš„æ‹‰æ™®æ‹‰æ–¯çŸ©é˜µæ˜ç¡®çš„å®šä¹‰ã€‚åŸºäºç©ºé—´çš„æ¨¡å‹å¯ä»¥å°†è¾“å…¥åˆå¹¶åˆ°èšåˆå‡½æ•°ä¸­ï¼Œæ‰€ä»¥åœ¨å¤„ç†å¤šæºè¾“å…¥åƒæ˜¯è¾¹ç‰¹å¾ï¼Œè¾¹æ–¹å‘ä¸Šæ›´çµæ´»ã€‚</li>
</ol>
<p>å› æ­¤ï¼Œè¿‘å¹´æ¥ï¼ŒåŸºäºç©ºé—´çš„æ–¹æ³•æ›´å—å…³æ³¨ã€‚</p>
<h2 id="è¶…gcnç½‘ç»œ">4. è¶…GCNç½‘ç»œ</h2>
<p>GAN GAT GGN GSTN</p>
<h3 id="å›¾æ³¨æ„åŠ›ç½‘ç»œgan">4.1 å›¾æ³¨æ„åŠ›ç½‘ç»œGAN</h3>
<ol type="1">
<li>GAT</li>
<li>GAAN</li>
<li>GAM</li>
<li>æ³¨æ„åŠ›æ¸¸èµ°</li>
<li>æ·±åº¦æ¸¸èµ°</li>
</ol>
<p>æ³¨æ„åŠ›æœºåˆ¶å¯¹GNNçš„è´¡çŒ®åˆ†ä¸ºä¸‰ä¸ªæ–¹é¢ï¼Œåœ¨èšåˆç‰¹å¾ä¿¡æ¯çš„æ—¶å€™å¯¹ä¸åŒçš„é‚»å±…èŠ‚ç‚¹åˆ†é…ä¸åŒçš„æƒå€¼ï¼Œæ ¹æ®æ³¨æ„åŠ›æƒé‡é›†æˆå¤šä¸ªæ¨¡å‹ï¼Œä½¿ç”¨æ³¨æ„åŠ›æƒé‡æŒ‡å¯¼éšæœºæ¸¸èµ°ã€‚å°½ç®¡å°†GATå’ŒGAANå½’ä¸ºå›¾çš„æ³¨æ„ç½‘ç»œçš„èŒƒç•´ï¼Œå®ƒä»¬ä¹ŸåŒæ—¶æ˜¯åŸºäºç©ºé—´çš„GCNã€‚GATå’ŒGAANçš„ä¼˜ç‚¹æ˜¯å¯ä»¥è‡ªé€‚åº”å­¦ä¹ é‚»å±…çš„é‡è¦æ€§æƒé‡ï¼Œå¦‚å›¾6æ‰€ç¤ºã€‚ä½†æ˜¯ï¼Œç”±äºå¿…é¡»è®¡ç®—æ¯å¯¹é‚»å±…ä¹‹é—´çš„æ³¨æ„åŠ›æƒé‡ï¼Œè®¡ç®—æˆæœ¬å’Œå†…å­˜æ¶ˆè€—è¿…é€Ÿå¢åŠ ã€‚</p>
<h3 id="å›¾è‡ªç¼–ç ">4.2 å›¾è‡ªç¼–ç </h3>
<p>ç½‘ç»œåµŒå…¥è‡´åŠ›äºä½¿ç”¨ç¥ç»ç½‘ç»œæ¶æ„å°†<strong>ç½‘ç»œé¡¶ç‚¹åœ¨ä½ç»´å‘é‡ç©ºé—´è¿›è¡Œè¡¨ç¤º</strong>ï¼Œå›¾è‡ªç¼–ç æ˜¯ç½‘ç»œåµŒå…¥çš„ä¸€ç§ç±»å‹ã€‚å…¸å‹åšæ³•æ˜¯åˆ©ç”¨å¤šå±‚æ„ŸçŸ¥æœºä½œä¸ºç¼–ç å™¨ï¼Œè·å¾—èŠ‚ç‚¹åµŒå…¥ï¼Œç„¶åè§£ç å™¨æ®æ­¤é‡æ„èŠ‚ç‚¹çš„é‚»åŸŸç»Ÿè®¡ä¿¡æ¯ï¼Œå¦‚æ­£ç‚¹æ€äº’ä¿¡æ¯(positive
pointwise mutual information,
PPMI)æˆ–ä¸€é˜¶å’ŒäºŒé˜¶è¿‘ä¼¼ã€‚è¿‘æœŸï¼Œç ”ç©¶å‘˜æ¢ç´¢å°†GCN[ä½œä¸ºç¼–ç å™¨,è®¾è®¡å›¾è‡ªç¼–ç å™¨çš„æ—¶å€™æˆ–ç»“åˆHCNä¸GANï¼Œæˆ–ç»“åˆGANä¸LSTMã€‚</p>
<p>è¿™äº›æ–¹æ³•éƒ½å­¦ä¹ èŠ‚ç‚¹åµŒå…¥ï¼Œä½†æ˜¯DNGRå’ŒSDNEåªç»™å®šæ‹“æ‰‘ç»“æ„ï¼Œè€ŒGAEã€ARGAã€NetRAå’ŒDRNEä¸ä»…ç»™å®šæ‹“æ‰‘ç»“æ„è€Œä¸”ç»™å®šèŠ‚ç‚¹å†…å®¹ç‰¹æ€§ã€‚å›¾è‡ªç¼–ç çš„ä¸€ä¸ªæŒ‘æˆ˜æ˜¯é‚»æ¥çŸ©é˜µçš„ç¨€ç–æ€§ï¼Œä½¿è§£ç å™¨çš„æ­£é¡¹æ•°è¿œå°‘äºè´Ÿé¡¹æ•°ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼ŒDNGRé‡æ„äº†ä¸€ä¸ªæ›´ç´§å¯†çš„çŸ©é˜µå³PPMIçŸ©é˜µï¼ŒSDNEå¯¹é‚»æ¥çŸ©é˜µçš„é›¶é¡¹è¿›è¡Œäº†æƒ©ç½šï¼ŒGAEå¯¹é‚»æ¥çŸ©é˜µä¸­çš„é¡¹è¿›è¡Œäº†åŠ æƒï¼ŒNetRAå°†å›¾çº¿æ€§åŒ–ä¸ºåºåˆ—ã€‚</p>
<h3 id="å›¾ç”Ÿæˆç½‘ç»œ">4.3 å›¾ç”Ÿæˆç½‘ç»œ</h3>
<p>å›¾ç”Ÿæˆç½‘ç»œï¼ˆGGNï¼‰çš„ç›®æ ‡æ˜¯ï¼Œåœ¨ç»™å®šä¸€ç»„è§‚å¯Ÿåˆ°çš„å›¾çš„å‰æä¸‹ç”Ÿæˆå›¾ã€‚å¾ˆå¤šå›¾ç”Ÿæˆæ–¹æ³•æ˜¯ä¸ç‰¹å®šé¢†åŸŸç›¸å…³çš„ï¼Œä¾‹å¦‚ï¼Œåˆ†å­å›¾ç”Ÿæˆï¼Œä¸€äº›æ–¹æ³•æ˜¯å¯¹åˆ†å­å›¾è¿›è¡Œå­—ç¬¦ä¸²è¡¨ç¤ºå»ºæ¨¡ï¼Œå«åšSMILESï¼Œè‡ªç„¶è¯­è¨€å¤„ç†ï¼Œä»¥ç»™å®šçš„å¥å­ä¸ºæ¡ä»¶ç”Ÿæˆè¯­ä¹‰å›¾æˆ–è€…çŸ¥è¯†å›¾ã€‚æœ€è¿‘ï¼Œæå‡ºäº†ä¸€äº›ç»Ÿä¸€çš„ç”Ÿæˆæ–¹æ³•ï¼Œä¸€äº›æ–¹æ³•å°†ç”Ÿæˆè¿‡ç¨‹çœ‹ä½œäº¤æ›¿ç”ŸæˆèŠ‚ç‚¹å’Œè¾¹ï¼Œå…¶ä»–çš„æ–¹æ³•åˆ©ç”¨ç”Ÿæˆå¯¹æŠ—è®­ç»ƒã€‚GGNä¸­çš„æ–¹æ³•æˆ–è€…åˆ©ç”¨GCNä½œä¸ºæ„å»ºå—ï¼Œæˆ–è€…ä½¿ç”¨ä¸åŒçš„æ¶æ„ã€‚</p>
<p>å¯¹ç”Ÿæˆçš„å›¾è¿›è¡Œè¯„ä¼°ä»ç„¶æ˜¯ä¸€ä¸ªéš¾é¢˜ã€‚ä¸äººå·¥åˆæˆå›¾åƒæˆ–è€…éŸ³é¢‘ä¸åŒï¼Œä»–ä»¬èƒ½å¤Ÿç›´æ¥è¢«äººç±»ä¸“å®¶è¯„ä¼°ï¼Œç”Ÿæˆçš„å›¾çš„è´¨é‡å¾ˆéš¾ç›´è§‚æ£€æµ‹ã€‚MolGANå’ŒDGMGåˆ©ç”¨å¤–éƒ¨çŸ¥è¯†æ¥è¯„ä¼°ç”Ÿæˆåˆ†å­å›¾çš„æœ‰æ•ˆæ€§ã€‚GraphRNNå’ŒNetGANé€šè¿‡å›¾ç»Ÿè®¡ä¿¡æ¯(å¦‚èŠ‚ç‚¹åº¦)è¯„ä¼°ç”Ÿæˆçš„å›¾å½¢ã€‚DGMGå’ŒGraphRNNä¾æ¬¡ç”ŸæˆèŠ‚ç‚¹å’Œè¾¹ç¼˜ï¼ŒMolGANå’ŒNetGANåŒæ—¶ç”ŸæˆèŠ‚ç‚¹å’Œè¾¹ç¼˜ã€‚æ ¹æ®[68]ï¼Œå‰ä¸€ç§æ–¹æ³•çš„ç¼ºç‚¹æ˜¯å½“å›¾å˜å¤§æ—¶ï¼Œå¯¹é•¿åºåˆ—å»ºæ¨¡æ˜¯ä¸ç°å®çš„ã€‚åä¸€ç§æ–¹æ³•çš„æŒ‘æˆ˜æ˜¯å¾ˆéš¾æ§åˆ¶å›¾çš„å…¨å±€å±æ€§ã€‚æœ€è¿‘ä¸€ç§æ–¹æ³•[68]é‡‡ç”¨å˜åˆ†è‡ªç¼–ç å™¨é€šè¿‡ç”Ÿæˆé‚»æ¥çŸ©é˜µæ¥ç”Ÿæˆå›¾å½¢ï¼Œå¼•å…¥æƒ©ç½šé¡¹æ¥è§£å†³æœ‰æ•ˆæ€§çº¦æŸã€‚ç„¶è€Œï¼Œç”±äºå…·æœ‰nä¸ªèŠ‚ç‚¹çš„å›¾çš„è¾“å‡ºç©ºé—´ä¸º<span
class="math inline">\(n^2\)</span> ï¼Œè¿™äº›æ–¹æ³•éƒ½ä¸èƒ½æ‰©å±•åˆ°å¤§å‹å›¾ã€‚</p>
<h3 id="å›¾æ—¶ç©ºç½‘ç»œ">4.4 å›¾æ—¶ç©ºç½‘ç»œ</h3>
<p>å›¾æ—¶ç©ºç½‘ç»œåŒæ—¶æ•è·æ—¶ç©ºå›¾çš„æ—¶ç©ºä¾èµ–æ€§ã€‚æ—¶ç©ºå›¾å…·æœ‰å…¨å±€å›¾ç»“æ„ï¼Œæ¯ä¸ªèŠ‚ç‚¹çš„è¾“å…¥éšæ—¶é—´å˜åŒ–ã€‚ä¾‹å¦‚ï¼Œåœ¨äº¤é€šç½‘ç»œä¸­ï¼Œå°†æ¯ä¸ªä¼ æ„Ÿå™¨ä½œä¸ºä¸€ä¸ªèŠ‚ç‚¹ï¼Œè¿ç»­è®°å½•æŸæ¡é“è·¯çš„äº¤é€šé€Ÿåº¦ï¼Œå…¶ä¸­äº¤é€šç½‘ç»œçš„è¾¹ç”±ä¼ æ„Ÿå™¨å¯¹ä¹‹é—´çš„è·ç¦»å†³å®šã€‚å›¾æ—¶ç©ºç½‘ç»œçš„ç›®æ ‡æ˜¯é¢„æµ‹æœªæ¥çš„èŠ‚ç‚¹å€¼æˆ–æ ‡ç­¾ï¼Œæˆ–é¢„æµ‹æ—¶ç©ºå›¾æ ‡ç­¾ã€‚æœ€è¿‘çš„ç ”ç©¶æ¢ç´¢äº†å•ç‹¬ä½¿ç”¨GCNs[72]ï¼Œç»“GCNsä¸RNN[70]æˆ–CNN[71]ï¼Œä»¥åŠä¸€ç§ä¸ºå›¾ç»“æ„å®šåˆ¶çš„å¾ªç¯æ¶æ„[73]ã€‚</p>
<p>DCRNNç”±äºåˆ©ç”¨äº†å¾ªç¯ç½‘ç»œæ¶æ„èƒ½å¤Ÿå¤„ç†é•¿æ—¶é—´ä¾èµ–å…³ç³»ã€‚è™½ç„¶CNN-GCNæ¯”DCRNNç®€å•ï¼Œä½†æ˜¯ç”±äºä»–é¦–å…ˆå®ç°äº†1D-CNNï¼Œæ‰€ä»¥åœ¨å¤„ç†æ—¶ç©ºå›¾ä¸Šæ›´åŠ é«˜æ•ˆã€‚ST-GCNå°†æ—¶é—´æµä½œä¸ºå›¾çš„è¾¹ï¼Œä½¿é‚»æ¥çŸ©é˜µçš„å¤§å°å‘ˆäºŒæ¬¡å¢é•¿ã€‚ä¸€æ–¹é¢ï¼Œå¢åŠ äº†å›¾å·ç§¯å±‚çš„è®¡ç®—æˆæœ¬ã€‚å¦ä¸€æ–¹é¢ï¼Œä¸ºäº†æ•è·é•¿æœŸä¾èµ–å…³ç³»ï¼Œå›¾å·ç§¯å±‚å¿…é¡»å¤šæ¬¡å åŠ ã€‚Structural-RNNé€šè¿‡åœ¨ç›¸åŒçš„è¯­ä¹‰ç»„å…±äº«ç›¸åŒçš„RNNæé«˜äº†æ¨¡å‹çš„æœ‰æ•ˆæ€§ã€‚ä½†æ˜¯ï¼Œéœ€è¦äººç±»å…ˆéªŒçŸ¥è¯†æ¥åˆ’åˆ†è¯­ä¹‰ç»„ã€‚</p>
]]></content>
      <categories>
        <category>Survey</category>
      </categories>
      <tags>
        <tag>GNN</tag>
      </tags>
  </entry>
  <entry>
    <title>æœ€è¿‘çš„ä¸€äº›è¿›å±• 2022.02</title>
    <url>/2022/02/08/thoughts-01/</url>
    <content><![CDATA[<h2 id="ç®€å•è®°å½•ä¸€ä¸‹æœ€è¿‘çš„è¿›å±•">1. ç®€å•è®°å½•ä¸€ä¸‹æœ€è¿‘çš„è¿›å±•</h2>
<p>ä¸Šæ¬¡å†™åšå®¢ä¹Ÿæ˜¯å¥½ä¹…ä¹‹å‰äº†ï¼Œç ”ç©¶ç”Ÿåˆšå¼€å§‹çš„æ—¶å€™è¿˜å…´å†²å†²çš„ï¼Œå¸Œæœ›å…»æˆå†™åšå®¢çš„å¥½ä¹ æƒ¯ï¼Œè®°å½•ä¸€ä¸‹è‡ªå·±çš„æˆé•¿ï¼Œä¹Ÿè®°å½•ä¸€ä¸‹æ—¥å¸¸å­¦ä¹ ç”Ÿæ´»è¸©è¿‡çš„å‘ã€‚
ä½†æ˜¯éª¨å­é‡Œçš„æ‡’æƒ°è¿˜æ˜¯æŠµä¸ä½ï¼Œå…´èµ·çš„çƒ­æƒ…åœ¨å†™äº†å‡ ç¯‡ä»¥åå°±è¢«æµ‡ç­äº†ã€‚
å…¶å®æ„Ÿè§‰è¿™ä¸ªä¸œè¥¿å†™èµ·æ¥æˆæœ¬ä¹Ÿæ²¡æœ‰é‚£ä¹ˆé«˜ã€‚é…ç½®ç¯å¢ƒä¹Ÿæ˜¯è®¡ç®—æœºäººå¸¸å¸¸è¦è¹šè¿‡çš„æµ‘æ°´ï¼Œåˆ°å†™çš„æ—¶å€™ï¼Œçœ‹ç€è‡ªå·±çš„æ–‡å­—è¢«æ¸²æŸ“æˆç½‘é¡µï¼Œç¨å¾®æ„Ÿå—äº†ä¸€ä¸‹å‰ç«¯äººçš„å¿«ä¹äº†ã€‚</p>
<p>æœ€è¿‘å‡ ä¸ªæœˆç»å†çš„äº‹æƒ…å¯èƒ½æ¯”æ•´ä¸ªç ”ç©¶ç”Ÿé˜¶æ®µç»å†çš„éƒ½è¦å¤šäº†ã€‚å–œå¿§éƒ½æœ‰ï¼Œè¿™é‡Œå€’ä¸çŸ¥ä»ä½•å¼€å¤´ï¼Œä¹Ÿå°±é¡ºç€æ—¶é—´è®²ä¸€ä¸‹å§ã€‚</p>
<p>é¦–å…ˆæ˜¯å®ä¹ è½¬æ­£ï¼Œæ„Ÿè§‰å…¶å®æœ‰ç‚¹æƒŠé™©ï¼Œç»„é‡Œé¢çš„hcå¤§æŠµæ˜¯ä¸å¤šçš„ï¼Œæˆ‘åˆæ˜¯é åå‡ ä¸ªæèµ·ç­”è¾©çš„ï¼ŒæŒ‰é“ç†å…è®¸ä½ æèµ·ç­”è¾©å…¶å®å°±æ˜¯é»˜è®¤èƒ½è¿‡çš„ï¼Œä½†æ˜¯ä»Šå¹´äº’è”ç½‘çš„å½¢åŠ¿ååˆ†ä¸¥å³»ï¼Œ
å­—èŠ‚å¹¶æ²¡æœ‰é‡‡å–æ‰©æ‹›ï¼Œè€Œæ˜¯ä½¿ç”¨äº†å°‘é‡hcæé«˜äººå‡packageçš„ç­–ç•¥ã€‚å½“æ—¶å…¶å®æˆ‘ä¹Ÿæ˜¯ä¸çŸ¥é“æœ‰è¿™ä¸ªæƒ…å†µï¼Œåœ¨8æœˆä¸­æ—¬æ…¢ååçš„æäº¤äº†ç­”è¾©ï¼Œå…¶å®å½“æ—¶æˆ‘å¹¶æ²¡æœ‰ä»€ä¹ˆæ˜æ˜¾çš„äº§å‡ºï¼Œåªæ˜¯è‡ªå·±æ¢ç´¢äº†ä¸€äº›NASåœ¨å¹¿å‘Šé‡Œé¢çš„åº”ç”¨æ–¹å‘ï¼Œæˆ‘ç†è§£æˆ‘çš„offerå³ä¾¿èƒ½å¤Ÿæ‹¿åˆ°ï¼Œå¯èƒ½ä¹Ÿåªæ˜¯ç»„å†…çš„ä¸€ä¸ªé—¨æ§›æ°´å¹³ï¼ˆå°SPï¼Ÿï¼‰ã€‚å½“æ—¶è¿˜æ˜¯å¿ƒæœ‰ä¸ç”˜çš„ï¼Œè§‰å¾—è‡ªå·±èƒ½åŠ›ä¸æ­¢äºæ­¤ï¼Œå› æ­¤åè€Œå¯¹è¿™ä¸ªofferæœŸæœ›ä¸å¤§ï¼Œä½†æ˜¯æœ€åé€‰æ‹©å­—èŠ‚åè€Œæœ‰ç‚¹é˜´å·®é˜³é”™äº†ã€‚å½“ç„¶å³ä¾¿å¦‚æ­¤ï¼Œè¿™ä¸ªofferä¹Ÿæ˜¯å°½åŠ›è¦æ‹¿åˆ°ï¼Œç¨³å®šä¸€ä¸‹å†›å¿ƒã€‚å½“æ—¶å·²ç»é¢è¿‡äº†è™¾çš®ï¼Œä¸€å¿ƒæƒ³runå»sgã€‚è¿™ä¸ªåé¢å†è°ˆäº†ã€‚ç­”è¾©æœ‰æƒŠæ— é™©ï¼Œå‘wqå’Œsxä¸¤ä½å¤§ä½¬è¿›è¡Œæ±‡æŠ¥ï¼Œå‹åŠ›å±å®æœ‰ç‚¹å¤§ï¼Œæ„Ÿè§‰è¯´è¯æœ‰ç‚¹ç»“å·´ï¼Œè¿™ä¸ªä¹Ÿæ˜¯ä¸ªäººé—®é¢˜ï¼Œä»å°åˆ°å¤§ï¼Œåœ¨é‡è¦åœºåˆå±•ç¤ºè‡ªå·±æ€»æ˜¯ç´§å¼ åˆ°ä¸è¡Œã€‚</p>
<p>ç¬¬äºŒä»¶äº‹æƒ…ï¼Œå°±æ˜¯çˆ¸çˆ¸çš„ç—…æƒ…ã€‚çˆ¸çˆ¸å½“æ—¶åœ¨ä¸‰æœˆä»½çš„æ—¶å€™æ£€æŸ¥å‡ºè„‘éƒ¨åŸºåº•å·¨å¤§åŠ¨è„‰ç˜¤ï¼ŒåŸºæœ¬ä¸Šä¹Ÿå±äºç–‘éš¾æ‚ç—‡äº†ï¼Œå‘ç—…ç‡æä½ï¼Œä½†æ˜¯å…¨å›½æ²»å¥½çš„ä¾‹å­ä¹Ÿä¸å¤šã€‚ä¸‰æœˆä»½ç”±äºä¸˜è„‘å‡ºè¡€ï¼Œä»–ä½†æ˜¯çš„è¯­è¨€è¡¨è¾¾èƒ½åŠ›å·²ç»å—åˆ°äº†å¾ˆå¤§çš„å½±å“ï¼Œæ£€æµ‹å‡ºæ¥åŠ¨è„‰ç˜¤å¯¹æˆ‘ä»¬å®¶ç€å®æ˜¯ä¸ªå·¨å¤§çš„æ‰“å‡»ã€‚å½“æ—¶åŒ»ç”Ÿä¹Ÿçœ‹ä¸æ¸…ï¼Œä¸˜è„‘å‡ºè¡€åŠå¹´ä»¥åï¼Œä¹Ÿå°±æ˜¯8æœˆåˆåˆ°ä¸­æ—¬çš„æ—¶å€™ï¼Œæ­£å¥½æˆ‘è¿˜åœ¨ä¸Šæµ·å®ä¹ ï¼Œçˆ¸å¦ˆå°±æ¥ä¸Šæµ·çš„åå±±åŒ»é™¢ï¼Œæ‰¾åˆ°äº†tylä¸»ä»»ï¼Œä¹Ÿæ‰¾äº†å¾ˆå¤šå…³ç³»æ‰“äº†æ‹›å‘¼ï¼Œä½é™¢æ£€æŸ¥ï¼Œå‡†å¤‡è¯´å¦‚æœèƒ½åšæ‰‹æœ¯ï¼Œè¿˜æ˜¯å‡†å¤‡å…ˆæŠŠè¿™ä¸ªåŠ¨è„‰ç˜¤ç»™è§£å†³æ‰ã€‚ä½†æ˜¯æ£€æŸ¥ç»“æœä»¤äººæ³„æ°”ï¼ŒåŒ»ç”ŸæŠŠæˆ‘å’Œå¦ˆå¦ˆæ‹‰åˆ°ä¸€ä¸ªå•ç‹¬çš„ä¼šè°ˆå®¤ï¼Œå‘¨å›´å…¨æ˜¯ç›‘æ§ï¼Œè·Ÿæˆ‘ä»¬è®²äº†ä¸€ä¸‹çˆ¸çˆ¸çš„æƒ…å†µï¼ŒåŸºæœ¬ä¸Šå·²ç»åˆ°äº†åšä¸äº†æ‰‹æœ¯çš„æ—¶å€™ï¼Œå½“æ—¶å‘ç°çš„æ—¶å€™å°±å·²ç»éå¸¸å¤§ï¼Œåˆ°ç°åœ¨è¿™ä¸ªç˜¤è¿›ä¸€æ­¥æ‰©å¤§ï¼ŒåŒ»ç”Ÿè¯´åªæœ‰ä¸€åŠçš„æŠŠæ¡èƒ½å¤Ÿåˆ‡é™¤ï¼Œå¦å¤–ä¸€åŠäººå°±æ²¡äº†ï¼Œè€Œä¸”å³ä¾¿æ‰‹æœ¯æˆåŠŸï¼ŒçŸ­æœŸå¹¶æ²¡æœ‰å¯¹ç—…äººæ˜æ˜¾å¸®åŠ©ï¼Œæˆ‘ä»¬è€ƒè™‘äº†å¾ˆä¹…ï¼Œæœ€ç»ˆè¿˜æ˜¯å†³å®šæ¥å—ä¿å®ˆæ²»ç–—ï¼Œå›åˆ°äº†åˆè‚¥ã€‚ä¹‹åæˆ‘å¦ˆå°±æƒ³æ‰¾ä¸ªè½»æ¾ä¸€ç‚¹çš„å·¥ä½œï¼Œåœ¨å®¶çœ‹ç€ç…§é¡¾ä¸€ä¸‹æˆ‘çˆ¸ï¼Œæˆ‘å°å§¨å°±è®©ä»–ä»¬ä¿©å›æ¡åŸï¼Œç®¡ä¸€ä¸‹ä»“åº“çš„è®°è´¦å·¥ä½œï¼Œæ¯å¤©ä¹Ÿå°±å‡ ä¸ªå°æ—¶ã€‚10æœˆåˆå›å®¶çš„æ—¶å€™è¿˜æ˜¯æŒºå¥½çš„ï¼Œæˆ‘çˆ¸å¤©å¤©è¿˜è¦å»ä¸Šç­ï¼Œè¯´ä»–èº«ä½“å¥½å¾—å¾ˆï¼ˆæˆ‘ä¸çŸ¥é“ä»–æ˜¯ç›²ç›®è‡ªä¿¡è¿˜æ˜¯ç›²ç›®ä¹è§‚äº†ï¼Œä¸€èˆ¬äººæ„Ÿè§‰ä¸æŠ‘éƒå·²ç»å¾ˆéš¾äº†ï¼Œä»–è·Ÿæ²¡äº‹äººä¸€æ ·ï¼‰ã€‚</p>
<p>ä½†æ˜¯ä»–çš„ç›²ç›®ä¹è§‚æ„Ÿè§‰æ˜¯ä»–ç¬¬äºŒæ¬¡å‘ç—…çš„é‡è¦åŸå› ä¹‹ä¸€ï¼Œä»–æ¯å¤©è¿˜è¦å‡ºå»æ•£å¥½å‡ ä¸ªå°æ—¶çš„æ­¥ï¼Œä»…ä»…ä¸€ä¸ªå¤šæœˆä»¥åï¼Œä»–å°±ç¬¬äºŒæ¬¡å‡ºç°äº†é—®é¢˜ï¼Œå¦‚åŒ»ç”Ÿæ‰€è¯´ï¼ŒåŠ¨è„‰ç˜¤å¹¶ä¸æ˜¯ä»–æœ€å¤§çš„é£é™©ï¼Œè„‘è¡€æ “æ‰æ˜¯ï¼Œè€Œä»–è¡€æ “çš„åœ°æ–¹ï¼Œæ›´æ˜¯äººä½“æœ€é‡è¦çš„åœ°æ–¹â€”â€”è„‘å¹²ã€‚11æœˆå°¾ï¼Œä»–å‡ºå»æ•£æ­¥ï¼Œå›æ¥å°±è¯´è„‘å­ä¸å¯¹åŠ²ï¼Œä»…ä»…ä¸€ä¸ªå¤šå°æ—¶ä»¥åï¼Œäººå°±å·²ç»ç«™ä¸èµ·æ¥è¯´ä¸äº†è¯äº†ï¼Œæˆ‘å¦ˆæ‰“ç”µè¯ç»™æˆ‘è¯´ä»–å‘ç—…äº†ï¼Œæˆ‘ç»™ä»–å«äº†æ»´æ»´ï¼Œå¸æœºåœ¨é—¨å£ç£¨è¹­åŠå¤©è¿˜æ˜¯æ‹’æ¥äº†ï¼Œè¿˜æ˜¯æˆ‘å°å§¨å¤«ä»å®¶é‡Œèµ¶è¿‡æ¥æŠŠä»–èƒŒä¸Šäº†è½¦ï¼Œè·¯ä¸Šäº¤ç»™äº†120ã€‚ä½†æ˜¯åˆ°åŒ»é™¢ï¼ŒåŒ»ç”Ÿè¯´æ²»ä¸äº†ï¼Œè½¬é™¢å»åˆè‚¥å§ï¼Œåˆæ€¥æ€¥å¿™å¿™å¾€åˆè‚¥é€ï¼Œè·¯ä¸Šæ€¥æ€§èƒƒæºƒç–¡å·²ç»åœ¨åè¡€äº†ï¼Œå‡ ä¸ªäº²æˆšèµ¶åˆ°çœç«‹åŒ»é™¢å—é™¢ï¼Œç›´æ¥é€è¿›äº†ICUï¼Œæˆ‘ä¹Ÿåœ¨å½“å¤©åŠå¤œåè½¦å›äº†å®¶ã€‚ICUä¸å…è®¸å®¶å±æ¢è§†ï¼Œæ¯å¤©å°±å»é‚£ä¸ªå°é—¨å£ï¼Œç­‰ç­‰åŒ»ç”Ÿå«ä½ ä¸€ä¸‹ï¼Œäº†è§£ä¸€ä¸‹ç—…æƒ…ï¼Œè¿™æ—¶å€™åŒ»ç”Ÿå·²ç»è¯´äº†ï¼Œç‰‡å­æ˜¾ç¤ºè„‘å¹²å°è„‘åŸºæœ¬ä¸Šå…¨éƒ¨å µæ­»ï¼Œå¦‚æœç†¬è¿‡è¿™å‡ å¤©ï¼Œå‡ºå»ä¹Ÿæ˜¯è·Ÿæ¤ç‰©äººä¸€æ ·ï¼Œèƒ½ä¸èƒ½é†’çœ‹é€ åŒ–ã€‚é¡ºåˆ©ç†¬è¿‡äº†ICUçš„å‡ å¤©ï¼Œè®©æ‹‰å‡ºå»å»å…¶ä»–åŒ»é™¢åšåº·å¤æ²»ç–—ï¼Œå‡ºæ¥çš„æ—¶å€™å‡ ä¸ªäººéƒ½å“­æˆäº†æ³ªäººã€‚ä½†æ˜¯ç”Ÿæ´»è¿˜å¾—ç»§ç»­ï¼Œåˆ°ç°åœ¨è¿˜åœ¨å‡ ä¸ªåŒ»é™¢æ¥å›è½¬ï¼Œæˆ‘å¦ˆè·Ÿç€åé¢ç…§é¡¾ç€ï¼Œè¯·ä¸€ä¸ªæŠ¤å·¥éƒ½ä¸å¤Ÿï¼Œä½•å†µè¿˜è¯·ä¸åˆ°è´Ÿè´£çš„åˆé€‚çš„æŠ¤å·¥ã€‚è¿‡å¹´è¿™å‡ å¤©æˆ‘å›å®¶ï¼Œåƒä½éƒ½æ˜¯åœ¨åŒ»é™¢çš„ï¼Œä»–ç°åœ¨è¿˜æ˜¯æ²¡æœ‰ä»€ä¹ˆå¥½è½¬ï¼Œä½†æ˜¯åœ¨åŒ»é™¢è¿™ä¹ˆä¹…ï¼Œæˆ‘å¦ˆä¹Ÿç´¯æ­»äº†ï¼Œå¶å°”æˆ‘å§æ›¿å¥¹ä¸€ä¸‹ï¼Œä½†æ˜¯è¯´å®è¯åŒ»é™¢é‡Œé¢åƒä½éƒ½ä¸æ–¹ä¾¿ï¼Œæ¯å¤©ä»æ—©åˆ°æ™šä¸èƒ½åœï¼Œèº«å¿ƒçš„æŸä¼¤çœŸçš„éå¸¸å¤§ï¼Œæˆ‘ä»¬å€’æ˜¯æƒ³ç­‰ä»–å¥½ä¸€ç‚¹ï¼Œæ¥å›å®¶å»æ…¢æ…¢ç–—å…»ï¼Œä¹Ÿè®©å‡ ä¸ªäººä¼‘æ¯ä¸€ä¸‹ã€‚</p>
<p>æœªå®Œå¾…ç»­...</p>
]]></content>
      <categories>
        <category>éšæƒ³</category>
      </categories>
      <tags>
        <tag>Thoughts</tag>
      </tags>
  </entry>
  <entry>
    <title>å¹¿å‘ŠæŠ•æ”¾ç³»ç»Ÿç®€ä»‹</title>
    <url>/2022/02/08/12-ads-overview/</url>
    <content><![CDATA[<p>æœ¬æ–‡ä¸»è¦ä»‹ç»äº†å¹¿å‘Šç®—æ³•å…¥é—¨çš„ä¸€äº›åŸºç¡€çŸ¥è¯†ã€‚ä¸»è¦ä»‹ç»äº†å¹¿å‘ŠæŠ•æ”¾æ¼æ–—çš„å‡ ä¸ªéƒ¨åˆ†æ‰¿æ‹…çš„åŠŸèƒ½ã€å„è‡ªçš„ç‰¹ç‚¹ä»¥åŠå¸¸è§çš„ä¸€äº›ç®—æ³•ã€‚</p>
<span id="more"></span>
<p>æ‰€è°“æœå¹¿æ¨æ˜¯ä¸€å®¶ï¼Œæœ¬è´¨ä¸Šæ¥è¯´ï¼Œ[æ¨è/å¹¿å‘Š]å’Œ[æœç´¢]çš„æ‰€ä½¿ç”¨çš„æŠ€æœ¯éƒ½æ˜¯éå¸¸ç±»ä¼¼çš„ï¼Œä¸åŒçš„æ˜¯æœç´¢æœ‰ä¸ªå¾ˆå¼ºçš„queryç‰¹å¾ï¼ˆç”¨æˆ·è‡ªå·±è¾“å…¥çš„ä¿¡æ¯ï¼Œæ¯”å¦‚ä½ å»æ·˜å®ä¸Šé¢æœç´¢çš„å•†å“åç§°ï¼‰ï¼Œè€Œæ¨èæˆ–è€…å¹¿å‘Šçš„ç¼ºå°‘queryç‰¹å¾ï¼Œåªèƒ½ä»<strong>ç”¨æˆ·ç‰¹å¾/å•†å“ç‰¹å¾/ä¸Šä¸‹æ–‡ç‰¹å¾/å†å²è¡Œä¸ºç‰¹å¾</strong>ä¸­å¯¹ç”¨æˆ·çš„å…´è¶£è¿›è¡ŒæŒ–æ˜ã€‚
å¹¿å‘Šç³»ç»ŸæŒ‰ç…§æ¼æ–—çš„å½¢å¼ï¼Œä»æ•°ç™¾æ•°åƒä¸‡å€™é€‰å¹¿å‘Šä¸­ï¼Œå¯¹ç”¨æˆ·çš„æ¯ä¸€åˆ·ï¼ˆä»¥æŠ–éŸ³ä¸ºä¾‹ï¼‰ç­›é€‰å‡ºå‡ åä¸ªå¹¿å‘Šï¼Œç„¶åå‘é€ç»™ç”¨æˆ·ã€‚</p>
<p>å¹¿å‘ŠæŠ•æ”¾ç³»ç»Ÿçš„æ¼æ–—å¤§è‡´å¯ä»¥åˆ†ä¸º [å®šå‘/å¬å›/ç²—æ’/ç²¾æ’/æ··æ’]
5ä¸ªéƒ¨åˆ†ï¼Œæœ‰äº›ç³»ç»Ÿå¯èƒ½æ²¡æœ‰æ··æ’ï¼Œæˆ–è€…æŠŠç²—æ’ç²¾æ’æ”¾åœ¨ä¸€èµ·ï¼ˆå½“ç³»ç»Ÿå€™é€‰è§„æ¨¡è¾ƒå°çš„æ—¶å€™ï¼‰ã€‚</p>
<h2 id="å®šå‘">1. å®šå‘</h2>
<p>å¹¿å‘Šä¸»è®¾å®šå¹¿å‘Šé¢å‘çš„äººç¾¤å¯¹è±¡ç­›é€‰æ¡ä»¶ï¼Œç»“åˆä¸šåŠ¡ä¸Šå¯¹æ¯ä¸ªç”¨æˆ·å¯æŠ•å¹¿å‘Šçš„æ§åˆ¶ï¼ˆæµæ§ã€é¢‘æ§ã€å…¶å®ƒè§„åˆ™ï¼‰å¯¹å¹¿å‘Šå…¨é›†è¿›è¡Œç­›é€‰ã€‚
ä¸€èˆ¬å—åˆ¶äºlatencyï¼ˆç³»ç»Ÿè€—æ—¶ï¼‰ï¼Œæˆ‘ä»¬é€‰æ‹©å®šå‘ä¸å¬å›ç»“æœå–äº¤é›†é€ç²—æ’ã€‚
å®šå‘çš„åŸºæœ¬æ£€ç´¢æ–¹å¼ä¸ºå»ºç«‹å€’æ’ç´¢å¼•ï¼Œmap&lt;filed, map&lt;value, bitmap&gt;
&gt;ã€‚ <img src="https://s2.loli.net/2022/02/09/N8eOyfJzvIkbS7a.png" />
bitmapä¸­çš„æ¯ä¸€ä¸ªbitï¼Œå¯¹åº”ä¸€ä¸ªå¹¿å‘Šidï¼Œå‡ ä¸ªè§„åˆ™ç´¢å¼•ä¸€èµ·æŒ‰ä½å–äº¤é›†ï¼Œå¾—åˆ°å®šå‘çš„ç»“æœcandidateå¹¿å‘Šã€‚</p>
]]></content>
      <categories>
        <category>æŠ€æœ¯</category>
      </categories>
      <tags>
        <tag>ads</tag>
      </tags>
  </entry>
</search>
