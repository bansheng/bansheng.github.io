<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>AutoMLè‡ªåŠ¨æœºå™¨å­¦ä¹ </title>
    <url>/2020/11/01/01-AutoML/</url>
    <content><![CDATA[<p>wiki definition:<br>AutoML is the process of automating the end-to-end process of applying appropriate data-preprocessing, feature engineering, model selection, and model evaluation to solve the certain task</p>
<ul>
<li>Google AutoML</li>
<li><a href="https://arxiv.org/abs/1611.01578">Neural Architecture Search with Reinforcement Learning
</a></li>
</ul>
<p>We will introduce NAS from two perspectives.</p>
<ul>
<li>The first is the structures of the model.<ul>
<li>entire structure</li>
<li>cell-based structure</li>
<li>hierarchical structure</li>
<li>morphism-based structure</li>
</ul>
</li>
<li>The second is hyperparameter optimization (HPO) for designing the model structure.<ul>
<li>Reinforcement Learning</li>
<li>Evolutionary Algorithms</li>
<li>Gradient-based</li>
<li>Bayesian Optimization</li>
</ul>
</li>
</ul>
<p>AutoML</p>
<ul>
<li>data preparation</li>
<li>feature engineering</li>
<li>model generation</li>
<li>model evaluation</li>
</ul>
<h2 id="1-Data-preparation"><a href="#1-Data-preparation" class="headerlink" title="1. Data preparation"></a>1. Data preparation</h2><h3 id="1-1-data-collection"><a href="#1-1-data-collection" class="headerlink" title="1.1 data collection"></a>1.1 data collection</h3><ol>
<li>data synthesis<ul>
<li>augment the exsiting dataset<br> CV: cropping, flipping, padding, rotation and resize, etc.<br> Library: torchvision augmentor</li>
<li>data warping<br> generates additional samples by applying transformation on data-space</li>
<li>synthetic over-sampling<br> creates additional samples in feature-space.</li>
<li>For text data, synonym insertion is a common way of augmentingåŒä¹‰è¯æ’å…¥</li>
<li>first translate the text into some foreign language, and then translate it back to the original language</li>
<li>non-domain-specific data augmentation strategy that uses noising in RNNs</li>
<li>back-translation</li>
<li>data simulator</li>
</ul>
<p> <strong>OpenAI Gym</strong> is a popular toolkit that provides various simulation environment</p>
<ul>
<li>GAN</li>
</ul>
</li>
<li>data searching(search for web data)<ul>
<li>On the one hand, sometimes the <strong>search results do not exactly match the keywords</strong>.(filter unrelated data)</li>
<li>The other problem is that web data may <strong>have wrong labels or even no labels.</strong>(learning-based <strong>self-labeling</strong> method, åˆ†ä¸ºself-training, co-training, co-learning)</li>
<li>the distribution of web data can be extremely different from the target dataset, which would increase the difficulty of training the model.(fine-tune these web data)</li>
<li>dataset inbalance(SMOTE, combines boosting method with data generation)</li>
</ul>
</li>
</ol>
<h3 id="1-2-data-cleaning"><a href="#1-2-data-cleaning" class="headerlink" title="1.2 data cleaning"></a>1.2 data cleaning</h3><p>redundant, incomplete, or incorrect data</p>
<p>standardization, scaling, binarization of quantitative characteristic, one-hot encoding qualitative characteristic, and filling missing values with mean value, etc.</p>
<h2 id="2-feature-engneering"><a href="#2-feature-engneering" class="headerlink" title="2. feature engneering"></a>2. feature engneering</h2><ul>
<li>feature selection å‡å°‘å†—ä½™ç‰¹å¾</li>
<li>extraction å‡å°‘ç‰¹å¾çš„ç»´åº¦</li>
<li>construction å±•å¼€åŸå§‹ç‰¹å¾ç©ºé—´</li>
</ul>
<h3 id="2-1-feature-selection"><a href="#2-1-feature-selection" class="headerlink" title="2.1 feature selection"></a>2.1 feature selection</h3><p><img src="/01-AutoML/03-feature-selection.png" alt="feature selection"></p>
<p>search strategy</p>
<ul>
<li>complete<ul>
<li>exhaustive</li>
<li>non-exhaustive</li>
</ul>
</li>
<li>heuristic<ul>
<li>Sequential Forward Selection(SFS)</li>
<li>Sequential Backward Selection(SBS)</li>
<li>Bidirectional Search(BS)</li>
</ul>
</li>
<li>random search algorithm<ul>
<li>Simulated Annealing(SA)</li>
<li>Genetic Algorithms(GA)</li>
</ul>
</li>
</ul>
<p>subset evaluation</p>
<ul>
<li>filter method<br>  scores each feature according to divergence or correlation, and then select features by a threshold</li>
<li>Wrapper method<br>  classifies the sample set with the selected feature subset, the classification accuracy is used as the criterion to measure the quality of the feature subset</li>
<li>embedded method<br>  performs variable selection as part of the learning procedure.<br>  Regularization, decision tree, <strong>DL</strong></li>
</ul>
<h3 id="2-2-feature-construction"><a href="#2-2-feature-construction" class="headerlink" title="2.2 feature construction"></a>2.2 feature construction</h3><h4 id="definition"><a href="#definition" class="headerlink" title="definition"></a>definition</h4><p><strong>constructs new features</strong> from the basic feature space or raw data to help enhance the robustness and generalization of the model, and its essence is to increase the representative ability of original features.</p>
<h4 id="å¸¸ç”¨æ–¹æ³•-preprocessing-transformation"><a href="#å¸¸ç”¨æ–¹æ³•-preprocessing-transformation" class="headerlink" title="å¸¸ç”¨æ–¹æ³• preprocessing transformation"></a>å¸¸ç”¨æ–¹æ³• preprocessing transformation</h4><p>åŒ…æ‹¬</p>
<ul>
<li>standardization</li>
<li>normalization</li>
<li>feature discretization</li>
</ul>
<h4 id="è‡ªåŠ¨åŒ–æ£€ç´¢"><a href="#è‡ªåŠ¨åŒ–æ£€ç´¢" class="headerlink" title="è‡ªåŠ¨åŒ–æ£€ç´¢"></a>è‡ªåŠ¨åŒ–æ£€ç´¢</h4><p>äººåŠ›å¾ˆéš¾æ£€ç´¢æ‰€æœ‰å¯èƒ½<br>some automatic feature construction methods have been proposed</p>
<p>These algorithms mainly aim to automate <strong>the process of searching and evaluating the operation combination</strong>å®ç°æ“ä½œç»„åˆæœç´¢å’Œè¯„ä»·çš„è‡ªåŠ¨åŒ–</p>
<p>searching ç®—æ³•</p>
<ul>
<li>decision tree-based methods</li>
<li>genetic algorithm<br>  éœ€è¦pre-defined operation space</li>
<li>annotation-based approaches<br>  ä¸éœ€è¦ï¼Œå°†domainçŸ¥è¯†ä»¥æ³¨é‡Šçš„å½¢å¼ä¸è®­ç»ƒç¤ºä¾‹ä¸€èµ·ä½¿ç”¨<br>  å¼•å…¥äº†äº¤äº’å¼ç‰¹å¾ç©ºé—´æ„å»ºåè®®ï¼Œå­¦ä¹ è€…è¯†åˆ«å‡ºç‰¹å¾ç©ºé—´çš„ä¸è¶³åŒºåŸŸï¼Œå¹¶ä¸é¢†åŸŸä¸“å®¶åä½œï¼Œé€šè¿‡ç°æœ‰çš„è¯­ä¹‰èµ„æºå¢åŠ æè¿°æ€§</li>
</ul>
<h3 id="2-3-feature-extraction"><a href="#2-3-feature-extraction" class="headerlink" title="2.3 feature extraction"></a>2.3 feature extraction</h3><p>a dimensionality reduction process through some mapping functions</p>
<p>mapping function</p>
<ul>
<li>Principal Component Analysis(PCA)</li>
<li>Independent COmponent Analysis(ICA)</li>
<li>isomap</li>
<li>nonlinear dimensionality reduction</li>
<li>Linear discriminant analysis(LDA)</li>
<li><strong>feed-forward neural networks approach</strong></li>
</ul>
<h2 id="3-model-generation"><a href="#3-model-generation" class="headerlink" title="3. model generation"></a>3. model generation</h2><p>two types of approaches for model selection:</p>
<ul>
<li>traditional model selection<ul>
<li>SVM</li>
<li>KNN</li>
<li>decision tree</li>
<li>K-means</li>
</ul>
</li>
<li>NAS</li>
</ul>
<p>ä¸»è¦ä»‹ç»NAS</p>
<h3 id="3-1-model-structures"><a href="#3-1-model-structures" class="headerlink" title="3.1 model structures"></a>3.1 model structures</h3><p>The model is generated by selecting and combining a set of primitive operations, which are pre-defined in the search space. The operations can be broadly divided into convolution, pooling, concatenation, elemental addition, skip connection, etc.</p>
<ol>
<li><p>entire structure<br> ç¼ºç‚¹ï¼šå¤ªæ·±ï¼Œæœç´¢ç©ºé—´å¤ªå¤§ï¼Œæ¶ˆè€—æ—¶é—´å’Œè®¡ç®—èµ„æºï¼Œæ‰¾åˆ°çš„modelçš„transferabilityå·®ï¼Œæ„å‘³ç€å°çš„æ•°æ®é›†ä¸Šæ‰¾åˆ°çš„æ¨¡å‹åœ¨å®Œæ•´æ•°æ®é›†ä¸Šè¡¨ç°å¾ˆå·®</p>
</li>
<li><p>Cell-based structure<br> å…ˆç”Ÿæˆcellï¼Œå†è¿èµ·æ¥<br> <img src="/01-AutoML/04-cell-model.png" alt="cell model"><br> ä¼˜ç‚¹ï¼šæœç´¢ç©ºé—´å¤§å¤§å‡å°ï¼Œå¹¶ä¸”æ›´å®¹æ˜“ä»å°datasetä¸Šè½¬æ¢åˆ°å¤§çš„datasetä¸Š(ç®€å•å åŠ cells))<br> åˆ†æˆä¸¤çº§ï¼š</p>
<ul>
<li>inner:cell level, selects the operation and connection for each node</li>
<li>outter level:network level, controls the spatial resolution changes</li>
</ul>
</li>
<li><p>Hierarchical structure<br> for a hierarchical structure, there are many levels, each with a fixed number of cells. The higher-level cell is generated by incorporating lower-level cell iteratively.<br> <img src="/01-AutoML/05-hierarchical-structure.png" alt="hierarchical structure"><br> å¯ä»¥å‘ç°æ›´å¤šå¤æ‚ã€çµæ´»çš„ç½‘ç»œç»“æ„ç±»å‹ã€‚</p>
</li>
<li><p>Network Morphism based structure<br> transferring the information stored in an existing neural network into a new neural network<br> ä»ç°æœ‰ç½‘ç»œåˆ°æ–°ç½‘ç»œ<br> ä¿è¯æ€§èƒ½ä¸ä½äºåŸæœ‰ç½‘ç»œ</p>
</li>
</ol>
<h3 id="3-2-hyperparameter-optimization-HPO"><a href="#3-2-hyperparameter-optimization-HPO" class="headerlink" title="3.2 hyperparameter optimization(HPO)"></a>3.2 hyperparameter optimization(HPO)</h3><ol>
<li><p>Grid &amp; Random Search<br> æœ€å¹¿æ³›ä½¿ç”¨çš„<br> <img src="/01-AutoML/06-grid-and-random-search.png" alt="grid&amp;random search"></p>
</li>
<li><p>Reinforcement Learning<br> åˆ†ä¸ºä¸¤éƒ¨åˆ†</p>
<ul>
<li>controller:RNN, used to generate different child networks at different epoch</li>
<li>reward network:trains and evaluates the generated child networks and uses the reward (e.g. accuracy) to update RNN controller.</li>
<li>ç¼ºç‚¹ï¼šè®­ç»ƒæ—¶é—´é•¿ï¼Œèµ„æºéœ€æ±‚å¤§</li>
<li>ENAS:å­æ¶æ„è¢«çœ‹åšæ˜¯é¢„å®šä¹‰æœç´¢ç©ºé—´çš„å­å›¾ï¼Œå…±äº«å‚æ•°ï¼Œä»è€Œé¿å…ä»é›¶å¼€å§‹åˆ°æ”¶æ•›åœ°è®­ç»ƒæ¯ä¸ªå­æ¨¡å‹</li>
</ul>
</li>
<li><p>Evolutionary Algorithm<br> é€šç”¨çš„åŸºäºç§ç¾¤çš„å…ƒå¯å‘å¼ä¼˜åŒ–ç®—æ³•ï¼Œ<br> æœ‰ä¸¤ç§ç±»å‹çš„ç¼–ç æ–¹æ¡ˆ:ç›´æ¥ç¼–ç å’Œé—´æ¥ç¼–ç ã€‚direct, indirect<br> ç›´æ¥ç¼–ç æ˜¯ä¸€ç§å¹¿æ³›ä½¿ç”¨çš„æ–¹æ³•ï¼Œå®ƒæ˜¾å¼åœ°æŒ‡å®šäº†è¡¨ç°å‹ï¼šGenetic CNN</p>
<ul>
<li>selection é€‰æ‹©<ul>
<li>fitness selection</li>
<li>rank selection</li>
<li>Tournament selection</li>
</ul>
</li>
<li>crossover æ‚äº¤</li>
<li>mutation çªå˜</li>
<li>update æ›´æ–°</li>
</ul>
<p> <img src="/01-AutoML/07-overview-of-EA.png" alt="overview of EA"></p>
</li>
<li><p>Bayesian Optimization</p>
<ul>
<li>BO</li>
<li>Sequential model-based optimization(SMBO)</li>
<li>Bayesian Optimization-based Hyperband (BOHB)</li>
</ul>
</li>
<li><p>Gradient Descent</p>
</li>
</ol>
<h2 id="4-model-estimation"><a href="#4-model-estimation" class="headerlink" title="4. model estimation"></a>4. model estimation</h2><h3 id="4-1-low-fidelity"><a href="#4-1-low-fidelity" class="headerlink" title="4.1 low fidelity"></a>4.1 low fidelity</h3><p>On the one hand, we can reduce the number of images or the resolution of images (for image classification tasks)<br>åœ¨å­é›†ä¸Šé¢è®­ç»ƒ,åœ¨ä½ç²¾åº¦è®­ç»ƒé›†ä¸Šé¢è®­ç»ƒ<br>On the other hand, low fidelity model evaluation can be realized by reducing the model size, such as training with less number of filters per layer<br>å‡å°‘ç½‘ç»œçš„å¤§å°ï¼Œæ¯”å¦‚æ¯å±‚çš„filterçš„æ•°ç›®</p>
<h3 id="4-2-Transfer-learning"><a href="#4-2-Transfer-learning" class="headerlink" title="4.2 Transfer learning"></a>4.2 Transfer learning</h3><ul>
<li>Transfer Neural AutoML<br>uses knowledge from prior tasks to speed up network design</li>
<li>ENAS<br>shares parameters among child networks</li>
<li>The network morphism based algorithms<br>inherit the weights of previous architectures</li>
</ul>
<h3 id="4-3-Surrogateä»£ç†"><a href="#4-3-Surrogateä»£ç†" class="headerlink" title="4.3 Surrogateä»£ç†"></a>4.3 Surrogateä»£ç†</h3><p>ä¸€èˆ¬æ¥è¯´ï¼Œä¸€æ—¦è·å¾—äº†ä¸€ä¸ªè‰¯å¥½çš„è¿‘ä¼¼ï¼Œå°±å¾ˆå®¹æ˜“æ‰¾åˆ°æœ€ä½³é…ç½®ï¼Œè€Œä¸æ˜¯ç›´æ¥ä¼˜åŒ–åŸæ¥æ˜‚è´µçš„ç›®æ ‡ã€‚<br>PNAS</p>
<p>this method is not applicable when the optimization space is too large and hard to quantize, and the evaluation of each configuration is extremely expensive</p>
<h3 id="4-4-Early-stopping"><a href="#4-4-Early-stopping" class="headerlink" title="4.4 Early stopping"></a>4.4 Early stopping</h3><p>is now being used to speed up model evaluation by <strong>stopping the evaluations which predicted to perform poorly on the validation set</strong></p>
<h2 id="5-NAS-PERFORMANCE-SUMMARY"><a href="#5-NAS-PERFORMANCE-SUMMARY" class="headerlink" title="5. NAS PERFORMANCE SUMMARY"></a>5. NAS PERFORMANCE SUMMARY</h2><p><img src="/01-AutoML/08-manual-vs-generated-model.png" alt="manual VS generated models"></p>
<h2 id="6-future-work"><a href="#6-future-work" class="headerlink" title="6. future work"></a>6. future work</h2><ol>
<li>Complete AutoML Pipeline<br>æ•°æ®éƒ¨åˆ†</li>
<li>Interpretability</li>
<li>Reproducibility</li>
<li>Flexible Encoding Scheme</li>
<li>More Area<br>cnn: image classification<br>rnn: language modeling<br>more</li>
<li>Lifelong Learn</li>
</ol>
]]></content>
      <categories>
        <category>Survey</category>
      </categories>
      <tags>
        <tag>AutoML</tag>
      </tags>
  </entry>
  <entry>
    <title>DARTS å¯å¾®åˆ†æ¶æ„æœç´¢</title>
    <url>/2020/11/01/02-DARTS/</url>
    <content><![CDATA[<h2 id="1-DARTS"><a href="#1-DARTS" class="headerlink" title="1. DARTS"></a>1. DARTS</h2><p> the computation procedure for an architecture (or a cell in it) is represented as a directed acyclic graph. è¡¨ç¤ºä¸ºæœ‰å‘å›¾ã€‚</p>
<h3 id="1-1-search-space"><a href="#1-1-search-space" class="headerlink" title="1.1 search space"></a>1.1 search space</h3><p>å¯»æ‰¾ä¸€ä¸ªè®¡ç®—cellï¼Œä½œä¸ºæœ€åæ¶æ„çš„å»ºé€ æ¨¡å—ã€‚å­¦ä¹ å‡ºæ¥çš„cellå¯ä»¥å åŠ èµ·æ¥ç»„æˆcnnï¼Œæˆ–è€…é€’å½’è¿æ¥èµ·æ¥ç»„æˆrnnã€‚</p>
<p>cellæ˜¯ç”±Nä¸ªæœ‰åºåºåˆ—nodeç»„æˆçš„æœ‰å‘æ— ç¯å›¾ã€‚æ¯ä¸€æ¡edgeéƒ½æ˜¯ä¸€ä¸ªè®¡ç®—ã€‚æˆ‘ä»¬å‡è®¾è¿™ä¸ªcellæœ‰ä¸¤ä¸ªinputå’Œä¸€ä¸ªoutputï¼Œå¯¹äºcnnï¼Œå®ƒå°±æ˜¯å‰é¢ä¸¤ä¸ªå±‚çš„è¾“å‡ºï¼Œå¯¹äºrnnï¼Œå®ƒæ˜¯ä¸Šä¸ªstepçš„stateä»¥åŠè¿™ä¸ªstepçš„Inputã€‚cellçš„è¾“å‡ºæ˜¯é€šè¿‡å¯¹æ‰€æœ‰ä¸­é—´èŠ‚ç‚¹åº”ç”¨reductionå¾—åˆ°çš„ã€‚</p>
<p>æ‰€æœ‰ä¸­é—´èŠ‚ç‚¹çš„è®¡ç®—ä¾èµ–å‰ç½®èŠ‚ç‚¹ã€‚<br>$$<br>x^{(j)} &#x3D; \sum_{i&lt;j}o^{(i,j)}(x^{(i)})<br>$$<br>æ³¨æ„zero operationä¹Ÿæ˜¯å¯ä»¥è¢«å…è®¸çš„edgeç±»å‹ã€‚</p>
<h3 id="1-2-continuous-relaxation-and-optimization"><a href="#1-2-continuous-relaxation-and-optimization" class="headerlink" title="1.2 continuous relaxation and optimization"></a>1.2 continuous relaxation and optimization</h3><p>æ‰¾åˆ°æ¯ä¸€ä¸ªæ“ä½œå¯¹åº”çš„æƒé‡çŸ©é˜µ$\alpha^{(i,j)}$ï¼Œè¿™æ ·æ‰€æœ‰çš„æƒé‡çŸ©é˜µé›†åˆä¸º$\alpha$ï¼Œæˆ‘ä»¬å°†NASçš„ä»»åŠ¡å‡å°ä¸ºå­¦ä¹ ä¸€ä¸ªè¿ç»­å˜é‡çš„é›†åˆ$\alpha$ã€‚</p>
<p>DARTSä½¿ç”¨çš„æ˜¯<strong>GD</strong>æ¥ä¼˜åŒ–validation lossã€‚ç›¸ä¼¼çš„æœ‰RL(<a href>Learning transferable architectures for scalable image recognition</a>)ï¼ŒEA(<a href>Hierarchical representations for efficient architecture search</a>)</p>
<p>NASçš„ç›®æ ‡æ˜¯æ‰¾åˆ°$\alpha^*$ä½¿å¾—validation loss$L_{val}(w^*, \alpha^*)$æœ€å°ï¼Œ$w^*$æ˜¯ä½¿å¾—training loss$L_{train}(w, \alpha^*)$æœ€å°çš„wã€‚<br>$$<br>min_{\alpha} L_{val}(w^*(\alpha), \alpha) \<br>s.t. w^*(\alpha) &#x3D; argmin_w L_{train}(w, \alpha)<br>$$<br><img src="/02-DARTS/01-algorithm.png" alt="algorithm"></p>
<h3 id="1-3-approximate-architecture-gradient"><a href="#1-3-approximate-architecture-gradient" class="headerlink" title="1.3 approximate architecture gradient"></a>1.3 approximate architecture gradient</h3><p>$$<br>\begin{aligned} &amp; \nabla_{\alpha} \mathcal{L}<em>{v a l}\left(w^{*}(\alpha), \alpha\right) \ \approx &amp; \nabla</em>{\alpha} \mathcal{L}<em>{v a l}\left(w-\xi \nabla</em>{w} \mathcal{L}_{t r a i n}(w, \alpha), \alpha\right) \end{aligned}<br>$$</p>
<p>è¿ç”¨chain ruleã€‚å°†ä¸Šå¼è¿›ä¸€æ­¥å¤„ç†ã€‚<br>$$<br>\triangledown_\alpha L_{val}(wâ€™, \alpha - \xi \triangledown^2_{\alpha, w} L_{train}(w, \alpha) \triangledown_{wâ€™}L_{val}(wâ€™, \alpha))<br>$$<br>å…¶ä¸­çš„$wâ€™ &#x3D; w - \xi\triangledown_w L_{train}(w, \alpha)$æŒ‡çš„å°±æ˜¯one-step forward modelã€‚</p>
<p>ä½¿ç”¨the finite difference approximation(æœ‰é™å·®åˆ†è¿‘ä¼¼)å¯ä»¥å‡å°‘å¤æ‚åº¦ã€‚<br>$$<br>\epsilon æ˜¯æå°é‡ \<br>w^{\pm} &#x3D; w \pm \epsilon \triangledown_{wâ€™}L_{val}(wâ€™, \alpha) \<br>\xi \triangledown^2_{\alpha, w} L_{train}(w, \alpha) \triangledown_{wâ€™}L_{val}(wâ€™, \alpha)) \approx \frac{\triangledown_\alpha L_{train}(w^{+}, \alpha) - \triangledown_\alpha L_{train}(w^{-}, \alpha)}{2\xi}<br>$$<br>å°†$\xi &#x3D; 0$ä½œä¸ºä¸€é˜¶è¿‘ä¼¼ï¼Œå°†$\xi &gt; 0$ä½œä¸ºä¸¤é˜¶è¿‘ä¼¼ã€‚</p>
<h3 id="1-4-deriving-discrete-architecture"><a href="#1-4-deriving-discrete-architecture" class="headerlink" title="1.4 deriving discrete architecture"></a>1.4 deriving discrete architecture</h3><p>åœ¨æ‰€æœ‰é0çš„å€™é€‰operationsä¿ç•™top-k strongest operationsï¼Œä¸ºäº†ä½¿å¾—å‡ºçš„ç½‘ç»œå¯ä»¥å’Œç°æœ‰ç½‘ç»œæ¯”è¾ƒï¼Œæˆ‘ä»¬é€‰æ‹©k&#x3D;2 for cnn, k&#x3D;1 for rnnã€‚</p>
<p>ä¸ºä»€ä¹ˆä¸ä½¿ç”¨zero operationå‘¢ï¼Ÿ</p>
<ol>
<li>ä¸ºäº†ä¸ç°æœ‰æ¨¡å‹è¿›è¡Œå…¬å¹³çš„æ¯”è¾ƒï¼Œæˆ‘ä»¬éœ€è¦æ¯ä¸ªèŠ‚ç‚¹æ°å¥½æœ‰kæ¡éé›¶çš„å¼•å…¥è¾¹</li>
<li>å› ä¸ºå¢åŠ é›¶æ“ä½œçš„logitsåªä¼šå½±å“ç»“æœèŠ‚ç‚¹è¡¨ç¤ºçš„è§„æ¨¡ï¼Œç”±äºBNå¤„ç†çš„å­˜åœ¨è€Œä¸ä¼šè€Œå½±å“æœ€ç»ˆçš„åˆ†ç±»ç»“æœ</li>
</ol>
<h2 id="2-Experiments-and-results"><a href="#2-Experiments-and-results" class="headerlink" title="2. Experiments and results"></a>2. Experiments and results</h2><h3 id="2-1-architecture-search"><a href="#2-1-architecture-search" class="headerlink" title="2.1 architecture search"></a>2.1 architecture search</h3><h4 id="2-1-1-search-for-convolutional-cells-on-cifar-10"><a href="#2-1-1-search-for-convolutional-cells-on-cifar-10" class="headerlink" title="2.1.1 search for convolutional cells on cifar-10"></a>2.1.1 search for convolutional cells on cifar-10</h4><p>åŒ…å«8ç§operationã€‚ 3 Ã— 3 and 5 Ã— 5 separable convolutions, 3 Ã— 3 and 5 Ã— 5 dilated separable convolutions, 3 Ã— 3 max pooling, 3 Ã— 3 average pooling, identity, and zeroã€‚</p>
<p>We use the ReLU-Conv-BN order for convolutional operations, and each separable convolution is always applied twice</p>
<p>åœ¨æ•´ä¸ªç½‘ç»œçš„1&#x2F;3å’Œ2&#x2F;3å¤„ï¼Œè®¾ç«‹reduce cellã€‚ç¼©å°ç©ºé—´åˆ†è¾¨ç‡ã€‚</p>
<h4 id="2-1-2-searching-for-recurrent-cells-for-penn-treebank"><a href="#2-1-2-searching-for-recurrent-cells-for-penn-treebank" class="headerlink" title="2.1.2 searching for recurrent cells for penn treebank"></a>2.1.2 searching for recurrent cells for penn treebank</h4><p>operationçš„ç§ç±»ï¼šlinear transformations followed by one of tanh, relu, sigmoid activations, as well as the identity mapping and the <em>zero</em> operation.</p>
<p>æ€»å…±12ä¸ªnodeï¼Œæœ€åˆçš„intermediate nodeæ˜¯ç”±ä¸¤ä¸ªinput nodeé€šè¿‡çº¿æ€§å˜æ¢ï¼Œæ±‚å’Œï¼Œç„¶åä¼ è¿‡ä¸€ä¸ªtanhæ¿€æ´»å‡½æ•°å¾—åˆ°çš„ã€‚</p>
<h3 id="2-2-architecture-evaluation"><a href="#2-2-architecture-evaluation" class="headerlink" title="2.2 architecture evaluation"></a>2.2 architecture evaluation</h3><p><strong>å¯»æ‰¾å¤šæ¬¡ï¼Œé¿å…åˆå§‹åŒ–çš„å½±å“</strong> ã€‚ä»cifar-10ä¸Šè¿ç§»åˆ°imagenetä¸Šï¼Œä»PTBä¸Šè¿ç§»åˆ°wikitext-2ä¸Šã€‚</p>
]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>NAS</tag>
      </tags>
  </entry>
  <entry>
    <title>ENAS</title>
    <url>/2020/02/09/03-ENAS/</url>
    <content><![CDATA[<h2 id="Efficient-Neural-Architecture-Search-via-Parameter-Sharing"><a href="#Efficient-Neural-Architecture-Search-via-Parameter-Sharing" class="headerlink" title="Efficient Neural Architecture Search via Parameter Sharing"></a>Efficient Neural Architecture Search via Parameter Sharing</h2><p>an RNN controller is trained in a loop: the controller first samples a candidate architecture, i.e. a child model, and then trains it to convergence to measure its performance on the task of desire.</p>
<h2 id="0-è®­ç»ƒ"><a href="#0-è®­ç»ƒ" class="headerlink" title="0. è®­ç»ƒ"></a>0. è®­ç»ƒ</h2><p>åˆ†ä¸ºä¸¤ä¸ªç½‘ç»œï¼Œcontrolleré€‰æ‹©è®¾è®¡å­ç½‘ç»œçš„æ¶æ„ï¼Œ<br>å­ç½‘ç»œæ˜¯ä¸€ä¸ªentireç½‘ç»œçš„ä¸€ä¸ªå­å›¾</p>
<p>åˆ†ä¸ºä¸¤ç§å‚æ•° RNNçš„å‚æ•°$\theta$ sampleç½‘ç»œçš„$w$<br>åˆ†åˆ«ä½¿ç”¨adam åœ¨validation setè®­ç»ƒ<br>SGDåœ¨training setä¸Šé¢è®­ç»ƒ</p>
<h2 id="1-RNN-cellsçš„è®¾è®¡"><a href="#1-RNN-cellsçš„è®¾è®¡" class="headerlink" title="1. RNN cellsçš„è®¾è®¡"></a>1. RNN cellsçš„è®¾è®¡</h2><p>controllerè®¾è®¡</p>
<ol>
<li>å½“å‰èŠ‚ç‚¹è¿æ¥çš„å‰ä¸€ä¸ªèŠ‚ç‚¹</li>
<li>ä½¿ç”¨ä»€ä¹ˆæ¿€æ´»å‡½æ•°(relu, sigmod, tanh, identity)4ç§</li>
</ol>
<p><img src="/03-ENAS/01-rnn-cells.png" alt="rnn cells"></p>
<p>search space:the search space has$4N Ã— N!$configurations. In our experiments, N &#x3D; 12,</p>
<h2 id="2-cnnçš„è®¾è®¡"><a href="#2-cnnçš„è®¾è®¡" class="headerlink" title="2. cnnçš„è®¾è®¡"></a>2. cnnçš„è®¾è®¡</h2><p>controllerè®¾è®¡</p>
<ol>
<li>å½“å‰èŠ‚ç‚¹è¿æ¥çš„å‰ä¸€ä¸ªèŠ‚ç‚¹</li>
<li>ä½¿ç”¨ä»€ä¹ˆè®¡ç®—å‡½æ•°(<code>conv3*3, conv5*5, sep3*3, sep5*5, maxpooling3*3, average pooling3*3</code>)6ç§</li>
</ol>
<p><img src="/03-ENAS/02-cnn.png" alt="cnn"></p>
<p>search space:<br>Making the described set of decisions for a total of L times, we can sample a network of L layers. Since all decisions are independent, there are 6L Ã— 2L(Lâˆ’1)&#x2F;2 networks in the search space. In our experiments, L &#x3D; 12, resulting in 1.6 Ã— 1029 possible networks.</p>
<h2 id="3-cnn-cellsè®¾è®¡"><a href="#3-cnn-cellsè®¾è®¡" class="headerlink" title="3. cnn cellsè®¾è®¡"></a>3. cnn cellsè®¾è®¡</h2><p>controllerè®¾è®¡</p>
<ol>
<li>ä¸¤ä¸ªå‰ç½®è¿æ¥çš„èŠ‚ç‚¹</li>
<li>ä¸¤æ¡è¾¹çš„è®¡ç®—ç§ç±»(<code>identity, sep3*3, spe5*5, avepooling3*3, maxpooling3*3</code>) 5ç§</li>
</ol>
<p><img src="/03-ENAS/03-cnn-cells.png" alt="cnn cells"></p>
<p>search space:<br>Finally, we estimate the complexity of this search space.<br>At node i (3 â‰¤ i â‰¤ B), the controller can select any two nodes from the i âˆ’ 1 previous nodes, and any two operations from 5 operations. As all decisions are independent, there are (5 Ã— (B âˆ’ 2)!)2 possible cells. Since we independently sample for a convolutional cell and a reduction cell, the final size of the search space is (5 Ã— (B âˆ’ 2)!) . With B &#x3D; 7 as in our experiments, the search space can realize 1.3 Ã— 1011 final networks, making it significantly smaller than the search space for entire convolutional networks</p>
]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>NAS</tag>
      </tags>
  </entry>
  <entry>
    <title>hierarchical representations for efficient architecture search</title>
    <url>/2020/11/01/04-HREAS/</url>
    <content><![CDATA[<p>åˆ†å±‚è®¾è®¡ï¼Œåº•å±‚ä¸ºä¸€ä¸ªä¸ªæœ€åŸºæœ¬çš„è®¡ç®—æ“ä½œï¼Œé¡¶å±‚ä¸ºæ•´ä½“æ¶æ„ã€‚</p>
<p><img src="/04-HREAS/01-hierarchical-architecture-representation.png" alt="hiarchical architecture representation"></p>
<h2 id="evolutionary-architecture-search"><a href="#evolutionary-architecture-search" class="headerlink" title="evolutionary architecture search"></a>evolutionary architecture search</h2><h3 id="mutation"><a href="#mutation" class="headerlink" title="mutation"></a>mutation</h3><p>æ‰¾åˆ°non-primitive level l&gt;&#x3D;2ï¼Œé€‰æ‹©è¿™ä¸ªlevelé‡Œé¢çš„ä¸€ä¸ªmotifï¼Œé€‰æ‹©motifé‡Œé¢çš„ä¸¤ä¸ªèŠ‚ç‚¹ï¼ŒæŠŠä¸¤ä¸ªèŠ‚ç‚¹ä¸­é—´çš„è¾¹ç½®æ¢ä¸ºå¦ä¸€ç§è¾¹(ä¸‰ç§æƒ…å†µï¼Œ1.æ–°å¢è¾¹ï¼›2.å»é™¤è¾¹ï¼›3.ç½®æ¢è¾¹)ã€‚</p>
<h3 id="initialization"><a href="#initialization" class="headerlink" title="initialization"></a>initialization</h3><p>åŸå‹åˆå§‹åŒ–çš„å¤„ç†</p>
<ol>
<li>å…ˆæŠŠæ‰€æœ‰çš„è¾¹ç½®æ¢ä¸ºidentity</li>
<li>æ‰§è¡Œå¾ˆå¤§æ•°ç›®(e.g. 1000)æ¬¡çš„mutation</li>
</ol>
<h3 id="search-algorithm"><a href="#search-algorithm" class="headerlink" title="search algorithm"></a>search algorithm</h3><p>Tournament selection</p>
<p>ä»åˆå§‹çš„éšæœºåŸå‹é›†åˆä¸­ï¼Œtournament selectioné€‰å‡ºæœ€promising åŸå‹ï¼ŒæŠŠå®ƒçš„mutatedåä»£æ”¾åˆ°é›†åˆä¸­ï¼Œé‡å¤è¿™ä¸ªè¿‡ç¨‹ï¼Œé›†åˆä¸­çš„åŸå‹è¡¨ç°ä¼šéšæ—¶é—´ç¼“æ…¢ä¼˜åŒ–ã€‚é€‰æ‹©åŸå‹é›†åˆä¸­åœ¨validation setä¸Šé¢è¡¨ç°æœ€å¥½çš„genotypeä½œä¸ºä¸€æ®µæ—¶é—´è¿›åŒ–çš„æœ€åè¾“å‡ºã€‚</p>
<p>randon search</p>
<p>ä¸åŒäºtournament selectionï¼Œrandom searchéšæœºé€‰æ‹©é›†åˆä¸­çš„åŸå‹è¿›è¡Œçªå˜ï¼Œè¿™æ ·çªå˜çš„è¿‡ç¨‹å¯ä»¥å¹¶è¡Œï¼Œå‡å°‘äº†search time</p>
<h3 id="implementation"><a href="#implementation" class="headerlink" title="implementation"></a>implementation</h3><p>å¼‚æ­¥çš„ ä¸€ä¸ªcontrollerè´Ÿè´£æ‰§è¡Œæ‰€æœ‰åŸå‹çš„è¿›åŒ–ï¼Œå…¶ä½™çš„workerè´Ÿè´£å¯¹åŸå‹çš„è¡¨ç°åševaluationã€‚Architectures are trained from scratch for a fixed number of steps with random weight initializationã€‚</p>
]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>NAS</tag>
      </tags>
  </entry>
  <entry>
    <title>ICLR2020éƒ¨åˆ†NASæŠ•ç¨¿è®ºæ–‡è§£è¯»</title>
    <url>/2020/11/01/05-ICLR2020_NAS_papers/</url>
    <content><![CDATA[<h2 id="1-stabilizing-DARTS-with-Amended-grarident-estimation-on-architectural-parameters"><a href="#1-stabilizing-DARTS-with-Amended-grarident-estimation-on-architectural-parameters" class="headerlink" title="1.stabilizing DARTS with Amended grarident estimation on architectural parameters"></a>1.stabilizing DARTS with Amended grarident estimation on architectural parameters</h2><p>å°†dartsçš„lossåˆ†ä¸ºä¸¤ä¸ªéƒ¨åˆ†ï¼Œå¯¹ç¬¬äºŒä¸ªéƒ¨åˆ†è¿›è¡Œäº†æ¨è¯ï¼Œæå‡ºäº†æ–°çš„ä¸€ç§æ•°å­¦å½¢å¼å»è¿‘ä¼¼è¿™ä¸ªlossï¼Œå¹¶è¿›è¡Œäº†solidçš„æ•°å­¦è¯æ˜ã€‚</p>
<p>$$\begin{equation}<br>\begin{aligned}<br>\mathbf{g}<em>{2}^{\prime}&#x3D;-\left.\left.\eta \cdot \nabla</em>{\boldsymbol{\alpha}, \boldsymbol{\omega}}^{2} \mathcal{L}<em>{\operatorname{train}}(\boldsymbol{\omega}, \boldsymbol{\alpha})\right|</em>{\omega&#x3D;\boldsymbol{\omega}^{<em>}\left(\boldsymbol{\alpha}<em>{t}\right), \boldsymbol{\alpha}&#x3D;\boldsymbol{\alpha}</em>{t}} \cdot \mathbf{H} \cdot \nabla_{\boldsymbol{\omega}} \mathcal{L}<em>{\mathrm{val}}(\boldsymbol{\omega}, \boldsymbol{\alpha})\right|</em>{\boldsymbol{\omega}&#x3D;\boldsymbol{\omega}^{</em>}\left(\boldsymbol{\alpha}<em>{t}\right), \boldsymbol{\alpha}&#x3D;\boldsymbol{\alpha}</em>{t}}<br>\end{aligned}<br>\end{equation}$$</p>
<p>æå‡ºDARTSçš„äºŒé˜¶åå¯¼çš„æ›´åˆç†çš„è¿‘ä¼¼ï¼Œä¸‹é¢è¿™ä¸ªå…¬å¼ï¼Œç¬¬ä¸€ä¸ªéƒ¨åˆ†ç§°ä¸º$g_1$ï¼Œé€šè¿‡æ¢¯åº¦çš„åå‘ä¼ æ’­å¾—åˆ°ã€‚ç¬¬äºŒéƒ¨åˆ†ç§°ä¸º$g_2$ï¼Œæ›´åˆç†çš„è¿‘ä¼¼ä¸º$g_2â€™$ã€‚<br>$$<br>\begin{aligned}<br>\nabla_{\boldsymbol{\alpha}} \mathcal{L}<em>{\mathrm{val}}\left(\boldsymbol{\omega}^{\star}(\boldsymbol{\alpha}), \boldsymbol{\alpha}\right)|</em>{\boldsymbol{\alpha}&#x3D;\boldsymbol{\alpha}<em>{t}} &#x3D;&amp; \nabla</em>{\boldsymbol{\alpha}} \mathcal{L}<em>{\mathrm{val}}(\boldsymbol{\omega}, \boldsymbol{\alpha})|</em>{\boldsymbol{\omega}&#x3D;\boldsymbol{\omega}^{<em>}\left(\boldsymbol{\alpha}<em>{t}\right), \boldsymbol{\alpha}&#x3D;\boldsymbol{\alpha}</em>{t}} -<br>\<br>&amp; \nabla_{\boldsymbol{\alpha}, \boldsymbol{\omega}}^{2} \mathcal{L}<em>{\mathrm{train}}(\boldsymbol{\omega},<br>\boldsymbol{\alpha})|</em>{\omega&#x3D;\boldsymbol{\omega}^{</em>}<br>\left(\boldsymbol{\alpha}<em>{t}\right),<br>\boldsymbol{\alpha}&#x3D;\boldsymbol{\alpha}</em>{t}} \cdot \mathbf{H}^{-1} \cdot \nabla_{\boldsymbol{\omega}} \mathcal{L}<em>{\mathrm{val}}(\boldsymbol{\omega}, \boldsymbol{\alpha})|</em>{\omega&#x3D;\boldsymbol{\omega}^{<em>}\left(\boldsymbol{\alpha}<em>{t}\right), \boldsymbol{\alpha}&#x3D;\boldsymbol{\alpha}</em>{t}}<br>\end{aligned}<br>$$<br>$$<br>\begin{aligned}<br>\left\langle\mathbf{g}<em>{2}^{\prime}, \mathbf{g}</em>{2}\right\rangle&#x3D;&amp;\left.\left.\eta \cdot \nabla_{\omega} \mathcal{L}<em>{\mathrm{val}}(\boldsymbol{\omega}, \boldsymbol{\alpha})\right|</em>{\omega&#x3D;\omega^{</em>}\left(\boldsymbol{\alpha}<em>{t}\right), \boldsymbol{\alpha}&#x3D;\boldsymbol{\alpha}</em>{t}} ^{\top} \cdot \mathbf{H}^{-1} \cdot \nabla_{\boldsymbol{\omega}, \boldsymbol{\alpha}}^{2} \mathcal{L}<em>{\mathrm{train}}(\boldsymbol{\omega}, \boldsymbol{\alpha})\right|</em>{\omega&#x3D;\boldsymbol{\omega}^{<em>}\left(\boldsymbol{\alpha}<em>{t}\right), \boldsymbol{\alpha}&#x3D;\boldsymbol{\alpha}</em>{t}} \ &amp;\left.\left.\nabla_{\boldsymbol{\alpha}, \boldsymbol{\omega}}^{2} \mathcal{L}<em>{\mathrm{train}}(\boldsymbol{\omega}, \boldsymbol{\alpha})\right|</em>{\omega&#x3D;\boldsymbol{\omega}^{</em>}\left(\boldsymbol{\alpha}<em>{t}\right), \boldsymbol{\alpha}&#x3D;\boldsymbol{\alpha}</em>{t}} \cdot \mathbf{H} \cdot \nabla_{\boldsymbol{\omega}} \mathcal{L}<em>{\mathrm{val}}(\boldsymbol{\omega}, \boldsymbol{\alpha})\right|</em>{\omega&#x3D;\omega^{*}\left(\boldsymbol{\alpha}<em>{t}\right), \boldsymbol{\alpha}&#x3D;\boldsymbol{\alpha}</em>{t}}<br>\end{aligned}<br>$$<br>å¹¶è¯æ˜$g_2â€™$ä¸$g_2$çš„ä¹˜ç§¯æ’å¤§äº0ï¼Œä¹Ÿå°±æ˜¯å¤¹è§’å°äº90åº¦ã€‚</p>
<h2 id="2-DARTS-Improved-Differentiable-Architecture-Search-with-Early-Stopping"><a href="#2-DARTS-Improved-Differentiable-Architecture-Search-with-Early-Stopping" class="headerlink" title="2. DARTS+: Improved Differentiable Architecture Search with Early Stopping"></a>2. DARTS+: Improved Differentiable Architecture Search with Early Stopping</h2><p>éšç€epochæ•°é‡çš„å¢å¤šï¼ŒDARTSå€¾å‘äºskip-connectionï¼Œé€ æˆæ¨¡å‹çš„è¡¨ç°ä¸‹é™</p>
<p>æå‡ºä¸€ç§æå‰åœæ­¢è®­ç»ƒçš„æ ‡å‡†ï¼Œè®©æ¨¡å‹æœç´¢æå‰åœæ­¢ã€‚</p>
<ol>
<li>å½“æ¨¡å‹ä¸­å‡ºç°ä¸¤ä¸ªskip-connectionçš„æ—¶å€™</li>
<li>å½“æ¨¡å‹ä¸­çš„$\alpha$å‚æ•°çš„æ’åˆ—é¡ºåºä¸å†å‘ç”Ÿæ”¹å˜çš„æ—¶å€™($\alpha$çš„å€¼æ˜¯å„ä¸ªPrimitivesçš„æ¦‚ç‡)</li>
</ol>
<h2 id="3-PC-DARTS"><a href="#3-PC-DARTS" class="headerlink" title="3. PC-DARTS"></a>3. PC-DARTS</h2><p>uses partial- channel connections to reduce search time,</p>
<p><img src="/05-ICLR2020_NAS_papers/12-PC-DARTS.png" alt="PC-DARTS"></p>
<ol>
<li><p>Partial Channel Connections</p>
<p>åªå°†1&#x2F;K çš„channelsä½¿ç”¨primitivesè¿æ¥ï¼Œå…¶ä½™çš„channelsé€‰æ‹©ç›´æ¥è¿æ¥ï¼Œä¹Ÿå°±æ˜¯ï¼Œä»$node_i$åˆ°$node_j$çš„è¾¹ä¸­ï¼Œé€‰å‡ºä¸€éƒ¨åˆ†channelä½¿ç”¨éidentityçš„æ–¹å¼è¿æ¥ï¼Œå…¶ä½™çš„ä½¿ç”¨identityï¼Œç»è¿‡éidentityæ–¹å¼çš„channelä¹˜ä»¥softmaxä»¥åçš„$\alpha$æƒé‡ç›¸åŠ ï¼Œå†å’ŒåŸæ¥çš„channelä¸€èµ·concatã€‚<strong>è¿™æ ·åšçš„å¤„ç†ï¼Œæ˜¯å¸Œæœ›å ç”¨çš„å†…å­˜æ›´å°ï¼Œä½¿ç”¨æ›´å¤§çš„batch_sizeï¼Œæå‡è®­ç»ƒå’Œæ¨¡å‹è¡¨ç°ã€‚</strong></p>
<p>å‰Šå¼±äº†weight-freeæ“ä½œçš„å½±å“ã€‚</p>
</li>
<li><p>Edge Normalization</p>
<p>$node_i$å‰é¢æ‰€æœ‰çš„$node$éƒ½éœ€è¦è¾“å‡ºåˆ°å®ƒï¼Œè®¾è®¡æƒé‡$\beta$ï¼Œä¹˜ä»¥è¿™äº›è¾¹ï¼Œå¾—åˆ°$node_i$çš„å€¼ã€‚</p>
</li>
</ol>
<h2 id="4-P-DARTS"><a href="#4-P-DARTS" class="headerlink" title="4. P-DARTS"></a>4. P-DARTS</h2><p>å°†layerçš„æ•°ç›®æ…¢æ…¢å¢åŠ ã€‚</p>
<p><img src="/05-ICLR2020_NAS_papers/01-pdarts1.png" alt="P-DARTS"></p>
<ol>
<li>searching for 25 epochs instead of 50 epochs,</li>
<li>adopting <em>dropout</em> after <em>skip-connect</em>s</li>
<li>manually reducing the number of <em>skip-connect</em>s to two</li>
</ol>
<p>ä¿®å‰ª<em>skip-connection</em>çš„æ•°ç›®æ“ä½œåªèƒ½å‘ç”Ÿåœ¨ç¬¬ä¸€ä¸ª</p>
<h2 id="5-Searching-for-A-Robust-Neural-Architecture-in-Four-GPU-Hours"><a href="#5-Searching-for-A-Robust-Neural-Architecture-in-Four-GPU-Hours" class="headerlink" title="5. Searching for A Robust Neural Architecture in Four GPU Hours"></a>5. Searching for A Robust Neural Architecture in Four GPU Hours</h2><p><img src="/05-ICLR2020_NAS_papers/14-in_four_hours.png" alt="overview"></p>
<p>æ¯æ¬¡åªè®¡ç®—æœ€å¤§æƒé‡çš„æ¢¯åº¦ï¼ŒåªBPæœ€å¤§æƒé‡çš„æ¢¯åº¦ï¼Œä»¥æ­¤æ¥å‡å°‘è®¡ç®—é‡å’ŒGPUæ˜¾å­˜ã€‚</p>
<h2 id="6-ProxylessNAS"><a href="#6-ProxylessNAS" class="headerlink" title="6. ProxylessNAS"></a>6. ProxylessNAS</h2><p>ProxylessNAS ä¸åŒäºä»¥å‰çš„åœ¨ä»£ç†æ•°æ®é›†ä¸Šé¢è¿›è¡Œæœç´¢ä»¥åè½¬ç§»åˆ°å¤§æ•°æ®é›†ç±»ä¼¼ImageNetä¸Šé¢è¿›è¡Œè®­ç»ƒæµ‹è¯•ï¼Œè€Œæ˜¯ç›´æ¥åœ¨å¤§æ•°æ®é›†ä¸Šé¢è¿›è¡Œæœç´¢ï¼Œå®ƒçš„æœç´ çš„ç®—å­æ•°ç›®è¢«å¤§å¤§å‡å°‘ä»¥å‡å°æœç´¢çš„ç©ºé—´ï¼Œé™ä½æœç´¢çš„éš¾åº¦ã€‚</p>
<h2 id="7-SNAS"><a href="#7-SNAS" class="headerlink" title="7. SNAS"></a>7. SNAS</h2><p>SNASæ•…äº‹è®²çš„ä¸ä¸€æ ·ï¼Œä½†æ˜¯æœ¬è´¨ä¸Šæ¥è¯´ï¼Œè·ŸDARTSåŸºæœ¬ä¸€æ ·çš„åŸç†ï¼Œå³ä½¿ç”¨operationçš„åŠ æƒå’Œæ¥ä»£æ›¿å•ç‹¬çš„operationã€‚<br>å®ƒä½¿ç”¨äº†gumble-softmax trickï¼Œ<strong>ä½¿ç”¨æ¦‚ç‡é‡‡æ ·å‡ºçš„æƒå€¼è€Œä¸æ˜¯å›ºå®šçš„æƒå€¼æ¥è®¡ç®—åŠ æƒå’Œ</strong>ï¼ŒåŒæ—¶å¢åŠ temperatureï¼Œä½¿å¾—é‡‡æ ·å‡ºçš„æƒå€¼æ›´åŠ æ¥è¿‘one-hotçš„æƒå€¼ï¼Œæ¥æ‹Ÿåˆå•ç‹¬çš„operationã€‚</p>
<p><img src="/05-ICLR2020_NAS_papers/16-snas.png" alt="snas"></p>
]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>NAS</tag>
      </tags>
  </entry>
  <entry>
    <title>Neural Architecture Search: A Survey</title>
    <url>/2020/11/01/06-NAS-Survey/</url>
    <content><![CDATA[<p>ç›®å‰å­˜åœ¨çš„åº”ç”¨<br>image classification<br>object detection<br>semantic segmentation</p>
<p>NAS can be seen as subfield of AutoML (Hutter et al., 2019) and has significant overlap with hyperparameter optimization (Feurer and Hutter, 2019) and meta-learning (Vanschoren, 2019).<br>AutoMLçš„å­é¢†åŸŸ<br>NASä¸å…ƒå­¦ä¹ å’Œè¶…å‚æ•°ä¼˜åŒ–æœ‰å¾ˆå¤šé‡åˆçš„åœ°æ–¹</p>
<p>NASçš„æ–¹æ³•åˆ†ä¸ºä¸‰ç±»ï¼š</p>
<ol>
<li>search space</li>
<li>search strategy</li>
<li>performance estimation strategy</li>
</ol>
<p><img src="/06-NAS-Survey/01-NAS-methods.png" alt="NAS methods"></p>
<ul>
<li>Search Space. åŸåˆ™ä¸Šå®šä¹‰äº†å“ªäº›æ¶æ„å¯ä»¥è¢«è¡¨ç¤ºï¼Œå…ˆéªŒçŸ¥è¯†ç¼©å°äº†search spaceï¼ŒåŒæ—¶ä¹Ÿå¯èƒ½æ¼æ‰è¶…å‡ºäººç±»è®¤çŸ¥çš„æ¶æ„</li>
<li>Search Strategy.æœç´¢ç­–ç•¥è¯¦ç»†æè¿°äº†å¦‚ä½•æ¢ç´¢æœç´¢ç©ºé—´(é€šå¸¸æ˜¯æŒ‡æ•°çº§å¤§çš„ï¼Œç”šè‡³æ˜¯æ— ç•Œçš„)ã€‚å®ƒåŒ…å«äº†ç‰©ç†çš„æ¢ç´¢-åˆ©ç”¨æƒè¡¡ï¼Œå› ä¸ºä¸€æ–¹é¢ï¼Œå¿«é€Ÿæ‰¾åˆ°æ€§èƒ½è‰¯å¥½çš„æ¶æ„æ˜¯å¯å–çš„ï¼Œè€Œå¦ä¸€æ–¹é¢ï¼Œåº”è¯¥é¿å…è¿‡æ—©åœ°æ”¶æ•›åˆ°æ¬¡ä¼˜æ¶æ„çš„åŒºåŸŸã€‚</li>
<li>Performance Estimation Strategy.<br>ç®€å•çš„å¯¹æ‰€æœ‰æ•°æ®è¿›è¡Œæ ‡å‡†è®­ç»ƒå’Œæµ‹è¯•ï¼Œä½†æ˜¯è¿™ç§æ–¹æ¡ˆè®¡ç®—å¤ªè¿‡æ˜‚è´µï¼Œå¹¶ä¸”é™åˆ¶äº†å¯ä»¥ç ”ç©¶çš„ä½“ç³»ç»“æ„çš„æ•°é‡</li>
</ul>
<h2 id="1-search-space"><a href="#1-search-space" class="headerlink" title="1. search space"></a>1. search space</h2><h3 id="chain-structured-neural-network-architecture"><a href="#chain-structured-neural-network-architecture" class="headerlink" title="chain-structured neural network architecture"></a>chain-structured neural network architecture</h3><p><img src="/06-NAS-Survey/09-chain.png" alt="chain"><br>æœç´¢ç©ºé—´çš„å½±å“å› ç´ </p>
<ol>
<li>å±‚çš„æ•°ç›®</li>
<li>æ¯ä¸€å±‚çš„ç§ç±» pooling, conv, skip-connection, etc</li>
<li>è¶…å‚æ•°</li>
</ol>
<h3 id="cell-based-model"><a href="#cell-based-model" class="headerlink" title="cell-based model"></a>cell-based model</h3><p><img src="/06-NAS-Survey/10-cell.png" alt="cell"></p>
<ul>
<li>normal cell</li>
<li>reduction cell</li>
</ul>
<p>ä¼˜ç‚¹ï¼š</p>
<ol>
<li>The size of the search space is drastically reduced<br>æœç´¢ç©ºé—´å¤§å¤§å‡å°</li>
<li>Architectures built from cells can more easily be transferred or adapted to other data sets by simply varying the number of cells and filters used within a model<br>å¯ç§»æ¤æ€§æ¯”è¾ƒå¥½</li>
<li>Creating architectures by repeating building blocks has proven a useful design prin- ciple in general, such as repeating an LSTM block in RNNs or stacking a residual block.<br>å·²ç»è¯æ˜å åŠ ç½‘ç»œæ˜¯æœ‰æ•ˆçš„è®¾è®¡å‡†åˆ™ï¼Œå¦‚LSTMï¼ŒRNNï¼Œres-block</li>
</ol>
<h3 id="macro-architecture"><a href="#macro-architecture" class="headerlink" title="macro-architecture"></a>macro-architecture</h3><p>how many cells shall be used and how should they be connected to build the actual model</p>
<h2 id="2-search-strategy"><a href="#2-search-strategy" class="headerlink" title="2. search strategy"></a>2. search strategy</h2><ul>
<li>random search</li>
<li>Bayesian optimization</li>
<li>evolutionary methods</li>
<li>reinforcement learning (RL)</li>
<li>gradient-based methods.</li>
</ul>
<ol>
<li><p>no interaction with an environment occurs during this sequential process (no external state is observed, and there are no intermediate rewards)<br>å°†æ¶æ„å–æ ·çš„è¿‡ç¨‹å½“åšsingle actionçš„çº¿æ€§ç”Ÿæˆè¿‡ç¨‹ï¼Œå°†RLé—®é¢˜è½¬æ¢ä¸ºæ— çŠ¶æ€å¤šæ­¦è£…å¼ºç›—é—®é¢˜ã€‚</p>
</li>
<li><p>frame NAS as a sequential decision process</p>
</li>
<li><p>deal with variable-length network architectures</p>
</li>
</ol>
<p><strong>use a bi-directional LSTM to encode architectures into a fixed-length representation</strong></p>
<ol start="4">
<li><p>ä½¿ç”¨gradient-based methodå»ä¼˜åŒ–æƒé‡ï¼Œä½¿ç”¨è¿›åŒ–ç®—æ³•ä»…ä»…å»ä¼˜åŒ–ç¥ç»ç½‘ç»œçš„æ¶æ„</p>
</li>
<li><p>Neuro-evolutionaryæ–¹æ³•ä¸åŒçš„åœ°æ–¹åœ¨äºhow they sample parents, update populations, and generate offsprings</p>
<p> <a href="https://arxiv.org/abs/1804.09081">Efficient multi-objective neural architecture search via lamarckian evolution.</a> åä»£ä»çˆ¶ç½‘ç»œä¸­ç»§æ‰¿æƒé‡</p>
<p> <a href="https://arxiv.org/pdf/1703.01041.pdf">Large-scale evolution of image classifiers</a> åä»£ä»çˆ¶ç½‘ç»œä¸­ç»§æ‰¿æ²¡æœ‰è¢«çªå˜å½±å“çš„æƒé‡</p>
</li>
<li><p>Monte Carlo Tree Search. hill climbing</p>
</li>
<li><p>optimize both the network weights and the network architecture by alternating gradient descent steps on training data for weights and on validation data for architectural parameters such as. äº¤æ›¿ä½¿ç”¨æ¢¯åº¦ä¸‹é™æ³•ï¼Œåœ¨è®­ç»ƒé›†ä¸Šè®­ç»ƒæƒé‡ï¼Œåœ¨éªŒè¯é›†ä¸Šæ›´æ”¹æ¶æ„å‚æ•°</p>
</li>
<li><p>åœ¨å¯èƒ½çš„æ“ä½œé›†åˆä¸Šé¢ä¼˜åŒ–å¸¦å‚çš„åˆ†å¸ƒ</p>
</li>
<li><p>ä¼˜åŒ–å±‚çš„è¶…å‚æ•°å’Œè¿æ¥æ¨¡å¼</p>
</li>
</ol>
<h2 id="3-Performance-Estimation-Strategy"><a href="#3-Performance-Estimation-Strategy" class="headerlink" title="3. Performance Estimation Strategy"></a>3. Performance Estimation Strategy</h2><p><img src="/06-NAS-Survey/11-overview_of_different_methods_for_speeding_up.png" alt="speed-up method"></p>
<h2 id="4-directions"><a href="#4-directions" class="headerlink" title="4. directions"></a>4. directions</h2><p>äººç±»å®šä¹‰æœç´¢ç©ºé—´çš„å¤§å°ç›¸æ¯”è¾ƒå¯»æ‰¾æ€§èƒ½æ›´å¥½çš„ç½‘ç»œæ¶æ„æ›´ç®€å•ï¼Œä½†åŒæ—¶ä¹Ÿé™åˆ¶äº†NASä¸å¤ªå¯èƒ½æ‰¾åˆ°æœ¬è´¨ä¸Šä¼˜äºç°åœ¨æ¶æ„çš„ç½‘ç»œæ¶æ„</p>
<p>åº”ç”¨åœ¨image restoration<br>semantic segmentation<br>reinforcement learning<br>ç­‰ç­‰ä¸Šé¢</p>
<p>GAN sensor, fusion</p>
<p>multi-task problems<br>multi-objective problems</p>
<p>extending one-shot NAS to generate different architectures depending on the task or instance on-the-fly.</p>
<p>search spaceçš„é€‰æ‹©</p>
<p>æ›´åŠ ç»†ç²’åº¦cellçš„æ„å»ºï¼Œèƒ½å¦å¤§å¤§åŠ å¼ºNASçš„èƒ½åŠ›</p>
<p>æ–°çš„æ•°æ®é›†ï¼šNas-bench-101: Towards reproducible neural architecture search</p>
<p>Learning Augmentation Policies from Data</p>
]]></content>
      <categories>
        <category>Survey</category>
      </categories>
      <tags>
        <tag>NAS</tag>
      </tags>
  </entry>
  <entry>
    <title>Graph Neural Networks: A review of methods and applications</title>
    <url>/2020/06/15/07-gnn-review1/</url>
    <content><![CDATA[<h2 id="Graph-Neural-Networks-A-review-of-methods-and-applications"><a href="#Graph-Neural-Networks-A-review-of-methods-and-applications" class="headerlink" title="Graph Neural Networks: A review of methods and applications"></a>Graph Neural Networks: A review of methods and applications</h2><h2 id="1-introduction"><a href="#1-introduction" class="headerlink" title="1. introduction"></a>1. introduction</h2><ol>
<li>social science (social networks)</li>
<li>natural science (physical systems</li>
<li>protein-protein interaction networks</li>
<li>knowledge graphs</li>
</ol>
<p>å¸¸è§çš„æ¬§å‡ é‡Œå¾—ç»“æ„åŒ–æ•°æ®ä¸»è¦åŒ…å«ï¼š</p>
<p>1Dï¼šå£°éŸ³ï¼Œæ—¶é—´åºåˆ—ç­‰ï¼›<br>2Dï¼šå›¾åƒç­‰ï¼›<br>3Dï¼šè§†é¢‘ï¼Œé«˜å…‰è°±å›¾åƒç­‰ï¼›</p>
<h3 id="1-1-motivation"><a href="#1-1-motivation" class="headerlink" title="1.1 motivation"></a>1.1 motivation</h3><ol>
<li>CNN<ul>
<li>å±€éƒ¨è¿æ¥</li>
<li>å…±äº«æƒé‡</li>
<li>å¤šå±‚ç½‘ç»œ</li>
</ul>
</li>
<li>graph embedding<ul>
<li>åœ¨ encoder ä¸­ï¼ŒèŠ‚ç‚¹ä¹‹é—´æ²¡æœ‰å…±äº«å‚æ•°ï¼Œè¿™å¯¼è‡´è®¡ç®—æ•ˆç‡ä½ä¸‹ï¼Œå› ä¸ºè¿™æ„å‘³ç€å‚æ•°çš„æ•°é‡éšç€èŠ‚ç‚¹çš„æ•°é‡çº¿æ€§å¢é•¿</li>
<li>ç›´æ¥åµŒå…¥æ–¹æ³•ç¼ºä¹æ³›åŒ–èƒ½åŠ›ï¼Œè¿™æ„å‘³ç€å®ƒä»¬æ— æ³•å¤„ç†åŠ¨æ€å›¾å½¢æˆ–æ¨å¹¿åˆ°æ–°å›¾å½¢</li>
</ul>
</li>
</ol>
<h3 id="1-2-ä¼˜ç‚¹"><a href="#1-2-ä¼˜ç‚¹" class="headerlink" title="1.2 ä¼˜ç‚¹"></a>1.2 ä¼˜ç‚¹</h3><ol>
<li><p>CNN å’Œ RNN è¿™æ ·çš„æ ‡å‡†ç¥ç»ç½‘ç»œæ— æ³•å¤„ç†æ²¡æœ‰è‡ªç„¶èŠ‚ç‚¹é¡ºåºçš„ä¸è§„åˆ™å›¾æ•°æ®ï¼Œè€Œ GNN åœ¨æ¯ä¸ªèŠ‚ç‚¹ä¸Šåˆ†åˆ«ä¼ æ’­ï¼Œå¿½ç•¥äº†èŠ‚ç‚¹çš„è¾“å…¥é¡ºåºã€‚å³ï¼ŒGNN çš„è¾“å‡ºå¯¹äºèŠ‚ç‚¹çš„è¾“å…¥é¡ºåºæ˜¯ä¸å˜çš„ã€‚</p>
</li>
<li><p>å›¾ä¸­çš„è¾¹è¡¨ç¤ºäº†ä¸¤ä¸ªèŠ‚ç‚¹ä¹‹é—´çš„ä¾èµ–å…³ç³»çš„ä¿¡æ¯ã€‚åœ¨æ ‡å‡†çš„ç¥ç»ç½‘ç»œä¸­ï¼Œè¿™äº›ä¾èµ–ä¿¡æ¯åªæ˜¯ä½œä¸ºèŠ‚ç‚¹çš„ç‰¹å¾ã€‚ç„¶åï¼ŒGNN å¯ä»¥é€šè¿‡å›¾å½¢ç»“æ„è¿›è¡Œä¼ æ’­ï¼Œè€Œä¸æ˜¯å°†å…¶ä½œä¸ºç‰¹å¾çš„ä¸€éƒ¨åˆ†ã€‚é€šå¸¸ï¼ŒGNN é€šè¿‡å…¶é‚»åŸŸçš„çŠ¶æ€çš„<strong>åŠ æƒå’Œ</strong>æ¥æ›´æ–°èŠ‚ç‚¹çš„éšè—çŠ¶æ€ã€‚</p>
</li>
<li><p>æ¨ç†æ˜¯é«˜çº§äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªéå¸¸é‡è¦çš„ç ”ç©¶è¯¾é¢˜ï¼Œäººè„‘ä¸­çš„æ¨ç†è¿‡ç¨‹å‡ ä¹éƒ½æ˜¯åŸºäºä»æ—¥å¸¸ç»éªŒä¸­æå–çš„å›¾å½¢ã€‚æ ‡å‡†ç¥ç»ç½‘ç»œå·²ç»æ˜¾ç¤ºå‡ºé€šè¿‡å­¦ä¹ æ•°æ®åˆ†å¸ƒæ¥ç”Ÿæˆåˆæˆå›¾åƒå’Œæ–‡æ¡£çš„èƒ½åŠ›ï¼ŒåŒæ—¶å®ƒä»¬ä»ç„¶æ— æ³•ä»å¤§å‹å®éªŒæ•°æ®ä¸­å­¦ä¹ æ¨ç†å›¾ã€‚ç„¶è€Œï¼ŒGNN æ¢ç´¢ä»åœºæ™¯å›¾ç‰‡å’Œæ•…äº‹æ–‡æ¡£ç­‰éç»“æ„æ€§æ•°æ®ç”Ÿæˆå›¾å½¢ï¼Œè¿™å¯ä»¥æˆä¸ºè¿›ä¸€æ­¥é«˜çº§ AI çš„å¼ºå¤§ç¥ç»æ¨¡å‹ã€‚</p>
</li>
</ol>
<h2 id="2-æ¨¡å‹"><a href="#2-æ¨¡å‹" class="headerlink" title="2. æ¨¡å‹"></a>2. æ¨¡å‹</h2><h3 id="2-1-é™åˆ¶"><a href="#2-1-é™åˆ¶" class="headerlink" title="2.1 é™åˆ¶"></a>2.1 é™åˆ¶</h3><p>è™½ç„¶å®éªŒç»“æœè¡¨æ˜ GNN æ˜¯ä¸€ç§ç”¨äºå»ºæ¨¡ç»“æ„æ•°æ®çš„å¼ºå¤§æ¶æ„ï¼Œä½†åŸå§‹ GNN ä»ç„¶å­˜åœ¨ä¸€äº›å±€é™æ€§ã€‚</p>
<ol>
<li>å¯¹äºå›ºå®šç‚¹æ¥è¿­ä»£æ›´æ–°èŠ‚ç‚¹çš„éšè—çŠ¶æ€æ˜¯ååˆ†ä½æ•ˆçš„ã€‚å¦‚æœæ”¾å®½å›ºå®šç‚¹çš„å‡è®¾ï¼Œå¯ä»¥è®¾è®¡ä¸€ä¸ªå¤šå±‚ GNN æ¥è·å¾—èŠ‚ç‚¹åŠå…¶é‚»åŸŸçš„ç¨³å®šè¡¨ç¤ºã€‚</li>
<li>GNN åœ¨è¿­ä»£ä¸­ä½¿ç”¨ç›¸åŒçš„å‚æ•°ï¼Œè€Œå¤§å¤šæ•°æµè¡Œçš„ç¥ç»ç½‘ç»œåœ¨ä¸åŒçš„å±‚ä¸­ä½¿ç”¨ä¸åŒçš„å‚æ•°æ¥è¿›è¡Œåˆ†å±‚ç‰¹å¾æå–ã€‚æ­¤å¤–ï¼ŒèŠ‚ç‚¹éšè—çŠ¶æ€çš„æ›´æ–°æ˜¯ä¸€ä¸ªé¡ºåºè¿‡ç¨‹ï¼Œå¯ä»¥åˆ©ç”¨ RNN å†…æ ¸ï¼Œå¦‚ GRU å’Œ LSTMï¼Œæ¥è¿›ä¸€æ­¥ä¼˜åŒ–ã€‚</li>
<li>å­˜åœ¨ä¸€äº›è¾¹ç¼˜ï¼ˆedgesï¼‰çš„ä¿¡æ¯ç‰¹å¾æ— æ³•åœ¨åŸå§‹ GNN ä¸­æœ‰æ•ˆå»ºæ¨¡ã€‚ä¾‹å¦‚ï¼ŒçŸ¥è¯†å›¾ä¸­çš„è¾¹ç¼˜å…·æœ‰å…³ç³»ç±»å‹ï¼Œå¹¶ä¸”é€šè¿‡ä¸åŒè¾¹ç¼˜çš„æ¶ˆæ¯ä¼ æ’­åº”æ ¹æ®å…¶ç±»å‹è€Œä¸åŒã€‚æ­¤å¤–ï¼Œå¦‚ä½•å­¦ä¹ è¾¹ç¼˜çš„éšè—çŠ¶æ€ä¹Ÿæ˜¯ä¸€ä¸ªé‡è¦é—®é¢˜ã€‚</li>
<li>å¦‚æœæˆ‘ä»¬ä¸“æ³¨äºèŠ‚ç‚¹çš„è¡¨ç¤ºè€Œä¸æ˜¯å›¾å½¢ï¼Œåˆ™ä¸é€‚åˆä½¿ç”¨å›ºå®šç‚¹ï¼Œå› ä¸ºå›ºå®šç‚¹ä¸­çš„è¡¨ç¤ºåˆ†å¸ƒå°†åœ¨å€¼ä¸Šéå¸¸å¹³æ»‘å¹¶ä¸”ç”¨äºåŒºåˆ†æ¯ä¸ªèŠ‚ç‚¹çš„ä¿¡æ¯é‡è¾ƒå°‘ã€‚</li>
</ol>
<h3 id="2-2-GNNçš„-å˜ä½“"><a href="#2-2-GNNçš„-å˜ä½“" class="headerlink" title="2.2 GNNçš„ å˜ä½“"></a>2.2 GNNçš„ å˜ä½“</h3><h4 id="2-2-1-å›¾ç±»å‹"><a href="#2-2-1-å›¾ç±»å‹" class="headerlink" title="2.2.1 å›¾ç±»å‹"></a>2.2.1 å›¾ç±»å‹</h4><p>åœ¨åŸå§‹çš„ GNN ä¸­ï¼Œè¾“å…¥çš„å›¾å½¢åŒ…æ‹¬å¸¦æœ‰æ ‡ç­¾ä¿¡æ¯çš„èŠ‚ç‚¹å’Œæ— å‘çš„è¾¹ï¼Œè¿™æ˜¯ä¸€ç§æœ€ç®€å•çš„å›¾å½¢å¼ã€‚ä½†åœ¨ç°å®ç”Ÿæ´»ä¸­ï¼Œå­˜åœ¨å¤šç§å›¾çš„å˜ä½“ï¼Œä¸»è¦åŒ…æ‹¬æœ‰å‘å›¾ã€å¼‚æ„å›¾å’Œå¸¦æœ‰è¾¹ä¿¡æ¯çš„å›¾ã€‚</p>
<ol>
<li>æœ‰å‘å›¾ï¼šå³å›¾ä¸­çš„è¾¹æ˜¯å­˜åœ¨æ–¹å‘çš„ã€‚æœ‰å‘è¾¹å¯ä»¥å¸¦æ¥æ¯”æ— å‘è¾¹æ›´å¤šçš„ä¿¡æ¯ã€‚</li>
<li>å¼‚æ„å›¾ï¼šå³å›¾ä¸­å­˜åœ¨å¤šç§ç±»å‹çš„èŠ‚ç‚¹ã€‚å¤„ç†å¼‚æ„å›¾çš„æœ€ç®€å•æ–¹æ³•æ˜¯å°†æ¯ä¸ªèŠ‚ç‚¹çš„ç±»å‹è½¬æ¢ä¸ºä¸åŸå§‹ç‰¹å¾è¿æ¥çš„ one-hot ç‰¹å¾å‘é‡ã€‚</li>
<li>å¸¦æœ‰è¾¹ä¿¡æ¯çš„å›¾ï¼šå³å›¾ä¸­çš„æ¯æ¡è¾¹ä¹Ÿå­˜åœ¨æƒé‡æˆ–ç±»å‹ç­‰ä¿¡æ¯ã€‚è¿™ç§ç±»å‹çš„å›¾æœ‰ä¸¤ç§è§£å†³åŠæ³•ï¼Œä¸€ç§æ˜¯å°†å›¾å½¢è½¬åŒ–ä¸ºäºŒéƒ¨å›¾ï¼ŒåŸå§‹è¾¹ä¹Ÿä½œä¸ºèŠ‚ç‚¹ï¼Œå¹¶å°†å…¶åˆ†å‰²æˆä¸¤æ¡æ–°çš„è¾¹ï¼Œåˆ†åˆ«è¿æ¥åŸå§‹è¾¹çš„ä¸¤ç«¯èŠ‚ç‚¹ï¼›ç¬¬äºŒç§æ–¹æ³•æ˜¯è°ƒæ•´ä¸åŒçš„æƒé‡çŸ©é˜µï¼Œä»¥ä¾¿åœ¨ä¸åŒç±»å‹çš„è¾¹ç¼˜ä¸Šä¼ æ’­ã€‚</li>
</ol>
<p><img src="/07-gnn-review1/01-graph_types.png" alt="graph types"></p>
<h4 id="2-2-2-ä¼ æ’­ç±»å‹"><a href="#2-2-2-ä¼ æ’­ç±»å‹" class="headerlink" title="2.2.2 ä¼ æ’­ç±»å‹"></a>2.2.2 ä¼ æ’­ç±»å‹</h4><p>å¯¹äºè·å–èŠ‚ç‚¹æˆ–è€…è¾¹çš„éšè—çŠ¶æ€ï¼Œç¥ç»ç½‘ç»œä¸­çš„ä¼ æ’­æ­¥éª¤å’Œè¾“å‡ºæ­¥éª¤è‡³å…³é‡è¦ã€‚åœ¨ä¼ æ’­æ­¥éª¤æ–¹é¢çš„æ”¹è¿›ä¸»è¦æœ‰å·ç§¯ã€æ³¨æ„åŠ›æœºåˆ¶ã€é—¨æœºåˆ¶å’Œè·³è·ƒè¿æ¥ï¼ˆskip connectionï¼‰ï¼Œè€Œåœ¨è¾“å‡ºæ­¥éª¤é€šå¸¸éµå¾ªç®€å•çš„å‰é¦ˆç¥ç»ç½‘ç»œè®¾ç½®ã€‚</p>
<ol>
<li>å·ç§¯ã€‚Graph Convolutional Networkï¼ˆGCNï¼‰å¸Œæœ›å°†å·ç§¯æ“ä½œåº”ç”¨åœ¨å›¾ç»“æ„æ•°æ®ä¸Šï¼Œä¸»è¦åˆ†ä¸º Spectral Method å’Œ Spatial Methodï¼ˆNon-spectral Methodï¼‰ä¸¤ç±»ã€‚Spectral Method å¸Œæœ›ä½¿ç”¨è°±åˆ†è§£çš„æ–¹æ³•ï¼Œåº”ç”¨å›¾çš„æ‹‰æ™®æ‹‰æ–¯çŸ©é˜µåˆ†è§£è¿›è¡ŒèŠ‚ç‚¹çš„ä¿¡æ¯æ”¶é›†ã€‚Spatial Method ç›´æ¥ä½¿ç”¨å›¾çš„æ‹“æ‰‘ç»“æ„ï¼Œæ ¹æ®å›¾çš„é‚»å±…ä¿¡æ¯è¿›è¡Œä¿¡æ¯æ”¶é›†ã€‚</li>
<li>æ³¨æ„åŠ›æœºåˆ¶ã€‚Graph Attention Network è‡´åŠ›äºå°†æ³¨æ„åŠ›æœºåˆ¶åº”ç”¨åœ¨å›¾ä¸­çš„ä¿¡æ¯æ”¶é›†é˜¶æ®µã€‚</li>
<li>é—¨æœºåˆ¶ã€‚è¿™äº›å˜ä½“å°†é—¨æœºåˆ¶åº”ç”¨äºèŠ‚ç‚¹æ›´æ–°é˜¶æ®µã€‚Gated graph neural network å°† GRU æœºåˆ¶åº”ç”¨äºèŠ‚ç‚¹æ›´æ–°ã€‚å¾ˆå¤šå·¥ä½œè‡´åŠ›äºå°† LSTM åº”ç”¨äºä¸åŒç±»å‹çš„å›¾ä¸Šï¼Œæ ¹æ®å…·ä½“æƒ…å¢ƒçš„ä¸åŒï¼Œå¯ä»¥åˆ†ä¸º Tree LSTMã€Graph LSTM å’Œ Sentence LSTM ç­‰ã€‚</li>
<li>æ®‹å·®è¿æ¥ã€‚æ³¨æ„åˆ°å †å å¤šå±‚å›¾ç¥ç»ç½‘ç»œå¯èƒ½å¼•èµ·ä¿¡æ¯å¹³æ»‘çš„é—®é¢˜ï¼Œå¾ˆå¤šå·¥ä½œå°†æ®‹å·®æœºåˆ¶åº”ç”¨äºå›¾ç¥ç»ç½‘ç»œä¸­ï¼Œæ–‡ä¸­ä»‹ç»äº† Highway GNN å’Œ Jump Knowledge Network ä¸¤ç§ä¸åŒçš„å¤„ç†æ–¹å¼</li>
</ol>
<p><img src="/07-gnn-review1/02-propagation_types.png" alt="propagation types"></p>
<h4 id="2-2-3-è®­ç»ƒæ–¹æ³•"><a href="#2-2-3-è®­ç»ƒæ–¹æ³•" class="headerlink" title="2.2.3 è®­ç»ƒæ–¹æ³•"></a>2.2.3 è®­ç»ƒæ–¹æ³•</h4><p>åŸå§‹å›¾å·ç§¯ç¥ç»ç½‘ç»œåœ¨è®­ç»ƒå’Œä¼˜åŒ–æ–¹æ³•ä¸­å…·æœ‰è‹¥å¹²ç¼ºç‚¹ã€‚ä¾‹å¦‚ï¼Œ</p>
<ol>
<li>GCN éœ€è¦å®Œæ•´çš„å›¾æ‹‰æ™®æ‹‰æ–¯ç®—å­ï¼Œè¿™å¯¹äºå¤§å›¾æ¥è¯´æ˜¯<strong>è®¡ç®—æˆæœ¬ååˆ†é«˜</strong>ã€‚</li>
<li>è€Œä¸”ï¼Œå±‚ ğ¿ çš„èŠ‚ç‚¹çš„åµŒå…¥æ˜¯é€šè¿‡å±‚ $ğ¿âˆ’1$ çš„æ‰€æœ‰è¯¥èŠ‚ç‚¹çš„é‚»å±…æ¥è¿›è¡Œè®¡ç®—çš„ã€‚å› æ­¤ï¼Œå•ä¸ªèŠ‚ç‚¹çš„æ„ŸçŸ¥åŸŸç›¸å¯¹äºå±‚æ•°å‘ˆæŒ‡æ•°å¢é•¿ï¼Œ<strong>å•ä¸ªèŠ‚ç‚¹çš„è®¡ç®—æ¢¯åº¦æˆæœ¬å¾ˆé«˜</strong>ã€‚</li>
<li>æœ€åï¼ŒGCN é’ˆå¯¹å›ºå®šå›¾å½¢è¿›è¡Œç‹¬ç«‹è®­ç»ƒï¼Œ<strong>ç¼ºä¹å½’çº³å­¦ä¹ çš„èƒ½åŠ›</strong>ã€‚</li>
</ol>
<h3 id="2-3-é€šç”¨æ¡†æ¶"><a href="#2-3-é€šç”¨æ¡†æ¶" class="headerlink" title="2.3 é€šç”¨æ¡†æ¶"></a>2.3 é€šç”¨æ¡†æ¶</h3><p>é™¤äº†æå‡ºå›¾ç¥ç»ç½‘ç»œçš„ä¸åŒå˜ä½“ä¹‹å¤–ï¼Œä¸€äº›ç ”ç©¶äººå‘˜ä»ç¥ç»ç½‘ç»œçš„æ¡†æ¶å…¥æ‰‹ï¼Œæå‡ºäº†ä¸€äº›é€šç”¨æ¡†æ¶ï¼Œæ—¨åœ¨å°†ä¸åŒæ¨¡å‹é›†æˆåˆ°ä¸€ä¸ªå•ä¸€æ¡†æ¶ä¸­ã€‚ä¸»è¦åŒ…æ‹¬ Message Passing Neural Networksï¼ˆMPNNï¼‰ã€Non-local Neural Networksï¼ˆNLNNï¼‰ä»¥åŠ Graph Networkï¼ˆGNï¼‰ç­‰ã€‚</p>
<ol>
<li><p>Message Passing Neural Networks<br> é’ˆå¯¹å›¾ç»“æ„çš„ç›‘ç£å­¦ä¹ æ¡†æ¶ï¼ŒMPNNæ¡†æ¶æŠ½è±¡äº†å‡ ç§æœ€æµè¡Œçš„å›¾å½¢ç»“æ„æ•°æ®æ¨¡å‹ï¼ˆå¦‚å›¾å·ç§¯ä¸­çš„å…‰è°±æ–¹æ³•å’Œéå…‰è°±æ–¹æ³•ï¼Œé—¨æ§ç¥ç»ç½‘ç»œï¼Œäº¤äº’ç½‘ç»œï¼Œåˆ†å­å›¾å·ç§¯ï¼Œæ·±åº¦å¼ é‡ç¥ç»ç½‘ç»œç­‰ï¼‰ä¹‹é—´çš„å…±æ€§ï¼Œ</p>
</li>
<li><p>Non-local Neural Networks<br> NLNNåˆ©ç”¨æ·±åº¦å­¦ä¹ æ•æ‰é•¿èŒƒå›´çš„ä¾èµ–å…³ç³»ï¼Œè¿™æ˜¯å¯¹éå±€éƒ¨å¹³å‡è¿ç®—çš„ä¸€ç§æ³›åŒ–ï¼Œéå±€éƒ¨è¿ç®—é€šè¿‡è®¡ç®—å¯¹æ‰€æœ‰ä½ç½®çš„ç‰¹å¾çš„åŠ æƒå’Œæ¥å¾—åˆ°å½“å‰ä½ç½®çš„å½±å“ï¼Œæ­¤å¤„çš„ä½ç½®é›†åˆå¯ä»¥æ˜¯ç©ºé—´ã€æ—¶é—´æˆ–è€…æ—¶ç©ºã€‚</p>
</li>
<li><p>Graph Networks<br> GNè¢«æå‡ºæ¥æ³›åŒ–å’Œæ‰©å±•å¤šç§å›¾ç¥ç»ç½‘ç»œï¼Œä»¥åŠ MPNN å’Œ NLNN æ–¹æ³•ã€‚æœ¬æ–‡ä¸»è¦ä»‹ç»äº†å›¾çš„å®šä¹‰ã€GN blockã€æ ¸å¿ƒ GN è®¡ç®—å•å…ƒã€è®¡ç®—æ­¥éª¤å’ŒåŸºæœ¬è®¾è®¡åŸåˆ™ã€‚è¯¦ç»†çš„å†…å®¹æ‰©å±•ä¼šå¦å¤–å†™åˆ°ä¸“é—¨é’ˆå¯¹è¯¥æ–‡çŒ®çš„é˜…è¯»ç¬”è®°å½“ä¸­ã€‚</p>
</li>
</ol>
<h2 id="3-åº”ç”¨"><a href="#3-åº”ç”¨" class="headerlink" title="3. åº”ç”¨"></a>3. åº”ç”¨</h2><p><img src="/07-gnn-review1/03-applications.png" alt="applications"></p>
<h2 id="4-å¼€æ”¾æ€§é—®é¢˜"><a href="#4-å¼€æ”¾æ€§é—®é¢˜" class="headerlink" title="4. å¼€æ”¾æ€§é—®é¢˜"></a>4. å¼€æ”¾æ€§é—®é¢˜</h2><h3 id="4-1-æµ…å±‚ç»“æ„"><a href="#4-1-æµ…å±‚ç»“æ„" class="headerlink" title="4.1 æµ…å±‚ç»“æ„"></a>4.1 æµ…å±‚ç»“æ„</h3><p>ä¼ ç»Ÿçš„æ·±åº¦ç¥ç»ç½‘ç»œå¯ä»¥å †å æ•°ç™¾å±‚ä»¥è·å¾—æ›´å¥½çš„æ€§èƒ½ï¼Œå› ä¸ºæ›´æ·±çš„ç»“æ„å…·æœ‰æ›´å¤šçš„å‚æ•°ï¼Œä»è€Œèƒ½å¤Ÿæ˜¾è‘—æé«˜è¡¨ç¤ºèƒ½åŠ›ã€‚è€Œå›¾ç¥ç»ç½‘ç»œé€šå¸¸éƒ½å¾ˆæµ…ï¼Œå¤§å¤šæ•°ä¸è¶…è¿‡ä¸‰å±‚ã€‚æ­£å¦‚ [5] ä¸­çš„å®éªŒæ‰€ç¤ºï¼Œå †å å¤šä¸ª GCN å±‚å°†å¯¼è‡´è¿‡åº¦å¹³æ»‘ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œæ‰€æœ‰é¡¶ç‚¹å°†æ”¶æ•›åˆ°ç›¸åŒçš„å€¼ã€‚å°½ç®¡ä¸€äº›ç ”ç©¶äººå‘˜è®¾æ³•è§£å†³äº†è¿™ä¸ªé—®é¢˜ï¼Œä½†å®ƒä»ç„¶æ˜¯ GNN çš„æœ€å¤§é™åˆ¶ã€‚è®¾è®¡çœŸæ­£çš„æ·±åº¦ GNN å¯¹äºæœªæ¥çš„ç ”ç©¶æ¥è¯´æ˜¯ä¸€ä¸ªä»¤äººå…´å¥‹çš„æŒ‘æˆ˜ï¼Œå¹¶å°†å¯¹ç†è§£ GNN åšå‡ºç›¸å½“å¤§çš„è´¡çŒ®ã€‚</p>
<h3 id="4-2-åŠ¨æ€å›¾ç»“æ„"><a href="#4-2-åŠ¨æ€å›¾ç»“æ„" class="headerlink" title="4.2 åŠ¨æ€å›¾ç»“æ„"></a>4.2 åŠ¨æ€å›¾ç»“æ„</h3><p>å¦ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„é—®é¢˜æ˜¯å¦‚ä½•å¤„ç†å…·æœ‰åŠ¨æ€ç»“æ„çš„å›¾å½¢ã€‚é™æ€å›¾æ˜¯ç¨³å®šçš„ï¼Œå› æ­¤å¯ä»¥å®¹æ˜“åœ°å»ºæ¨¡ï¼Œè€ŒåŠ¨æ€å›¾åˆ™å¼•å…¥å˜åŒ–çš„ç»“æ„ã€‚å½“è¾¹å’ŒèŠ‚ç‚¹å‡ºç°æˆ–æ¶ˆå¤±æ—¶ï¼ŒGNN æ— æ³•è‡ªé€‚åº”åœ°æ›´æ”¹ã€‚<br>åŠ¨æ€ GNN æ­£åœ¨ç§¯æç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬è®¤ä¸ºå®ƒæ˜¯ä¸€èˆ¬ GNN çš„ç¨³å®šæ€§å’Œé€‚åº”æ€§çš„é‡è¦é‡Œç¨‹ç¢‘ã€‚</p>
<h3 id="4-3-éç»“æ„åŒ–åœºæ™¯"><a href="#4-3-éç»“æ„åŒ–åœºæ™¯" class="headerlink" title="4.3 éç»“æ„åŒ–åœºæ™¯"></a>4.3 éç»“æ„åŒ–åœºæ™¯</h3><p>è™½ç„¶æˆ‘ä»¬å·²ç»è®¨è®ºäº† GNN åœ¨éç»“æ„åœºæ™¯ä¸­çš„åº”ç”¨ï¼Œä½†æˆ‘ä»¬å‘ç°æ²¡æœ‰æœ€ä½³æ–¹æ³•å¯ä»¥ä»åŸå§‹æ•°æ®ç”Ÿæˆå›¾å½¢ã€‚å› æ­¤ï¼Œæ‰¾åˆ°æœ€ä½³å›¾å½¢ç”Ÿæˆæ–¹æ³•å°†æä¾› GNN å¯ä»¥åšå‡ºè´¡çŒ®çš„æ›´å¹¿æ³›çš„é¢†åŸŸã€‚</p>
<h3 id="4-4-å¯ä¼¸ç¼©æ€§"><a href="#4-4-å¯ä¼¸ç¼©æ€§" class="headerlink" title="4.4 å¯ä¼¸ç¼©æ€§"></a>4.4 å¯ä¼¸ç¼©æ€§</h3><p>å¦‚ä½•åœ¨ç¤¾äº¤ç½‘ç»œæˆ–æ¨èç³»ç»Ÿç­‰ç½‘ç»œè§„æ¨¡æ¡ä»¶ä¸‹åº”ç”¨åµŒå…¥æ–¹æ³•å¯¹äºå‡ ä¹æ‰€æœ‰å›¾å½¢åµŒå…¥ç®—æ³•æ¥è¯´éƒ½æ˜¯ä¸€ä¸ªè‡´å‘½çš„é—®é¢˜ï¼Œè€Œ GNN ä¹Ÿä¸ä¾‹å¤–ã€‚æ‰©å±• GNN å¾ˆå›°éš¾ï¼Œå› ä¸ºè®¸å¤šæ ¸å¿ƒæ­¥éª¤åœ¨å¤§æ•°æ®ç¯å¢ƒä¸­çš„è®¡ç®—æˆæœ¬éƒ½ååˆ†é«˜ã€‚</p>
]]></content>
      <categories>
        <category>Survey</category>
      </categories>
      <tags>
        <tag>GNN</tag>
      </tags>
  </entry>
  <entry>
    <title>meta-learning_nas</title>
    <url>/2020/06/18/08-meta-learning-nas/</url>
    <content><![CDATA[<h2 id="1-Towards-fast-adaptation-of-neural-architectures-with-meta-learning"><a href="#1-Towards-fast-adaptation-of-neural-architectures-with-meta-learning" class="headerlink" title="1. Towards fast adaptation of neural architectures with meta learning"></a>1. Towards fast adaptation of neural architectures with meta learning</h2><p><a href="https://openreview.net/forum?id=r1eowANFvr">ICLR2020</a></p>
<p>æ–‡ç« çš„çš„ä¸»è¦æ€æƒ³æ˜¯ï¼Œåœ¨meta-learningçš„settingä¸Šé¢ï¼Œé€šè¿‡ä¸åŒçš„taskï¼Œå­¦ä¹ ä¸€ä¸ªå¯ä»¥æ³›åŒ–çš„architectureï¼Œç„¶ååœ¨queryé›†ä¸Šé¢è¿›è¡Œfune-tuningï¼Œå¾®è°ƒè¿™ä¸ªç»“æ„ï¼Œä½¿å¾—è¯¥ç»“æ„å¯¹ä¸åŒtest taskæœ‰è‰¯å¥½çš„é€‚ç”¨æ€§ã€‚<br><img src="/08-meta-learning-nas/01-towards1.png" alt="towards"></p>
<p>åœ¨mini-imagenetä¸Šé¢5-wayçš„ç»“æœ<br><img src="/08-meta-learning-nas/02-towards2.png" alt="towards_result"></p>
<h2 id="2-Auto-Meta-Automated-Gradient-Based-Meta-Learner-Search"><a href="#2-Auto-Meta-Automated-Gradient-Based-Meta-Learner-Search" class="headerlink" title="2. Auto-Meta: Automated Gradient Based Meta Learner Search"></a>2. Auto-Meta: Automated Gradient Based Meta Learner Search</h2><p><a href="https://arxiv.org/abs/1806.06927">https://arxiv.org/abs/1806.06927</a></p>
<p>ä¹Ÿæ˜¯æ„é€ cellå»stackèµ·æ¥ï¼Œè·å–æ•´ä¸ªçš„networkï¼Œä½†æ˜¯ä¸€å¼€å§‹çš„cellå¹¶ä¸æ˜¯æ•´ä¸ªçš„supernetï¼Œè€Œæ˜¯åœ¨æœç´¢çš„è¿‡ç¨‹ä¸­ï¼Œé€æ­¥å¾€è¿™ä¸ªcellé‡Œé¢å»æ·»åŠ opetatorï¼Œ<strong>ç„¶åä½¿ç”¨ä¸€ä¸ªpredictorå»é¢„æµ‹è¿™ä¸ªcellçš„æ€§èƒ½</strong>ï¼Œé€‰æ‹©top kæ€§èƒ½çš„cellç»„æˆç½‘ç»œè¿›è¡Œæµ‹è¯•ã€‚<br><img src="/08-meta-learning-nas/03-auto_meta.png" alt="auto meta"></p>
<h2 id="3-Meta-Architecture-Search"><a href="#3-Meta-Architecture-Search" class="headerlink" title="3. Meta Architecture Search"></a>3. Meta Architecture Search</h2><p><a href="https://openreview.net/forum?id=B1M0gBSlLB">NIPS19</a></p>
<p>æœ¬æ–‡ä»Bayesiançš„è§’åº¦ï¼Œæ¨ç†äº†ä¸€éNASçš„åŸç†ï¼Œæå‡ºç”¨Coupled Variational Bayes (CVB)å»ç”Ÿæˆå‚æ•°çš„è¡¨è¾¾ï¼ŒåŒæ—¶è¿›è¡Œäº†æ¨ç†ï¼ˆhard mathï¼‰ã€‚æœ¬è´¨ä¸Šæ¥è¯´ï¼Œè¿™ç¯‡å·¥ä½œåŸºæœ¬ä¸Šè¿˜æ˜¯dartsï¼Œä¸è¿‡å®ƒé¦–å…ˆå°†meta learningçš„åœ¨imagenetä¸Šé¢è·å–çš„å…ˆéªŒçŸ¥è¯†æ‹¿å‡ºæ¥æ”¾åˆ°å…¶ä»–ä»»åŠ¡ä¸Šå»trainã€‚<br>é¦–å…ˆä½¿ç”¨gumble_softmaxed darts(å‚è§SNAS)ï¼Œå–å¾—meta networkçš„archå’Œinitï¼Œç„¶åé’ˆå¯¹ä¸åŒä»»åŠ¡è¿›è¡Œfine tuningã€‚<br><img src="/08-meta-learning-nas/04-meta_architecture_search.png" alt="meta as"></p>
<h2 id="MetAdapt-Meta-Learned-Task-Adaptive-Architecture-for-Few-Shot-Classification"><a href="#MetAdapt-Meta-Learned-Task-Adaptive-Architecture-for-Few-Shot-Classification" class="headerlink" title="MetAdapt: Meta-Learned Task-Adaptive Architecture for Few-Shot Classification"></a>MetAdapt: Meta-Learned Task-Adaptive Architecture for Few-Shot Classification</h2><p><a href="https://arxiv.org/abs/1912.00412">https://arxiv.org/abs/1912.00412</a></p>
<p>åœ¨dartsçš„åŸºç¡€ä¸Šï¼Œæå‡ºäº†ä¸€ä¸ªMetAdapt Controllersï¼Œå°±æ˜¯è¯´ï¼Œå¯¹äºä¸åŒçš„taskï¼Œäº§ç”Ÿä¸åŒçš„å åŠ æƒé‡<br><img src="/08-meta-learning-nas/05-MetAdapt.png" alt="MetAdapt"></p>
<h2 id="Meta-Learning-of-Neural-Architectures-for-Few-Shot-Learning"><a href="#Meta-Learning-of-Neural-Architectures-for-Few-Shot-Learning" class="headerlink" title="Meta-Learning of Neural Architectures for Few-Shot Learning"></a>Meta-Learning of Neural Architectures for Few-Shot Learning</h2><p><a href="https://arxiv.org/abs/1911.11090">https://arxiv.org/abs/1911.11090</a><br>æå‡ºäº†gradient-based NAS + meta learning ç»“åˆçš„æ¡†æ¶ï¼Œç›´æ¥æƒ³æŠŠæ‰€æœ‰æ–¹æ³•éƒ½æ¡†åˆ°è‡ªå·±ä¸‹é¢ã€‚<br><img src="/08-meta-learning-nas/06-meta_learning_of_NAS4FS.png" alt="06-meta_learning_of_NAS4FS"></p>
]]></content>
      <categories>
        <category>Survey</category>
      </categories>
      <tags>
        <tag>NAS, meta-learning</tag>
      </tags>
  </entry>
  <entry>
    <title>string_pattern</title>
    <url>/2020/07/15/09-string-pattern/</url>
    <content><![CDATA[<h2 id="1-1-å­—ç¬¦ä¸²åŒ¹é…ç®—æ³•"><a href="#1-1-å­—ç¬¦ä¸²åŒ¹é…ç®—æ³•" class="headerlink" title="1.1 å­—ç¬¦ä¸²åŒ¹é…ç®—æ³•"></a>1.1 å­—ç¬¦ä¸²åŒ¹é…ç®—æ³•</h2><table>
<thead>
<tr>
<th align="left">algorithm</th>
<th align="center">$T_{best}$</th>
<th align="center">$T_{avg}$</th>
<th align="center">$T_{worst}$</th>
</tr>
</thead>
<tbody><tr>
<td align="left">1. æœ´ç´ åŒ¹é…ç®—æ³•</td>
<td align="center">O(nm)</td>
<td align="center">O(nm)</td>
<td align="center">O(nm)</td>
</tr>
<tr>
<td align="left">2. Robin-Karp ç®—æ³•</td>
<td align="center">O(n)</td>
<td align="center">O(nm)</td>
<td align="center">O(nm)</td>
</tr>
<tr>
<td align="left">3. KMPç®—æ³•</td>
<td align="center">O(n+m)</td>
<td align="center">O(n+m)</td>
<td align="center">O(n+m)</td>
</tr>
</tbody></table>
<h3 id="1-1-1-æœ´ç´ åŒ¹é…ç®—æ³•"><a href="#1-1-1-æœ´ç´ åŒ¹é…ç®—æ³•" class="headerlink" title="1.1.1 æœ´ç´ åŒ¹é…ç®—æ³•"></a>1.1.1 æœ´ç´ åŒ¹é…ç®—æ³•</h3><p>æš´åŠ›æ±‚è§£</p>
<h3 id="1-1-2-Robin-Karpç®—æ³•"><a href="#1-1-2-Robin-Karpç®—æ³•" class="headerlink" title="1.1.2 Robin-Karpç®—æ³•"></a>1.1.2 Robin-Karpç®—æ³•</h3><p>å…ˆæ˜¯è®¡ç®—ä¸¤ä¸ªå­—ç¬¦ä¸²çš„å“ˆå¸Œå€¼ï¼Œç„¶åé€šè¿‡æ¯”è¾ƒè¿™ä¸¤ä¸ªå“ˆå¸Œå€¼çš„å¤§å°æ¥åˆ¤æ–­æ˜¯å¦å‡ºç°åŒ¹é…ã€‚<br>é€‰æ‹©ä¸€ä¸ªåˆé€‚çš„å“ˆå¸Œå‡½æ•°å¾ˆé‡è¦ã€‚å‡è®¾æ–‡æœ¬ä¸²ä¸ºt[0, n)ï¼Œæ¨¡å¼ä¸²ä¸ºp[0, m)ï¼Œå…¶ä¸­ $0&lt;m&lt;n$ï¼Œ$Hash(t[i,j])$ä»£è¡¨å­—ç¬¦ä¸²t[i, j]çš„å“ˆå¸Œå€¼ã€‚</p>
<p>å½“ $Hash(t[0, m-1])!&#x3D;Hash(p[0,m-1])$ æ—¶ï¼Œæˆ‘ä»¬å¾ˆè‡ªç„¶çš„ä¼šæŠŠ $Hash(t[1, m])$ æ‹¿è¿‡æ¥ç»§ç»­æ¯”è¾ƒã€‚åœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­ï¼Œè‹¥æˆ‘ä»¬é‡æ–°è®¡ç®—å­—ç¬¦ä¸²t[1, m]çš„å“ˆå¸Œå€¼ï¼Œè¿˜éœ€è¦ O(n) çš„æ—¶é—´å¤æ‚åº¦ï¼Œä¸åˆ’ç®—ã€‚è§‚å¯Ÿåˆ°å­—ç¬¦ä¸²t[0, m-1]ä¸t[1, m]ä¸­æœ‰ m-1 ä¸ªå­—ç¬¦æ˜¯é‡åˆçš„ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥é€‰ç”¨<strong>æ»šåŠ¨å“ˆå¸Œå‡½æ•°</strong>ï¼Œé‚£ä¹ˆé‡æ–°è®¡ç®—çš„æ—¶é—´å¤æ‚åº¦å°±é™ä¸º O(1)ã€‚</p>
<p>Rabin-Karp ç®—æ³•é€‰ç”¨çš„æ»šåŠ¨å“ˆå¸Œå‡½æ•°ä¸»è¦æ˜¯åˆ©ç”¨$Rabin fingerprint$çš„æ€æƒ³ï¼Œä¸¾ä¸ªä¾‹å­ï¼Œè®¡ç®—å­—ç¬¦ä¸²t[0, m - 1]çš„å“ˆå¸Œå€¼çš„å…¬å¼å¦‚ä¸‹ï¼Œ</p>
<p>$$Hash(t[0,mâˆ’1])&#x3D;t[0]âˆ—b_{mâˆ’1}+t[1]âˆ—b_{mâˆ’2}+â€¦+t[mâˆ’1]âˆ—b_0$$</p>
<p>å…¶ä¸­çš„ b_k å¯ä»¥æ˜¯ä¸€ä¸ªå¸¸æ•°ï¼Œåœ¨ Rabin-Karp ç®—æ³•ä¸­ï¼Œæˆ‘ä»¬ä¸€èˆ¬å–å€¼ä¸º256ï¼Œå› ä¸ºä¸€ä¸ªå­—ç¬¦çš„æœ€å¤§å€¼ä¸è¶…è¿‡255ã€‚ä¸Šé¢çš„å…¬å¼è¿˜æœ‰ä¸€ä¸ªé—®é¢˜ï¼Œå“ˆå¸Œå€¼å¦‚æœè¿‡å¤§å¯èƒ½ä¼šæº¢å‡ºï¼Œå› æ­¤æˆ‘ä»¬è¿˜éœ€è¦å¯¹å…¶å–æ¨¡ï¼Œè¿™ä¸ªå€¼åº”è¯¥å°½å¯èƒ½å¤§ï¼Œä¸”æ˜¯è´¨æ•°ï¼Œè¿™æ ·å¯ä»¥å‡å°å“ˆå¸Œç¢°æ’çš„æ¦‚ç‡ï¼Œåœ¨è¿™é‡Œæˆ‘ä»¬å°±å– 101ã€‚</p>
<p>åˆ™è®¡ç®—å­—ç¬¦ä¸²t[1, m]çš„å“ˆå¸Œå€¼å…¬å¼å¦‚ä¸‹ï¼Œ</p>
<p>$$Hash(t[1,m])&#x3D;(Hash(t[0,mâˆ’1])âˆ’t[0]âˆ—b_{mâˆ’1})âˆ—b+t[m]âˆ—b_0$$</p>
<h3 id="1-1-3-KMPç®—æ³•"><a href="#1-1-3-KMPç®—æ³•" class="headerlink" title="1.1.3 KMPç®—æ³•"></a>1.1.3 KMPç®—æ³•</h3><p>KMPç®—æ³•çš„ç²¾é«“åœ¨äºï¼Œå¯¹äºä¸€ä¸ªä¸åŒ¹é…çš„å­ä¸²ï¼Œæˆ‘ä»¬å°†æ•´ä¸ªæ¨¡å¼ä¸²å‘åé¢ç§»åŠ¨æ›´å¤šçš„ä½æ•°è€Œä¸æ˜¯1ï¼Œæ¥åŠ é€Ÿå­ä¸²çš„è¯†åˆ«ï¼Œè¿™ä¸ªç§»åŠ¨æ­¥æ•°è·Ÿåªéœ€è¦æ ¹æ®æ¨¡å¼å­ä¸²è®¡ç®—ä¸€æ¬¡å°±å¯ä»¥å¾—åˆ°ã€‚</p>
<p><a href="http://www.ruanyifeng.com/blog/2013/05/Knuth%E2%80%93Morris%E2%80%93Pratt_algorithm.html">é˜®ä¸€å³°KMPç®—æ³•</a></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#KMP</span>
<span class="token keyword">def</span> <span class="token function">kmp_match</span><span class="token punctuation">(</span>s<span class="token punctuation">,</span> p<span class="token punctuation">)</span><span class="token punctuation">:</span>
    m <span class="token operator">=</span> len<span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token punctuation">;</span> n <span class="token operator">=</span> len<span class="token punctuation">(</span>p<span class="token punctuation">)</span>
    cur <span class="token operator">=</span> <span class="token number">0</span><span class="token comment" spellcheck="true">#èµ·å§‹æŒ‡é’ˆcur</span>
    table <span class="token operator">=</span> partial_table<span class="token punctuation">(</span>p<span class="token punctuation">)</span>
    <span class="token keyword">while</span> cur<span class="token operator">&lt;=</span>m<span class="token operator">-</span>n<span class="token punctuation">:</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> s<span class="token punctuation">[</span>i<span class="token operator">+</span>cur<span class="token punctuation">]</span><span class="token operator">!=</span>p<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">:</span>
                cur <span class="token operator">+=</span> max<span class="token punctuation">(</span>i <span class="token operator">-</span> table<span class="token punctuation">[</span>i<span class="token number">-1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#æœ‰äº†éƒ¨åˆ†åŒ¹é…è¡¨,æˆ‘ä»¬ä¸åªæ˜¯å•çº¯çš„1ä½1ä½å¾€å³ç§»,å¯ä»¥ä¸€æ¬¡ç§»åŠ¨å¤šä½</span>
                <span class="token keyword">break</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span> <span class="token boolean">True</span>
    <span class="token keyword">return</span> <span class="token boolean">False</span>

<span class="token comment" spellcheck="true">#éƒ¨åˆ†åŒ¹é…è¡¨</span>
<span class="token keyword">def</span> <span class="token function">partial_table</span><span class="token punctuation">(</span>p<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">'''partial_table("ABCDABD") -> [0, 0, 0, 0, 1, 2, 0]'''</span>
    prefix <span class="token operator">=</span> set<span class="token punctuation">(</span><span class="token punctuation">)</span>
    postfix <span class="token operator">=</span> set<span class="token punctuation">(</span><span class="token punctuation">)</span>
    ret <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>len<span class="token punctuation">(</span>p<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        prefix<span class="token punctuation">.</span>add<span class="token punctuation">(</span>p<span class="token punctuation">[</span><span class="token punctuation">:</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>
        postfix <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;p[j:i+1] for j in range(1,i+1)&amp;#125;</span>
        ret<span class="token punctuation">.</span>append<span class="token punctuation">(</span>len<span class="token punctuation">(</span><span class="token punctuation">(</span>prefix<span class="token operator">&amp;</span>postfix <span class="token operator">or</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;''&amp;#125;).pop()))</span>
    <span class="token keyword">return</span> ret
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>string</tag>
      </tags>
  </entry>
  <entry>
    <title>è”é‚¦å­¦ä¹ æ¦‚è¿°</title>
    <url>/2020/11/01/10-FL/</url>
    <content><![CDATA[<p>Examples of potential applications include: learning sentiment, semantic location, or activities of mobile phone users; adapting to pedestrian behavior in autonomous vehicles; and predicting health events like heart attack risk from wearable devices [6, 52, 84].</p>
<h2 id="1-Overview"><a href="#1-Overview" class="headerlink" title="1. Overview"></a>1. Overview</h2><h3 id="1-1-é—®é¢˜å®šä¹‰"><a href="#1-1-é—®é¢˜å®šä¹‰" class="headerlink" title="1.1 é—®é¢˜å®šä¹‰"></a>1.1 é—®é¢˜å®šä¹‰</h3><p><img src="/10-FL/01-FL_problem.png" alt="problem definition"><br>ç®€å•æ¥è¯´ï¼Œå°±æ˜¯è¯´è”é‚¦å­¦ä¹ çš„ç›®æ ‡æ˜¯è®­ç»ƒä¸€ä¸ªâ€å°½å¯èƒ½æ¥è¿‘æŠŠå„ä¸ªèŠ‚ç‚¹æ•°æ®èšåˆèµ·æ¥è®­ç»ƒâ€çš„æ¨¡å‹ã€‚</p>
<h3 id="1-2-å…¸å‹åº”ç”¨"><a href="#1-2-å…¸å‹åº”ç”¨" class="headerlink" title="1.2 å…¸å‹åº”ç”¨"></a>1.2 å…¸å‹åº”ç”¨</h3><ul>
<li>smart phone</li>
<li>Organizations</li>
<li>internet of things ç‰©è”ç½‘ æ”¶é›†å„ç§æ¨¡æ€çš„ä¿¡æ¯</li>
</ul>
<h3 id="1-3-ä¸»è¦æŒ‘æˆ˜"><a href="#1-3-ä¸»è¦æŒ‘æˆ˜" class="headerlink" title="1.3 ä¸»è¦æŒ‘æˆ˜"></a>1.3 ä¸»è¦æŒ‘æˆ˜</h3><ol>
<li>expensive communication<ul>
<li>reducing the total number of communication rounds</li>
<li>reducing the size of transmitted messages at each round.</li>
</ul>
</li>
<li>systems heterogeneity<ul>
<li>only a small fraction of the devices being active at once</li>
<li>anticipate a low amount of participation</li>
<li>tolerate heterogeneous hardware</li>
<li>be robust to dropped devices in the network.</li>
</ul>
</li>
<li>Statistical Heterogeneity<ul>
<li>independent and identically distributed</li>
<li>Both the multi-task and meta-learning perspectives enable personalized or device-specific modeling, which is often a more natural approach to handle the statistical heterogeneity of the data.</li>
</ul>
</li>
<li>Privacy Concern<ul>
<li>secure multiparty computation or differential privacy</li>
<li>at the cost of reduced model performance or system efficiency.</li>
</ul>
</li>
</ol>
<h2 id="2-related-and-current-work"><a href="#2-related-and-current-work" class="headerlink" title="2. related and current work"></a>2. related and current work</h2><h3 id="2-1-Communication-efficiency"><a href="#2-1-Communication-efficiency" class="headerlink" title="2.1 Communication-efficiency"></a>2.1 Communication-efficiency</h3><ol>
<li>local updating methods</li>
<li>compression schemes</li>
<li>decentralized training</li>
</ol>
<h3 id="2-2-Systems-Heterogeneity"><a href="#2-2-Systems-Heterogeneity" class="headerlink" title="2.2 Systems Heterogeneity"></a>2.2 Systems Heterogeneity</h3><h3 id="2-3-Statistical-Heterogeneity"><a href="#2-3-Statistical-Heterogeneity" class="headerlink" title="2.3 Statistical Heterogeneity"></a>2.3 Statistical Heterogeneity</h3><h4 id="2-3-1-Modeling-heterogeneous-Data"><a href="#2-3-1-Modeling-heterogeneous-Data" class="headerlink" title="2.3.1 Modeling heterogeneous Data"></a>2.3.1 Modeling heterogeneous Data</h4><ul>
<li>fairness</li>
<li>accountability</li>
<li>interpretability</li>
</ul>
<h4 id="2-3-2-Convergence-Guarantees-for-Non-IID-Data"><a href="#2-3-2-Convergence-Guarantees-for-Non-IID-Data" class="headerlink" title="2.3.2 Convergence Guarantees for Non-IID Data"></a>2.3.2 Convergence Guarantees for Non-IID Data</h4><p>Indeed, when data is not identically distributed across devices in the network, methods such as <strong>FedAvg</strong> have been shown to diverge in practice</p>
<p>Parallel SGD and related variants</p>
<p>FedProx</p>
<h3 id="2-4-Ptivacy"><a href="#2-4-Ptivacy" class="headerlink" title="2.4 Ptivacy"></a>2.4 Ptivacy</h3><h4 id="2-4-1-privacy-in-Machine-learning"><a href="#2-4-1-privacy-in-Machine-learning" class="headerlink" title="2.4.1 privacy in Machine learning"></a>2.4.1 privacy in Machine learning</h4><p>differential privacyï¼š strong information theoretic guarantees, algorithmic simplicity, and relatively small systems overhead</p>
<p>homomorphic encryptionåŒæ€åŠ å¯†</p>
<h4 id="2-4-2-Privacy-in-Federated-Learning"><a href="#2-4-2-Privacy-in-Federated-Learning" class="headerlink" title="2.4.2 Privacy in Federated Learning"></a>2.4.2 Privacy in Federated Learning</h4><p>è®¡ç®—å»‰ä»·ï¼Œäº¤æµé«˜æ•ˆï¼Œå…è®¸ä¸¢å¤±deviceâ€“ä¸èƒ½å¯¹accuracyåšå¾ˆå¤§è®©æ­¥</p>
<ol>
<li><p>Secure Multi-party Computation (SMC) å®‰å…¨çš„å¤šæ–¹è®¡ç®—<br> å„æ–¹é™¤äº†è¾“å…¥å’Œè¾“å‡ºå¤–ä¸€æ— æ‰€çŸ¥</p>
<ul>
<li>å¤æ‚çš„è®¡ç®—åè®®</li>
<li>å¦‚æœæä¾›å®‰å…¨ä¿è¯ï¼Œåˆ™éƒ¨åˆ†çŸ¥è¯†å…¬å¼€å¯èƒ½è¢«è®¤ä¸ºæ˜¯å¯ä»¥æ¥å—çš„</li>
</ul>
<p> è¦æ±‚å‚ä¸è€…çš„æ•°æ®åœ¨éå†²çªæœåŠ¡å™¨ä¹‹é—´ç§˜å¯†å…±äº«</p>
</li>
<li><p>Differential Privacy å·®å¼‚éšç§<br> å‘æ•°æ®æ·»åŠ å™ªéŸ³ï¼Œæˆ–ä½¿ç”¨å½’çº³æ–¹æ³•é®ç›–æŸäº›æ•æ„Ÿå±æ€§ï¼Œç›´åˆ°ç¬¬ä¸‰æ–¹æ— æ³•åŒºåˆ†ä¸ªäºº</p>
<ul>
<li>æ•°æ®ä¹Ÿè¢«ä¼ è¾“åˆ°ç»™äº†å…¶ä»–äºº</li>
<li>æ¶‰åŠå‡†ç¡®æ€§å’Œéšç§ä¹‹é—´çš„æƒè¡¡</li>
</ul>
</li>
<li><p>Homomorphic Encryption åŒæ€åŠ å¯†<br> åœ¨æœºå™¨å­¦ä¹ æœŸé—´é€šè¿‡åŠ å¯†æœºåˆ¶ä¸‹çš„å‚æ•°äº¤æ¢æ¥ä¿æŠ¤ç”¨æˆ·æ•°æ®éšç§</p>
<ul>
<li>æ•°æ®å’Œæ¨¡å‹æœ¬èº«ä¸ä¼ è¾“</li>
<li>å‡†ç¡®æ€§ä¸ç§å¯†æ€§ä¹‹é—´çš„æƒè¡¡</li>
</ul>
</li>
</ol>
<h2 id="3-future-directions"><a href="#3-future-directions" class="headerlink" title="3. future directions"></a>3. future directions</h2><ol>
<li>Extreme communication schemes<ul>
<li>one- shot or divide-and-conquer communication schemes</li>
<li>one-shot&#x2F;few-shot heuristics</li>
</ul>
</li>
<li>Communication reduction and the Pareto frontier<ul>
<li>local updatding æœ¬åœ°æ›´æ–°</li>
<li>model compression æ¨¡å‹å‹ç¼©</li>
</ul>
</li>
<li>Novel models of asynchrony<ul>
<li>ä»»ä½•è®¾å¤‡åœ¨ä»»ä½•è¿­ä»£ä¸­éƒ½æœ‰å¯èƒ½å¤±è”</li>
<li>è®¾å¤‡éšæ—¶é€šè¿‡<strong>äº‹ä»¶é©±åŠ¨</strong>å’Œcentral serveräº¤æ¢ä¿¡æ¯</li>
</ul>
</li>
<li>Heterogeneity diagnostics<ul>
<li>æ˜¯å¦å­˜åœ¨ç®€å•çš„è¯Šæ–­æ–¹æ³•æ¥é¢„å…ˆå¿«é€Ÿç¡®å®šè”åˆç½‘ç»œçš„å¼‚æ„ç¨‹åº¦?</li>
<li>èƒ½å¦å¼€å‘å‡ºç±»ä¼¼çš„è¯Šæ–­æ–¹æ³•æ¥é‡åŒ–ä¸ç³»ç»Ÿç›¸å…³çš„å¼‚è´¨æ€§çš„æ•°é‡</li>
<li>å¯ä»¥åˆ©ç”¨ç°æœ‰çš„æˆ–æ–°çš„å¼‚æ„å®šä¹‰è¿›ä¸€æ­¥æ”¹è¿›è”é‚¦ä¼˜åŒ–æ–¹æ³•çš„æ”¶æ•›æ€§å—?</li>
</ul>
</li>
<li>Granular privacy constraints<ul>
<li>thus providing a weaker form of privacy in exchange for more accurate models</li>
</ul>
</li>
<li>Beyond supervised learning<ul>
<li>scalability, heterogeneity, and privacy.</li>
</ul>
</li>
<li>Productionizing federated learning<ul>
<li>å®é™…è½åœ°çš„é—®é¢˜ concept drift</li>
<li>diurnal variations è®¾å¤‡ä¸åŒæ—¶é—´è¡¨ç°ä¸åŒ</li>
<li>cold start problems è®¾å¤‡æ–°åŠ å…¥</li>
</ul>
</li>
<li>Benchmarks<ul>
<li>reproducibility of empirical results and the dissemination of new solutions for federated learning.</li>
</ul>
</li>
</ol>
]]></content>
      <categories>
        <category>Survey</category>
      </categories>
      <tags>
        <tag>Federated Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>A Comprehensive Survey on Graph Neural Networks</title>
    <url>/2020/11/01/11-GNN-survey2/</url>
    <content><![CDATA[<h2 id="1-ç®€ä»‹"><a href="#1-ç®€ä»‹" class="headerlink" title="1 ç®€ä»‹"></a>1 ç®€ä»‹</h2><p>æ¬§å¼æ•°æ®ï¼šå›¾ç‰‡ï¼Œæ–‡æœ¬ï¼Œè¯­è¨€ï¼Œè§†é¢‘<br>éæ¬§å¼æ•°æ®ï¼šå›¾</p>
<p>å›¾æ•°æ®ä¸è§„åˆ™ï¼Œæ¯ä¸ªå›¾çš„æ— åºèŠ‚ç‚¹å¤§å°æ˜¯å¯å˜çš„ï¼Œä¸”æ¯ä¸ªç»“ç‚¹æœ‰ä¸åŒæ•°é‡çš„é‚»å±…ç»“ç‚¹ï¼Œå› æ­¤ä¸€äº›é‡è¦çš„æ“ä½œå¦‚å·ç§¯èƒ½å¤Ÿåœ¨å›¾åƒæ•°æ®ä¸Šè½»æ˜“è®¡ç®—ï¼Œä½†æ˜¯ä¸é€‚ç”¨äºå›¾æ•°æ®ï¼Œå¯è§å›¾æ•°æ®çš„å¤æ‚æ€§ç»™ç°æœ‰çš„æœºå™¨å­¦ä¹ ç®—æ³•å¸¦æ¥äº†å·¨å¤§çš„æŒ‘æˆ˜ ã€‚æ­¤å¤–ï¼Œç°æœ‰çš„æœºå™¨å­¦ä¹ ç®—æ³•å‡è®¾æ•°æ®ä¹‹é—´æ˜¯ç›¸äº’ç‹¬ç«‹çš„ï¼Œä½†æ˜¯ï¼Œå›¾æ•°æ®ä¸­æ¯ä¸ªç»“ç‚¹éƒ½é€šè¿‡ä¸€äº›å¤æ‚çš„è¿æ¥ä¿¡æ¯ä¸å…¶ä»–é‚»å±…ç›¸å…³ï¼Œè¿™äº›è¿æ¥ä¿¡æ¯ç”¨äºæ•è·æ•°æ®ä¹‹é—´çš„ç›¸äº’ä¾èµ–å…³ç³»ï¼ŒåŒ…æ‹¬ï¼Œå¼•ç”¨ï¼Œå…³ç³»ï¼Œäº¤äº’ã€‚</p>
<ol>
<li>Graph attention networksï¼ˆå›¾æ³¨æ„åŠ›ç½‘ç»œ)</li>
<li>Graph autoencodersï¼ˆå›¾è‡ªç¼–ç ï¼‰</li>
<li>Graph generative networksï¼ˆå›¾ç”Ÿæˆç½‘ç»œï¼‰</li>
<li>Graph spatial-temporal networksï¼ˆå›¾æ—¶ç©ºç½‘ç»œ</li>
</ol>
<p>GNN vs å›¾åµŒå…¥</p>
<p>ç½‘ç»œåµŒå…¥è‡´åŠ›äº<strong>åœ¨ä¸€ä¸ªä½ç»´å‘é‡ç©ºé—´è¿›è¡Œç½‘ç»œèŠ‚ç‚¹è¡¨ç¤ºï¼ŒåŒæ—¶ä¿æŠ¤ç½‘ç»œæ‹“æ‰‘ç»“æ„å’ŒèŠ‚ç‚¹çš„ä¿¡æ¯</strong>ï¼Œä¾¿äºåç»­çš„å›¾åƒåˆ†æä»»åŠ¡ï¼ŒåŒ…æ‹¬åˆ†ç±»ï¼Œèšç±»ï¼Œæ¨èç­‰ï¼Œèƒ½å¤Ÿä½¿ç”¨ç®€å•ç°æˆçš„æœºå™¨å­¦ä¹ ç®—æ³•ï¼ˆä¾‹å¦‚ï¼Œä½¿ç”¨SVMåˆ†ç±»ï¼‰ã€‚è®¸å¤šç½‘ç»œåµŒå…¥ç®—æ³•éƒ½æ˜¯å…¸å‹çš„æ— ç›‘ç£ç®—æ³•ï¼Œå®ƒä»¬å¯ä»¥å¤§è‡´åˆ†ä¸ºä¸‰ç§ç±»å‹ï¼Œå³ï¼Œ</p>
<ol>
<li>çŸ©é˜µåˆ†è§£</li>
<li>éšæœºæ¸¸èµ°</li>
<li>æ·±åº¦å­¦ä¹ </li>
</ol>
<p><img src="/11-GNN-survey2/04-network_embedding.png" alt="network embedding"></p>
<h2 id="2-GNNåˆ†ç±»åŠæ¡†æ¶"><a href="#2-GNNåˆ†ç±»åŠæ¡†æ¶" class="headerlink" title="2 GNNåˆ†ç±»åŠæ¡†æ¶"></a>2 GNNåˆ†ç±»åŠæ¡†æ¶</h2><p>äº”ç§ç±»å‹ GCN GAN GAE GGN GSTN</p>
<h3 id="2-1-åˆ†ç±»"><a href="#2-1-åˆ†ç±»" class="headerlink" title="2.1 åˆ†ç±»"></a>2.1 åˆ†ç±»</h3><h4 id="2-1-1-GCN"><a href="#2-1-1-GCN" class="headerlink" title="2.1.1 GCN"></a>2.1.1 GCN</h4><p>GCNså°†ä¼ ç»Ÿæ•°æ®çš„å·ç§¯ç®—å­æ³›åŒ–åˆ°å›¾æ•°æ®ï¼Œè¿™ä¸ªç®—æ³•çš„å…³é”®æ˜¯å­¦ä¹ ä¸€ä¸ªå‡½æ•°$f$ï¼Œèƒ½å¤Ÿç»“åˆ$v_i$é‚»å±…èŠ‚ç‚¹çš„ç‰¹å¾$X_j$å’Œå…¶æœ¬èº«ç‰¹å¾$X_i$ç”Ÿæˆ$v_i$çš„æ–°è¡¨ç¤º.</p>
<p><img src="/11-GNN-survey2/05-gcn_mlp.png" alt="GCNçš„å¤šå±‚å˜ä½“"><br><img src="/11-GNN-survey2/06-gcn_%E6%9E%84%E5%BB%BA%E7%9A%84%E7%BD%91%E7%BB%9C.png" alt="GCN æ„å»ºç½‘ç»œ"></p>
<h4 id="2-1-2-GAN"><a href="#2-1-2-GAN" class="headerlink" title="2.1.2 GAN"></a>2.1.2 GAN</h4><p>GANä¸GCNç±»ä¼¼ï¼Œè‡´åŠ›äºå¯»æ‰¾ä¸€ä¸ªèšåˆå‡½æ•°ï¼Œèåˆå›¾ä¸­ç›¸é‚»çš„èŠ‚ç‚¹ï¼Œéšæœºæ¸¸åŠ¨å’Œå€™é€‰æ¨¡å‹ï¼Œå­¦ä¹ ä¸€ç§æ–°çš„è¡¨ç¤ºã€‚<strong>å…³é”®åŒºåˆ«æ˜¯ï¼šGANä½¿ç”¨æ³¨æ„åŠ›æœºåˆ¶ä¸ºæ›´é‡è¦çš„èŠ‚ç‚¹ï¼Œæ­¥æˆ–è€…æ¨¡å‹åˆ†é…æ›´å¤§çš„æƒé‡ï¼Œæƒé‡ä¸ªç½‘ç»œä¸€èµ·å­¦ä¹ ã€‚</strong>ä¸‹å›¾å±•ç¤ºäº†GCNå’ŒGANåœ¨èšåˆé‚»å±…èŠ‚ç‚¹ä¿¡æ¯æ—¶å€™çš„ä¸åŒã€‚</p>
<p><img src="/11-GNN-survey2/07-GAN.png" alt="GAN"></p>
<h4 id="2-1-3-GAE"><a href="#2-1-3-GAE" class="headerlink" title="2.1.3 GAE"></a>2.1.3 GAE</h4><p>GAEæ˜¯ä¸€ç§æ— ç›‘ç£å­¦ä¹ æ¡†æ¶ï¼Œé€šè¿‡ç¼–ç å™¨å­¦ä¹ ä¸€ç§ä½ç»´ç‚¹å‘é‡ï¼Œç„¶åé€šè¿‡è§£ç å™¨é‡æ„å›¾æ•°æ®ã€‚GAEæ˜¯ä¸€ç§å¸¸ç”¨çš„å­¦ä¹ å›¾åµŒå…¥çš„æ–¹æ³•ï¼Œæ—¢é€‚ç”¨äºæ— å±æ€§ä¿¡æ¯çš„æ™®é€šå›¾ï¼Œè¿˜é€‚ç”¨äºæ˜¯æœ‰å±æ€§å›¾ã€‚å¯¹äºæ™®é€šçš„å›¾ï¼Œå¤§å¤šæ•°ç®—æ³•ç›´æ¥é¢„å…ˆå¾—åˆ°ä¸€ä¸ªé‚»æ¥çŸ©é˜µï¼Œæˆ–è€…æ„å»ºä¸€ä¸ªä¿¡æ¯ä¸°å¯Œçš„çŸ©é˜µï¼Œä¹Ÿå°±æ˜¯ç‚¹å¯¹äº’ä¿¡æ¯çŸ©é˜µï¼Œæˆ–è€…é‚»æ¥çŸ©é˜µå¡«å……è‡ªç¼–ç æ¨¡å‹ï¼Œå¹¶æ•è·ä¸€é˜¶å’ŒäºŒé˜¶ä¿¡æ¯ã€‚å¯¹äºå±æ€§å›¾ï¼Œå›¾è‡ªç¼–ç æ¨¡å‹åˆ©ç”¨GCNä½œä¸ºä¸€ä¸ªæ„å»ºå—ç”¨äºç¼–ç ï¼Œå¹¶ä¸”é€šè¿‡é“¾è·¯é¢„æµ‹è§£ç å™¨é‡æ„ç»“æ„ä¿¡æ¯ã€‚</p>
<h4 id="2-1-4-GGN"><a href="#2-1-4-GGN" class="headerlink" title="2.1.4 GGN"></a>2.1.4 GGN</h4><p>GGNæ—¨åœ¨ä»æ•°æ®ä¸­ç”Ÿæˆå¯ä¿¡çš„ä¿¡æ¯ï¼Œç”Ÿæˆç»™å®šå›¾ç»éªŒåˆ†å¸ƒçš„å›¾ä»æ ¹æœ¬ä¸Šæ¥è¯´æ˜¯å…·æœ‰æŒ‘æˆ˜æ€§çš„ï¼Œä¸»è¦å› ä¸ºå›¾æ˜¯å¤æ‚çš„æ•°æ®ç»“æ„ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œç ”ç©¶å‘˜æ¢ç´¢äº†å°†äº¤æ›¿å½¢æˆèŠ‚ç‚¹å’Œè¾¹ä½œä¸ºç”Ÿæˆè¿‡ç¨‹çš„å› ç´ ï¼Œå¹¶å€ŸåŠ©ä½œä¸ºè®­ç»ƒè¿‡ç¨‹ã€‚GGNä¸€ä¸ªå¾ˆæœ‰å‰é€”çš„åº”ç”¨é¢†åŸŸæ˜¯åŒ–åˆç‰©åˆæˆã€‚åœ¨åŒ–å­¦å›¾ä¸­ï¼Œè§†åŸå­ä¸ºèŠ‚ç‚¹ï¼ŒåŒ–å­¦é”®ä¸ºè¾¹ï¼Œä»»åŠ¡æ˜¯å‘ç°å…·æœ‰ä¸€å®šåŒ–å­¦å’Œç‰©ç†æ€§è´¨çš„å¯åˆæˆçš„æ–°åˆ†å­ã€‚</p>
<h4 id="2-1-5-GSTN"><a href="#2-1-5-GSTN" class="headerlink" title="2.1.5 GSTN"></a>2.1.5 GSTN</h4><p>GSTNä»æ—¶ç©ºå›¾ä¸­å­¦ä¹ ä¸å¯è§çš„æ¨¡å¼ï¼Œåœ¨äº¤é€šé¢„æµ‹å’Œäººç±»æ´»åŠ¨é¢„æµ‹ç­‰åº”ç”¨ä¸­è¶Šæ¥è¶Šé‡è¦ã€‚ä¾‹å¦‚ï¼Œåº•å±‚é“è·¯äº¤é€šç½‘ç»œæ˜¯ä¸€ä¸ªè‡ªç„¶å›¾ï¼Œå…¶ä¸­æ¯ä¸ªå…³é”®ä½ç½®æ˜¯ä¸€ä¸ªèŠ‚ç‚¹ï¼Œå®ƒçš„äº¤é€šæ•°æ®æ˜¯è¢«è¿ç»­ç›‘æµ‹çš„ã€‚é€šè¿‡å»ºç«‹æœ‰æ•ˆçš„GSTNï¼Œèƒ½å¤Ÿå‡†ç¡®é¢„æµ‹æ•´ä¸ªäº¤é€šçš„ç³»ç»Ÿçš„äº¤é€šçŠ¶æ€ã€‚GSTNçš„æ ¸å¿ƒè§‚ç‚¹æ˜¯ï¼Œ<strong>åŒæ—¶è€ƒè™‘ç©ºé—´ä¾èµ–æ€§å’Œæ—¶é—´ä¾èµ–æ€§ã€‚</strong> ç›®å‰å¾ˆå¤šæ–¹æ³•ä½¿ç”¨GCNsæ•è·ä¾èµ–æ€§ï¼ŒåŒæ—¶ä½¿ç”¨RNN,æˆ–è€…CNNå»ºæ¨¡æ—¶é—´ä¾èµ–å…³ç³»ã€‚</p>
<h3 id="2-2-æ¡†æ¶"><a href="#2-2-æ¡†æ¶" class="headerlink" title="2.2 æ¡†æ¶"></a>2.2 æ¡†æ¶</h3><ol>
<li>node_level<br> è¾“å‡ºç”¨äº<strong>ç‚¹å›å½’å’Œåˆ†ç±»ä»»åŠ¡</strong>ã€‚å›¾å·ç§¯æ¨¡å‹ç›´æ¥ç»™å®šèŠ‚ç‚¹çš„æ½œåœ¨è¡¨ç¤ºï¼Œç„¶åä¸€ä¸ªå¤šå±‚æ„ŸçŸ¥æœºæˆ–è€…softmaxå±‚ç”¨ä½œGCNæœ€åä¸€å±‚ã€‚</li>
<li>Edge-level<br> è¾“å‡ºä¸<strong>è¾¹åˆ†ç±»å’Œé“¾è·¯é¢„æµ‹ä»»åŠ¡</strong>ç›¸å…³ã€‚ä¸ºäº†é¢„æµ‹ä¸€æ¡è¾¹çš„æ ‡ç­¾æˆ–è€…è¿æ¥å¼ºåº¦ï¼Œé™„åŠ å‡½æ•°ä»å›¾å·ç§¯æ¨¡å‹ä¸­æå–ä¸¤ä¸ªèŠ‚ç‚¹çš„æ½œåœ¨è¡¨ç¤ºä½œä¸ºè¾“å…¥ã€‚</li>
<li>Graph-level<br> è¾“å‡ºå’Œ<strong>å›¾åˆ†ç±»ä»»åŠ¡</strong>ç›¸å…³ï¼Œæ± åŒ–æ¨¡å—ç”¨äºæ± åŒ–ä¸€ä¸ªå›¾ä¸ºå­å›¾æˆ–è€…å¯¹èŠ‚ç‚¹è¡¨ç¤ºæ±‚å’Œ&#x2F;æ±‚å¹³å‡ï¼Œä»¥è·å¾—å›¾çº§åˆ«ä¸Šçš„ç´§å‡‘è¡¨ç¤ºã€‚</li>
</ol>
<p>ç«¯åˆ°ç«¯è®­ç»ƒæ¡†æ¶ï¼šGCNå¯ä»¥åœ¨ç«¯åˆ°ç«¯å­¦ä¹ æ¡†æ¶ä¸­è¿›è¡Œ(åŠ)ç›‘ç£æˆ–æ— ç›‘ç£çš„è®­ç»ƒï¼Œå–å†³äºå­¦ä¹ ä»»åŠ¡å’Œæ ‡ç­¾ä¿¡æ¯çš„å¯ç”¨æ€§ã€‚</p>
<ol>
<li>node-level åŠç›‘ç£åˆ†ç±»ã€‚ç»™å®šä¸€ä¸ªéƒ¨åˆ†èŠ‚ç‚¹è¢«æ ‡è®°è€Œå…¶ä»–èŠ‚ç‚¹æœªæ ‡è®°çš„ç½‘ç»œï¼ŒGCNå¯ä»¥å­¦ä¹ ä¸€ä¸ªé²æ£’çš„æ¨¡å‹ï¼Œæœ‰æ•ˆåœ°è¯†åˆ«æœªæ ‡è®°èŠ‚ç‚¹çš„ç±»æ ‡ç­¾ã€‚ä¸ºæ­¤ï¼Œå¯ä»¥æ„å»ºä¸€ä¸ªç«¯åˆ°ç«¯çš„å¤šåˆ†ç±»æ¡†æ¶ï¼Œé€šè¿‡å åŠ å‡ ä¸ªå›¾å½¢å·ç§¯å±‚ï¼Œç´§è·Ÿç€ä¸€ä¸ªsoftmaxå±‚ã€‚</li>
<li>graph-level ç›‘ç£åˆ†ç±»ã€‚ç»™å®šä¸€ä¸ªå›¾æ•°æ®é›†ï¼Œå›¾çº§åˆ†ç±»æ—¨åœ¨é¢„æµ‹æ•´ä¸ªå›¾çš„ç±»æ ‡ç­¾(s)ï¼Œç«¯åˆ°ç«¯å­¦ä¹ æ¡†æ¶ï¼Œé€šè¿‡ç»“åˆGCNå’Œæ± åŒ–è¿‡ç¨‹å®ç°ã€‚å…·ä½“çš„ï¼Œé€šè¿‡GCNè·å¾—æ¯ä¸ªå›¾é‡Œæ¯ä¸ªèŠ‚ç‚¹å›ºå®šç»´æ•°çš„ç‰¹å¾è¡¨ç¤ºï¼Œç„¶åï¼Œé€šè¿‡æ± åŒ–æ±‚å›¾ä¸­æ‰€æœ‰èŠ‚ç‚¹çš„è¡¨ç¤ºå‘é‡çš„å’Œï¼Œä»¥å¾—åˆ°æ•´ä¸ªå›¾çš„è¡¨ç¤ºã€‚æœ€åï¼ŒåŠ ä¸Šå¤šå±‚æ„ŸçŸ¥æœºå’Œsoftmaxå±‚ï¼Œå¯ä»¥æ„é€ ä¸€ä¸ªç«¯åˆ°ç«¯çš„å›¾åˆ†ç±»ã€‚å›¾5ï¼ˆaï¼‰å±•ç¤ºäº†è¿™æ ·ä¸€ä¸ªè¿‡ç¨‹ã€‚</li>
<li>æ— ç›‘ç£å›¾åµŒå…¥ã€‚å›¾ä¸­æ²¡æœ‰æ ‡ç­¾æ•°æ®çš„æ—¶å€™ï¼Œå¯ä»¥åœ¨ç«¯åˆ°ç«¯çš„æ¡†æ¶ä¸­ä»¥æ— ç›‘ç£çš„æ–¹å¼å­¦ä¹ ä¸€ç§å›¾åµŒå…¥ã€‚è¿™äº›ç®—æ³•ä»¥ä¸¤ç§æ–¹å¼åˆ©ç”¨è¾¹çº§ä¿¡æ¯ã€‚ä¸€ç§ç®€å•çš„ï¼šåˆ©ç”¨è‡ªç¼–ç æ¡†æ¶ï¼Œç¼–ç å™¨åˆ©ç”¨GCNå°†å›¾åµŒå…¥åˆ°æ½œåœ¨çš„è¡¨ç¤ºä¸­ï¼Œè§£ç å™¨åˆ©ç”¨æ½œåœ¨çš„è¡¨ç¤ºé‡æ„å›¾ç»“æ„ã€‚å¦ä¸€ç§æ–¹å¼ï¼šåˆ©ç”¨è´Ÿé‡‡æ ·æ–¹æ³•ï¼ŒæŠ½å–ä¸€éƒ¨åˆ†èŠ‚ç‚¹å¯¹ä½œä¸ºè´Ÿå¯¹ï¼Œå›¾ä¸­å‰©ä½™çš„èŠ‚ç‚¹å¯¹ä½œä¸ºæ­£å¯¹ï¼Œä¹‹ååˆ©ç”¨é€»è¾‘å›å½’å±‚ï¼Œå½¢æˆä¸€ä¸ªç«¯åˆ°ç«¯çš„å­¦ä¹ æ¡†æ¶ã€‚</li>
</ol>
<h2 id="3-å›¾å·ç§¯ç½‘ç»œ"><a href="#3-å›¾å·ç§¯ç½‘ç»œ" class="headerlink" title="3. å›¾å·ç§¯ç½‘ç»œ"></a>3. å›¾å·ç§¯ç½‘ç»œ</h2><p>åˆ†ä¸ºä¸¤ç±»</p>
<ol>
<li>Spectral-basedæ–¹æ³•<br> ä»å›¾ä¿¡å·å¤„ç†çš„è§’åº¦å¼•å…¥æ»¤æ³¢å™¨æ¥å®šä¹‰å›¾å·ç§¯ï¼Œæ­¤ä½¿å›¾å·ç§¯è¢«è§£é‡Šä¸ºä»å›¾ä¿¡å·ä¸­å»é™¤å™ªå£°ã€‚</li>
<li>Spatial-basedçš„æ–¹æ³•<br> å°†å›¾å·ç§¯è¡¨ç¤ºä¸ºæ¥è‡ªé‚»å±…èŠ‚ç‚¹çš„ç‰¹å¾ä¿¡æ¯çš„ç»“åˆ</li>
</ol>
<h3 id="3-1-åŸºäºå›¾è°±çš„GCN"><a href="#3-1-åŸºäºå›¾è°±çš„GCN" class="headerlink" title="3.1 åŸºäºå›¾è°±çš„GCN"></a>3.1 åŸºäºå›¾è°±çš„GCN</h3><p>$$<br>x * G g_{\theta}&#x3D;U g_{\theta} U^{T} x<br>$$</p>
<p>åŸºäºè°±çš„GCNéƒ½éµå¾ªè¿™ä¸ªå®šä¹‰ï¼Œä¸åŒçš„æ˜¯æ»¤æ³¢å™¨$g_{\theta}$çš„é€‰æ‹©ä¸åŒã€‚</p>
<p><strong>ç¼ºé™·</strong><br>é¦–å…ˆï¼Œå¯¹å›¾çš„ä»»ä½•æ‰°åŠ¨éƒ½ä¼šå¯¼è‡´ç‰¹å¾åŸºçš„å˜åŒ–ã€‚å…¶æ¬¡ï¼Œå­¦ä¹ çš„è¿‡æ»¤å™¨ä¾èµ–äºä¸åŒé¢†åŸŸï¼Œè¿™æ„å‘³ç€å®ƒä»¬ä¸èƒ½åº”ç”¨äºå…·æœ‰ä¸åŒç»“æ„çš„å›¾ã€‚ç¬¬ä¸‰ï¼Œç‰¹å¾åˆ†è§£éœ€è¦$O(N^3)$è®¡ç®—å’Œ$O(N^2)$å†…å­˜</p>
<p>è°±æ–¹æ³•çš„ä¸€ä¸ªå¸¸è§ç¼ºç‚¹æ˜¯éœ€è¦å°†æ•´ä¸ªå›¾åŠ è½½åˆ°å†…å­˜ä¸­è¿›è¡Œå›¾å·ç§¯ï¼Œè¿™åœ¨å¤„ç†å¤§å›¾æ—¶æ•ˆç‡ä¸é«˜ã€‚</p>
<h3 id="3-2-åŸºäºç©ºé—´çš„GCN"><a href="#3-2-åŸºäºç©ºé—´çš„GCN" class="headerlink" title="3.2 åŸºäºç©ºé—´çš„GCN"></a>3.2 åŸºäºç©ºé—´çš„GCN</h3><p>åˆ†ä¸ºåŸºäºå¾ªç¯å’ŒåŸºäºç»„åˆçš„GCNsã€‚åŸºäºå¾ªç¯çš„GCNä½¿ç”¨ä¸€ä¸ªç›¸åŒçš„GCLä¸ªæ›´æ–°éšå«è¡¨ç¤ºï¼ŒåŸºäºç»„åˆGCNåˆ™ä½¿ç”¨ä¸åŒçš„GCLæ›´æ–°éšå«è¡¨ç¤ºã€‚<br><img src="/11-GNN-survey2/08-spatial_GCN.png" alt="spatial gcn"></p>
<p><strong>åŸºäºå¾ªç¯çš„ç©ºé—´GCNs</strong><br>åŸºäºé€’å½’çš„æ–¹æ³•çš„ä¸»è¦æ€æƒ³æ˜¯é€’å½’åœ°æ›´æ–°èŠ‚ç‚¹çš„æ½œåœ¨è¡¨ç¤ºï¼Œç›´åˆ°è¾¾åˆ°ç¨³å®šçš„ä¸åŠ¨ç‚¹ã€‚é€šè¿‡å¯¹å¾ªç¯å‡½æ•°æ–½åŠ çº¦æŸã€ä½¿ç”¨é—¨å¾ªç¯å•å…ƒæ¶æ„ã€å¼‚æ­¥å’Œéšæœºæ›´æ–°èŠ‚ç‚¹æ½œåœ¨è¡¨ç¤ºæ¥å®ç°ã€‚</p>
<p><strong>åŸºäºç»„åˆçš„ç©ºé—´GCNs</strong><br>åŸºäºç»„åˆçš„æ–¹æ³•é€šè¿‡å åŠ å¤šä¸ªå›¾çš„å·ç§¯å±‚æ¥æ›´æ–°èŠ‚ç‚¹çš„è¡¨ç¤ºã€‚</p>
<h3 id="3-3-å›¾æ± æ¨¡å—"><a href="#3-3-å›¾æ± æ¨¡å—" class="headerlink" title="3.3 å›¾æ± æ¨¡å—"></a>3.3 å›¾æ± æ¨¡å—</h3><h3 id="3-4-åŸºäºå…‰è°±å’Œç©ºé—´çš„GCNsçš„å¯¹æ¯”"><a href="#3-4-åŸºäºå…‰è°±å’Œç©ºé—´çš„GCNsçš„å¯¹æ¯”" class="headerlink" title="3.4 åŸºäºå…‰è°±å’Œç©ºé—´çš„GCNsçš„å¯¹æ¯”"></a>3.4 åŸºäºå…‰è°±å’Œç©ºé—´çš„GCNsçš„å¯¹æ¯”</h3><ol>
<li>æ•ˆç‡<br> åŸºäºå…‰è°±çš„æ–¹æ³•çš„è®¡ç®—é‡ä¼šéšç€å›¾çš„å¤§å°æ€¥å‰§å¢åŠ ï¼Œå› ä¸ºæ¨¡å‹éœ€è¦åŒæ—¶è®¡ç®—ç‰¹å¾å‘é‡æˆ–è€…åŒæ—¶å¤„ç†å¤§å›¾ï¼Œè¿™å°±ä½¿å¾—æ¨¡å‹å¾ˆéš¾å¯¹å¤§å›¾è¿›è¡Œå¹¶è¡Œå¤„ç†æˆ–ç¼©æ”¾ã€‚åŸºäºç©ºé—´çš„å›¾æ–¹æ³•ç”±äºç›´æ¥å¯¹å›¾åŸŸçš„é‚»å±…èŠ‚ç‚¹è¿›è¡Œèšåˆï¼Œæ‰€ä»¥æœ‰æ½œåŠ›å¤„ç†å¤§å›¾ï¼Œæ–¹æ³•æ˜¯å¯¹ä¸€ä¸ªbatchæ•°æ®è®¡ç®—è€Œä¸æ˜¯åœ¨æ•´ä¸ªå›¾ä¸Šè®¡ç®—ã€‚å¦‚æœé‚»å±…èŠ‚ç‚¹çš„æ•°é‡å¢åŠ ï¼Œèƒ½å¤Ÿé€šè¿‡é‡‡æ ·æŠ€æœ¯æé«˜æ•ˆç‡ã€‚</li>
<li>é€šç”¨æ€§<br> åŸºäºå…‰è°±çš„å›¾æ–¹æ³•å‡è®¾å›¾æ˜¯å›ºå®šçš„ï¼Œå› æ­¤å¯¹æ–°çš„æˆ–è€…ä¸åŒçš„å›¾æ³›åŒ–æ€§èƒ½å¾ˆå·®ã€‚åŸºäºç©ºé—´çš„æ–¹æ³•åœ¨æ¯ä¸ªèŠ‚ç‚¹ä¸Šè¿›è¡Œå±€éƒ¨å›¾å·ç§¯ï¼Œæƒå€¼å¯ä»¥å¾ˆå®¹æ˜“åœ°åœ¨ä¸åŒåœ°ä½ç½®å’Œç»“æ„ä¹‹é—´å…±äº«ã€‚</li>
<li>çµæ´»æ€§<br> åŸºäºè°±çš„æ¨¡å‹åªé€‚ç”¨äºæ— å‘å›¾ï¼Œè°±æ–¹æ³•ç”¨äºæœ‰å‘å›¾çš„å”¯ä¸€æ–¹æ³•æ˜¯uå°†æœ‰å‘å›¾è½¬æ¢ä¸ºæ— å‘å›¾ï¼Œå› ä¸ºæ²¡æœ‰æœ‰å‘å›¾çš„æ‹‰æ™®æ‹‰æ–¯çŸ©é˜µæ˜ç¡®çš„å®šä¹‰ã€‚åŸºäºç©ºé—´çš„æ¨¡å‹å¯ä»¥å°†è¾“å…¥åˆå¹¶åˆ°èšåˆå‡½æ•°ä¸­ï¼Œæ‰€ä»¥åœ¨å¤„ç†å¤šæºè¾“å…¥åƒæ˜¯è¾¹ç‰¹å¾ï¼Œè¾¹æ–¹å‘ä¸Šæ›´çµæ´»ã€‚</li>
</ol>
<p>å› æ­¤ï¼Œè¿‘å¹´æ¥ï¼ŒåŸºäºç©ºé—´çš„æ–¹æ³•æ›´å—å…³æ³¨ã€‚</p>
<h2 id="4-è¶…GCNç½‘ç»œ"><a href="#4-è¶…GCNç½‘ç»œ" class="headerlink" title="4. è¶…GCNç½‘ç»œ"></a>4. è¶…GCNç½‘ç»œ</h2><p>GAN GAT GGN GSTN</p>
<h3 id="4-1-å›¾æ³¨æ„åŠ›ç½‘ç»œGAN"><a href="#4-1-å›¾æ³¨æ„åŠ›ç½‘ç»œGAN" class="headerlink" title="4.1 å›¾æ³¨æ„åŠ›ç½‘ç»œGAN"></a>4.1 å›¾æ³¨æ„åŠ›ç½‘ç»œGAN</h3><ol>
<li>GAT</li>
<li>GAAN</li>
<li>GAM</li>
<li>æ³¨æ„åŠ›æ¸¸èµ°</li>
<li>æ·±åº¦æ¸¸èµ°</li>
</ol>
<p>æ³¨æ„åŠ›æœºåˆ¶å¯¹GNNçš„è´¡çŒ®åˆ†ä¸ºä¸‰ä¸ªæ–¹é¢ï¼Œåœ¨èšåˆç‰¹å¾ä¿¡æ¯çš„æ—¶å€™å¯¹ä¸åŒçš„é‚»å±…èŠ‚ç‚¹åˆ†é…ä¸åŒçš„æƒå€¼ï¼Œæ ¹æ®æ³¨æ„åŠ›æƒé‡é›†æˆå¤šä¸ªæ¨¡å‹ï¼Œä½¿ç”¨æ³¨æ„åŠ›æƒé‡æŒ‡å¯¼éšæœºæ¸¸èµ°ã€‚å°½ç®¡å°†GATå’ŒGAANå½’ä¸ºå›¾çš„æ³¨æ„ç½‘ç»œçš„èŒƒç•´ï¼Œå®ƒä»¬ä¹ŸåŒæ—¶æ˜¯åŸºäºç©ºé—´çš„GCNã€‚GATå’ŒGAANçš„ä¼˜ç‚¹æ˜¯å¯ä»¥è‡ªé€‚åº”å­¦ä¹ é‚»å±…çš„é‡è¦æ€§æƒé‡ï¼Œå¦‚å›¾6æ‰€ç¤ºã€‚ä½†æ˜¯ï¼Œç”±äºå¿…é¡»è®¡ç®—æ¯å¯¹é‚»å±…ä¹‹é—´çš„æ³¨æ„åŠ›æƒé‡ï¼Œè®¡ç®—æˆæœ¬å’Œå†…å­˜æ¶ˆè€—è¿…é€Ÿå¢åŠ ã€‚</p>
<h3 id="4-2-å›¾è‡ªç¼–ç "><a href="#4-2-å›¾è‡ªç¼–ç " class="headerlink" title="4.2 å›¾è‡ªç¼–ç "></a>4.2 å›¾è‡ªç¼–ç </h3><p>ç½‘ç»œåµŒå…¥è‡´åŠ›äºä½¿ç”¨ç¥ç»ç½‘ç»œæ¶æ„å°†<strong>ç½‘ç»œé¡¶ç‚¹åœ¨ä½ç»´å‘é‡ç©ºé—´è¿›è¡Œè¡¨ç¤º</strong>ï¼Œå›¾è‡ªç¼–ç æ˜¯ç½‘ç»œåµŒå…¥çš„ä¸€ç§ç±»å‹ã€‚å…¸å‹åšæ³•æ˜¯åˆ©ç”¨å¤šå±‚æ„ŸçŸ¥æœºä½œä¸ºç¼–ç å™¨ï¼Œè·å¾—èŠ‚ç‚¹åµŒå…¥ï¼Œç„¶åè§£ç å™¨æ®æ­¤é‡æ„èŠ‚ç‚¹çš„é‚»åŸŸç»Ÿè®¡ä¿¡æ¯ï¼Œå¦‚æ­£ç‚¹æ€äº’ä¿¡æ¯(positive pointwise mutual information, PPMI)æˆ–ä¸€é˜¶å’ŒäºŒé˜¶è¿‘ä¼¼ã€‚è¿‘æœŸï¼Œç ”ç©¶å‘˜æ¢ç´¢å°†GCN[ä½œä¸ºç¼–ç å™¨,è®¾è®¡å›¾è‡ªç¼–ç å™¨çš„æ—¶å€™æˆ–ç»“åˆHCNä¸GANï¼Œæˆ–ç»“åˆGANä¸LSTMã€‚</p>
<p>è¿™äº›æ–¹æ³•éƒ½å­¦ä¹ èŠ‚ç‚¹åµŒå…¥ï¼Œä½†æ˜¯DNGRå’ŒSDNEåªç»™å®šæ‹“æ‰‘ç»“æ„ï¼Œè€ŒGAEã€ARGAã€NetRAå’ŒDRNEä¸ä»…ç»™å®šæ‹“æ‰‘ç»“æ„è€Œä¸”ç»™å®šèŠ‚ç‚¹å†…å®¹ç‰¹æ€§ã€‚å›¾è‡ªç¼–ç çš„ä¸€ä¸ªæŒ‘æˆ˜æ˜¯é‚»æ¥çŸ©é˜µçš„ç¨€ç–æ€§ï¼Œä½¿è§£ç å™¨çš„æ­£é¡¹æ•°è¿œå°‘äºè´Ÿé¡¹æ•°ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼ŒDNGRé‡æ„äº†ä¸€ä¸ªæ›´ç´§å¯†çš„çŸ©é˜µå³PPMIçŸ©é˜µï¼ŒSDNEå¯¹é‚»æ¥çŸ©é˜µçš„é›¶é¡¹è¿›è¡Œäº†æƒ©ç½šï¼ŒGAEå¯¹é‚»æ¥çŸ©é˜µä¸­çš„é¡¹è¿›è¡Œäº†åŠ æƒï¼ŒNetRAå°†å›¾çº¿æ€§åŒ–ä¸ºåºåˆ—ã€‚</p>
<h3 id="4-3-å›¾ç”Ÿæˆç½‘ç»œ"><a href="#4-3-å›¾ç”Ÿæˆç½‘ç»œ" class="headerlink" title="4.3 å›¾ç”Ÿæˆç½‘ç»œ"></a>4.3 å›¾ç”Ÿæˆç½‘ç»œ</h3><p>å›¾ç”Ÿæˆç½‘ç»œï¼ˆGGNï¼‰çš„ç›®æ ‡æ˜¯ï¼Œåœ¨ç»™å®šä¸€ç»„è§‚å¯Ÿåˆ°çš„å›¾çš„å‰æä¸‹ç”Ÿæˆå›¾ã€‚å¾ˆå¤šå›¾ç”Ÿæˆæ–¹æ³•æ˜¯ä¸ç‰¹å®šé¢†åŸŸç›¸å…³çš„ï¼Œä¾‹å¦‚ï¼Œåˆ†å­å›¾ç”Ÿæˆï¼Œä¸€äº›æ–¹æ³•æ˜¯å¯¹åˆ†å­å›¾è¿›è¡Œå­—ç¬¦ä¸²è¡¨ç¤ºå»ºæ¨¡ï¼Œå«åšSMILESï¼Œè‡ªç„¶è¯­è¨€å¤„ç†ï¼Œä»¥ç»™å®šçš„å¥å­ä¸ºæ¡ä»¶ç”Ÿæˆè¯­ä¹‰å›¾æˆ–è€…çŸ¥è¯†å›¾ã€‚æœ€è¿‘ï¼Œæå‡ºäº†ä¸€äº›ç»Ÿä¸€çš„ç”Ÿæˆæ–¹æ³•ï¼Œä¸€äº›æ–¹æ³•å°†ç”Ÿæˆè¿‡ç¨‹çœ‹ä½œäº¤æ›¿ç”ŸæˆèŠ‚ç‚¹å’Œè¾¹ï¼Œå…¶ä»–çš„æ–¹æ³•åˆ©ç”¨ç”Ÿæˆå¯¹æŠ—è®­ç»ƒã€‚GGNä¸­çš„æ–¹æ³•æˆ–è€…åˆ©ç”¨GCNä½œä¸ºæ„å»ºå—ï¼Œæˆ–è€…ä½¿ç”¨ä¸åŒçš„æ¶æ„ã€‚</p>
<p>å¯¹ç”Ÿæˆçš„å›¾è¿›è¡Œè¯„ä¼°ä»ç„¶æ˜¯ä¸€ä¸ªéš¾é¢˜ã€‚ä¸äººå·¥åˆæˆå›¾åƒæˆ–è€…éŸ³é¢‘ä¸åŒï¼Œä»–ä»¬èƒ½å¤Ÿç›´æ¥è¢«äººç±»ä¸“å®¶è¯„ä¼°ï¼Œç”Ÿæˆçš„å›¾çš„è´¨é‡å¾ˆéš¾ç›´è§‚æ£€æµ‹ã€‚MolGANå’ŒDGMGåˆ©ç”¨å¤–éƒ¨çŸ¥è¯†æ¥è¯„ä¼°ç”Ÿæˆåˆ†å­å›¾çš„æœ‰æ•ˆæ€§ã€‚GraphRNNå’ŒNetGANé€šè¿‡å›¾ç»Ÿè®¡ä¿¡æ¯(å¦‚èŠ‚ç‚¹åº¦)è¯„ä¼°ç”Ÿæˆçš„å›¾å½¢ã€‚DGMGå’ŒGraphRNNä¾æ¬¡ç”ŸæˆèŠ‚ç‚¹å’Œè¾¹ç¼˜ï¼ŒMolGANå’ŒNetGANåŒæ—¶ç”ŸæˆèŠ‚ç‚¹å’Œè¾¹ç¼˜ã€‚æ ¹æ®[68]ï¼Œå‰ä¸€ç§æ–¹æ³•çš„ç¼ºç‚¹æ˜¯å½“å›¾å˜å¤§æ—¶ï¼Œå¯¹é•¿åºåˆ—å»ºæ¨¡æ˜¯ä¸ç°å®çš„ã€‚åä¸€ç§æ–¹æ³•çš„æŒ‘æˆ˜æ˜¯å¾ˆéš¾æ§åˆ¶å›¾çš„å…¨å±€å±æ€§ã€‚æœ€è¿‘ä¸€ç§æ–¹æ³•[68]é‡‡ç”¨å˜åˆ†è‡ªç¼–ç å™¨é€šè¿‡ç”Ÿæˆé‚»æ¥çŸ©é˜µæ¥ç”Ÿæˆå›¾å½¢ï¼Œå¼•å…¥æƒ©ç½šé¡¹æ¥è§£å†³æœ‰æ•ˆæ€§çº¦æŸã€‚ç„¶è€Œï¼Œç”±äºå…·æœ‰nä¸ªèŠ‚ç‚¹çš„å›¾çš„è¾“å‡ºç©ºé—´ä¸º$n^2$<br> ï¼Œè¿™äº›æ–¹æ³•éƒ½ä¸èƒ½æ‰©å±•åˆ°å¤§å‹å›¾ã€‚</p>
<h3 id="4-4-å›¾æ—¶ç©ºç½‘ç»œ"><a href="#4-4-å›¾æ—¶ç©ºç½‘ç»œ" class="headerlink" title="4.4 å›¾æ—¶ç©ºç½‘ç»œ"></a>4.4 å›¾æ—¶ç©ºç½‘ç»œ</h3><p>å›¾æ—¶ç©ºç½‘ç»œåŒæ—¶æ•è·æ—¶ç©ºå›¾çš„æ—¶ç©ºä¾èµ–æ€§ã€‚æ—¶ç©ºå›¾å…·æœ‰å…¨å±€å›¾ç»“æ„ï¼Œæ¯ä¸ªèŠ‚ç‚¹çš„è¾“å…¥éšæ—¶é—´å˜åŒ–ã€‚ä¾‹å¦‚ï¼Œåœ¨äº¤é€šç½‘ç»œä¸­ï¼Œå°†æ¯ä¸ªä¼ æ„Ÿå™¨ä½œä¸ºä¸€ä¸ªèŠ‚ç‚¹ï¼Œè¿ç»­è®°å½•æŸæ¡é“è·¯çš„äº¤é€šé€Ÿåº¦ï¼Œå…¶ä¸­äº¤é€šç½‘ç»œçš„è¾¹ç”±ä¼ æ„Ÿå™¨å¯¹ä¹‹é—´çš„è·ç¦»å†³å®šã€‚å›¾æ—¶ç©ºç½‘ç»œçš„ç›®æ ‡æ˜¯é¢„æµ‹æœªæ¥çš„èŠ‚ç‚¹å€¼æˆ–æ ‡ç­¾ï¼Œæˆ–é¢„æµ‹æ—¶ç©ºå›¾æ ‡ç­¾ã€‚æœ€è¿‘çš„ç ”ç©¶æ¢ç´¢äº†å•ç‹¬ä½¿ç”¨GCNs[72]ï¼Œç»“GCNsä¸RNN[70]æˆ–CNN[71]ï¼Œä»¥åŠä¸€ç§ä¸ºå›¾ç»“æ„å®šåˆ¶çš„å¾ªç¯æ¶æ„[73]ã€‚</p>
<p>DCRNNç”±äºåˆ©ç”¨äº†å¾ªç¯ç½‘ç»œæ¶æ„èƒ½å¤Ÿå¤„ç†é•¿æ—¶é—´ä¾èµ–å…³ç³»ã€‚è™½ç„¶CNN-GCNæ¯”DCRNNç®€å•ï¼Œä½†æ˜¯ç”±äºä»–é¦–å…ˆå®ç°äº†1D-CNNï¼Œæ‰€ä»¥åœ¨å¤„ç†æ—¶ç©ºå›¾ä¸Šæ›´åŠ é«˜æ•ˆã€‚ST-GCNå°†æ—¶é—´æµä½œä¸ºå›¾çš„è¾¹ï¼Œä½¿é‚»æ¥çŸ©é˜µçš„å¤§å°å‘ˆäºŒæ¬¡å¢é•¿ã€‚ä¸€æ–¹é¢ï¼Œå¢åŠ äº†å›¾å·ç§¯å±‚çš„è®¡ç®—æˆæœ¬ã€‚å¦ä¸€æ–¹é¢ï¼Œä¸ºäº†æ•è·é•¿æœŸä¾èµ–å…³ç³»ï¼Œå›¾å·ç§¯å±‚å¿…é¡»å¤šæ¬¡å åŠ ã€‚Structural-RNNé€šè¿‡åœ¨ç›¸åŒçš„è¯­ä¹‰ç»„å…±äº«ç›¸åŒçš„RNNæé«˜äº†æ¨¡å‹çš„æœ‰æ•ˆæ€§ã€‚ä½†æ˜¯ï¼Œéœ€è¦äººç±»å…ˆéªŒçŸ¥è¯†æ¥åˆ’åˆ†è¯­ä¹‰ç»„ã€‚</p>
]]></content>
      <categories>
        <category>Survey</category>
      </categories>
      <tags>
        <tag>GNN</tag>
      </tags>
  </entry>
  <entry>
    <title>æœ€è¿‘çš„ä¸€äº›è¿›å±• 2022.02</title>
    <url>/2022/02/08/thoughts-01/</url>
    <content><![CDATA[<h2 id="1-ç®€å•è®°å½•ä¸€ä¸‹æœ€è¿‘çš„è¿›å±•"><a href="#1-ç®€å•è®°å½•ä¸€ä¸‹æœ€è¿‘çš„è¿›å±•" class="headerlink" title="1. ç®€å•è®°å½•ä¸€ä¸‹æœ€è¿‘çš„è¿›å±•"></a>1. ç®€å•è®°å½•ä¸€ä¸‹æœ€è¿‘çš„è¿›å±•</h2><p>ä¸Šæ¬¡å†™åšå®¢ä¹Ÿæ˜¯å¥½ä¹…ä¹‹å‰äº†ï¼Œç ”ç©¶ç”Ÿåˆšå¼€å§‹çš„æ—¶å€™è¿˜å…´å†²å†²çš„ï¼Œå¸Œæœ›å…»æˆå†™åšå®¢çš„å¥½ä¹ æƒ¯ï¼Œè®°å½•ä¸€ä¸‹è‡ªå·±çš„æˆé•¿ï¼Œä¹Ÿè®°å½•ä¸€ä¸‹æ—¥å¸¸å­¦ä¹ ç”Ÿæ´»è¸©è¿‡çš„å‘ã€‚<br>ä½†æ˜¯éª¨å­é‡Œçš„æ‡’æƒ°è¿˜æ˜¯æŠµä¸ä½ï¼Œå…´èµ·çš„çƒ­æƒ…åœ¨å†™äº†å‡ ç¯‡ä»¥åå°±è¢«æµ‡ç­äº†ã€‚<br>å…¶å®æ„Ÿè§‰è¿™ä¸ªä¸œè¥¿å†™èµ·æ¥æˆæœ¬ä¹Ÿæ²¡æœ‰é‚£ä¹ˆé«˜ã€‚é…ç½®ç¯å¢ƒä¹Ÿæ˜¯è®¡ç®—æœºäººå¸¸å¸¸è¦è¹šè¿‡çš„æµ‘æ°´ï¼Œåˆ°å†™çš„æ—¶å€™ï¼Œçœ‹ç€è‡ªå·±çš„æ–‡å­—è¢«æ¸²æŸ“æˆç½‘é¡µï¼Œç¨å¾®æ„Ÿå—äº†ä¸€ä¸‹å‰ç«¯äººçš„å¿«ä¹äº†ã€‚</p>
<p>æœ€è¿‘å‡ ä¸ªæœˆç»å†çš„äº‹æƒ…å¯èƒ½æ¯”æ•´ä¸ªç ”ç©¶ç”Ÿé˜¶æ®µç»å†çš„éƒ½è¦å¤šäº†ã€‚å–œå¿§éƒ½æœ‰ï¼Œè¿™é‡Œå€’ä¸çŸ¥ä»ä½•å¼€å¤´ï¼Œä¹Ÿå°±é¡ºç€æ—¶é—´è®²ä¸€ä¸‹å§ã€‚</p>
<p>é¦–å…ˆæ˜¯å®ä¹ è½¬æ­£ï¼Œæ„Ÿè§‰å…¶å®æœ‰ç‚¹æƒŠé™©ï¼Œç»„é‡Œé¢çš„hcå¤§æŠµæ˜¯ä¸å¤šçš„ï¼Œæˆ‘åˆæ˜¯é åå‡ ä¸ªæèµ·ç­”è¾©çš„ï¼ŒæŒ‰é“ç†å…è®¸ä½ æèµ·ç­”è¾©å…¶å®å°±æ˜¯é»˜è®¤èƒ½è¿‡çš„ï¼Œä½†æ˜¯ä»Šå¹´äº’è”ç½‘çš„å½¢åŠ¿ååˆ†ä¸¥å³»ï¼Œ<br>å­—èŠ‚å¹¶æ²¡æœ‰é‡‡å–æ‰©æ‹›ï¼Œè€Œæ˜¯ä½¿ç”¨äº†å°‘é‡hcæé«˜äººå‡packageçš„ç­–ç•¥ã€‚å½“æ—¶å…¶å®æˆ‘ä¹Ÿæ˜¯ä¸çŸ¥é“æœ‰è¿™ä¸ªæƒ…å†µï¼Œåœ¨8æœˆä¸­æ—¬æ…¢ååçš„æäº¤äº†ç­”è¾©ï¼Œå…¶å®å½“æ—¶æˆ‘å¹¶æ²¡æœ‰ä»€ä¹ˆæ˜æ˜¾çš„äº§å‡ºï¼Œåªæ˜¯è‡ªå·±æ¢ç´¢äº†ä¸€äº›NASåœ¨å¹¿å‘Šé‡Œé¢çš„åº”ç”¨æ–¹å‘ï¼Œæˆ‘ç†è§£æˆ‘çš„offerå³ä¾¿èƒ½å¤Ÿæ‹¿åˆ°ï¼Œå¯èƒ½ä¹Ÿåªæ˜¯ç»„å†…çš„ä¸€ä¸ªé—¨æ§›æ°´å¹³ï¼ˆå°SPï¼Ÿï¼‰ã€‚å½“æ—¶è¿˜æ˜¯å¿ƒæœ‰ä¸ç”˜çš„ï¼Œè§‰å¾—è‡ªå·±èƒ½åŠ›ä¸æ­¢äºæ­¤ï¼Œå› æ­¤åè€Œå¯¹è¿™ä¸ªofferæœŸæœ›ä¸å¤§ï¼Œä½†æ˜¯æœ€åé€‰æ‹©å­—èŠ‚åè€Œæœ‰ç‚¹é˜´å·®é˜³é”™äº†ã€‚å½“ç„¶å³ä¾¿å¦‚æ­¤ï¼Œè¿™ä¸ªofferä¹Ÿæ˜¯å°½åŠ›è¦æ‹¿åˆ°ï¼Œç¨³å®šä¸€ä¸‹å†›å¿ƒã€‚å½“æ—¶å·²ç»é¢è¿‡äº†è™¾çš®ï¼Œä¸€å¿ƒæƒ³runå»sgã€‚è¿™ä¸ªåé¢å†è°ˆäº†ã€‚ç­”è¾©æœ‰æƒŠæ— é™©ï¼Œå‘wqå’Œsxä¸¤ä½å¤§ä½¬è¿›è¡Œæ±‡æŠ¥ï¼Œå‹åŠ›å±å®æœ‰ç‚¹å¤§ï¼Œæ„Ÿè§‰è¯´è¯æœ‰ç‚¹ç»“å·´ï¼Œè¿™ä¸ªä¹Ÿæ˜¯ä¸ªäººé—®é¢˜ï¼Œä»å°åˆ°å¤§ï¼Œåœ¨é‡è¦åœºåˆå±•ç¤ºè‡ªå·±æ€»æ˜¯ç´§å¼ åˆ°ä¸è¡Œã€‚</p>
<p>ç¬¬äºŒä»¶äº‹æƒ…ï¼Œå°±æ˜¯çˆ¸çˆ¸çš„ç—…æƒ…ã€‚çˆ¸çˆ¸å½“æ—¶åœ¨ä¸‰æœˆä»½çš„æ—¶å€™æ£€æŸ¥å‡ºè„‘éƒ¨åŸºåº•å·¨å¤§åŠ¨è„‰ç˜¤ï¼ŒåŸºæœ¬ä¸Šä¹Ÿå±äºç–‘éš¾æ‚ç—‡äº†ï¼Œå‘ç—…ç‡æä½ï¼Œä½†æ˜¯å…¨å›½æ²»å¥½çš„ä¾‹å­ä¹Ÿä¸å¤šã€‚ä¸‰æœˆä»½ç”±äºä¸˜è„‘å‡ºè¡€ï¼Œä»–ä½†æ˜¯çš„è¯­è¨€è¡¨è¾¾èƒ½åŠ›å·²ç»å—åˆ°äº†å¾ˆå¤§çš„å½±å“ï¼Œæ£€æµ‹å‡ºæ¥åŠ¨è„‰ç˜¤å¯¹æˆ‘ä»¬å®¶ç€å®æ˜¯ä¸ªå·¨å¤§çš„æ‰“å‡»ã€‚å½“æ—¶åŒ»ç”Ÿä¹Ÿçœ‹ä¸æ¸…ï¼Œä¸˜è„‘å‡ºè¡€åŠå¹´ä»¥åï¼Œä¹Ÿå°±æ˜¯8æœˆåˆåˆ°ä¸­æ—¬çš„æ—¶å€™ï¼Œæ­£å¥½æˆ‘è¿˜åœ¨ä¸Šæµ·å®ä¹ ï¼Œçˆ¸å¦ˆå°±æ¥ä¸Šæµ·çš„åå±±åŒ»é™¢ï¼Œæ‰¾åˆ°äº†tylä¸»ä»»ï¼Œä¹Ÿæ‰¾äº†å¾ˆå¤šå…³ç³»æ‰“äº†æ‹›å‘¼ï¼Œä½é™¢æ£€æŸ¥ï¼Œå‡†å¤‡è¯´å¦‚æœèƒ½åšæ‰‹æœ¯ï¼Œè¿˜æ˜¯å‡†å¤‡å…ˆæŠŠè¿™ä¸ªåŠ¨è„‰ç˜¤ç»™è§£å†³æ‰ã€‚ä½†æ˜¯æ£€æŸ¥ç»“æœä»¤äººæ³„æ°”ï¼ŒåŒ»ç”ŸæŠŠæˆ‘å’Œå¦ˆå¦ˆæ‹‰åˆ°ä¸€ä¸ªå•ç‹¬çš„ä¼šè°ˆå®¤ï¼Œå‘¨å›´å…¨æ˜¯ç›‘æ§ï¼Œè·Ÿæˆ‘ä»¬è®²äº†ä¸€ä¸‹çˆ¸çˆ¸çš„æƒ…å†µï¼ŒåŸºæœ¬ä¸Šå·²ç»åˆ°äº†åšä¸äº†æ‰‹æœ¯çš„æ—¶å€™ï¼Œå½“æ—¶å‘ç°çš„æ—¶å€™å°±å·²ç»éå¸¸å¤§ï¼Œåˆ°ç°åœ¨è¿™ä¸ªç˜¤è¿›ä¸€æ­¥æ‰©å¤§ï¼ŒåŒ»ç”Ÿè¯´åªæœ‰ä¸€åŠçš„æŠŠæ¡èƒ½å¤Ÿåˆ‡é™¤ï¼Œå¦å¤–ä¸€åŠäººå°±æ²¡äº†ï¼Œè€Œä¸”å³ä¾¿æ‰‹æœ¯æˆåŠŸï¼ŒçŸ­æœŸå¹¶æ²¡æœ‰å¯¹ç—…äººæ˜æ˜¾å¸®åŠ©ï¼Œæˆ‘ä»¬è€ƒè™‘äº†å¾ˆä¹…ï¼Œæœ€ç»ˆè¿˜æ˜¯å†³å®šæ¥å—ä¿å®ˆæ²»ç–—ï¼Œå›åˆ°äº†åˆè‚¥ã€‚ä¹‹åæˆ‘å¦ˆå°±æƒ³æ‰¾ä¸ªè½»æ¾ä¸€ç‚¹çš„å·¥ä½œï¼Œåœ¨å®¶çœ‹ç€ç…§é¡¾ä¸€ä¸‹æˆ‘çˆ¸ï¼Œæˆ‘å°å§¨å°±è®©ä»–ä»¬ä¿©å›æ¡åŸï¼Œç®¡ä¸€ä¸‹ä»“åº“çš„è®°è´¦å·¥ä½œï¼Œæ¯å¤©ä¹Ÿå°±å‡ ä¸ªå°æ—¶ã€‚10æœˆåˆå›å®¶çš„æ—¶å€™è¿˜æ˜¯æŒºå¥½çš„ï¼Œæˆ‘çˆ¸å¤©å¤©è¿˜è¦å»ä¸Šç­ï¼Œè¯´ä»–èº«ä½“å¥½å¾—å¾ˆï¼ˆæˆ‘ä¸çŸ¥é“ä»–æ˜¯ç›²ç›®è‡ªä¿¡è¿˜æ˜¯ç›²ç›®ä¹è§‚äº†ï¼Œä¸€èˆ¬äººæ„Ÿè§‰ä¸æŠ‘éƒå·²ç»å¾ˆéš¾äº†ï¼Œä»–è·Ÿæ²¡äº‹äººä¸€æ ·ï¼‰ã€‚</p>
<p>ä½†æ˜¯ä»–çš„ç›²ç›®ä¹è§‚æ„Ÿè§‰æ˜¯ä»–ç¬¬äºŒæ¬¡å‘ç—…çš„é‡è¦åŸå› ä¹‹ä¸€ï¼Œä»–æ¯å¤©è¿˜è¦å‡ºå»æ•£å¥½å‡ ä¸ªå°æ—¶çš„æ­¥ï¼Œä»…ä»…ä¸€ä¸ªå¤šæœˆä»¥åï¼Œä»–å°±ç¬¬äºŒæ¬¡å‡ºç°äº†é—®é¢˜ï¼Œå¦‚åŒ»ç”Ÿæ‰€è¯´ï¼ŒåŠ¨è„‰ç˜¤å¹¶ä¸æ˜¯ä»–æœ€å¤§çš„é£é™©ï¼Œè„‘è¡€æ “æ‰æ˜¯ï¼Œè€Œä»–è¡€æ “çš„åœ°æ–¹ï¼Œæ›´æ˜¯äººä½“æœ€é‡è¦çš„åœ°æ–¹â€”â€”è„‘å¹²ã€‚11æœˆå°¾ï¼Œä»–å‡ºå»æ•£æ­¥ï¼Œå›æ¥å°±è¯´è„‘å­ä¸å¯¹åŠ²ï¼Œä»…ä»…ä¸€ä¸ªå¤šå°æ—¶ä»¥åï¼Œäººå°±å·²ç»ç«™ä¸èµ·æ¥è¯´ä¸äº†è¯äº†ï¼Œæˆ‘å¦ˆæ‰“ç”µè¯ç»™æˆ‘è¯´ä»–å‘ç—…äº†ï¼Œæˆ‘ç»™ä»–å«äº†æ»´æ»´ï¼Œå¸æœºåœ¨é—¨å£ç£¨è¹­åŠå¤©è¿˜æ˜¯æ‹’æ¥äº†ï¼Œè¿˜æ˜¯æˆ‘å°å§¨å¤«ä»å®¶é‡Œèµ¶è¿‡æ¥æŠŠä»–èƒŒä¸Šäº†è½¦ï¼Œè·¯ä¸Šäº¤ç»™äº†120ã€‚ä½†æ˜¯åˆ°åŒ»é™¢ï¼ŒåŒ»ç”Ÿè¯´æ²»ä¸äº†ï¼Œè½¬é™¢å»åˆè‚¥å§ï¼Œåˆæ€¥æ€¥å¿™å¿™å¾€åˆè‚¥é€ï¼Œè·¯ä¸Šæ€¥æ€§èƒƒæºƒç–¡å·²ç»åœ¨åè¡€äº†ï¼Œå‡ ä¸ªäº²æˆšèµ¶åˆ°çœç«‹åŒ»é™¢å—é™¢ï¼Œç›´æ¥é€è¿›äº†ICUï¼Œæˆ‘ä¹Ÿåœ¨å½“å¤©åŠå¤œåè½¦å›äº†å®¶ã€‚ICUä¸å…è®¸å®¶å±æ¢è§†ï¼Œæ¯å¤©å°±å»é‚£ä¸ªå°é—¨å£ï¼Œç­‰ç­‰åŒ»ç”Ÿå«ä½ ä¸€ä¸‹ï¼Œäº†è§£ä¸€ä¸‹ç—…æƒ…ï¼Œè¿™æ—¶å€™åŒ»ç”Ÿå·²ç»è¯´äº†ï¼Œç‰‡å­æ˜¾ç¤ºè„‘å¹²å°è„‘åŸºæœ¬ä¸Šå…¨éƒ¨å µæ­»ï¼Œå¦‚æœç†¬è¿‡è¿™å‡ å¤©ï¼Œå‡ºå»ä¹Ÿæ˜¯è·Ÿæ¤ç‰©äººä¸€æ ·ï¼Œèƒ½ä¸èƒ½é†’çœ‹é€ åŒ–ã€‚é¡ºåˆ©ç†¬è¿‡äº†ICUçš„å‡ å¤©ï¼Œè®©æ‹‰å‡ºå»å»å…¶ä»–åŒ»é™¢åšåº·å¤æ²»ç–—ï¼Œå‡ºæ¥çš„æ—¶å€™å‡ ä¸ªäººéƒ½å“­æˆäº†æ³ªäººã€‚ä½†æ˜¯ç”Ÿæ´»è¿˜å¾—ç»§ç»­ï¼Œåˆ°ç°åœ¨è¿˜åœ¨å‡ ä¸ªåŒ»é™¢æ¥å›è½¬ï¼Œæˆ‘å¦ˆè·Ÿç€åé¢ç…§é¡¾ç€ï¼Œè¯·ä¸€ä¸ªæŠ¤å·¥éƒ½ä¸å¤Ÿï¼Œä½•å†µè¿˜è¯·ä¸åˆ°è´Ÿè´£çš„åˆé€‚çš„æŠ¤å·¥ã€‚è¿‡å¹´è¿™å‡ å¤©æˆ‘å›å®¶ï¼Œåƒä½éƒ½æ˜¯åœ¨åŒ»é™¢çš„ï¼Œä»–ç°åœ¨è¿˜æ˜¯æ²¡æœ‰ä»€ä¹ˆå¥½è½¬ï¼Œä½†æ˜¯åœ¨åŒ»é™¢è¿™ä¹ˆä¹…ï¼Œæˆ‘å¦ˆä¹Ÿç´¯æ­»äº†ï¼Œå¶å°”æˆ‘å§æ›¿å¥¹ä¸€ä¸‹ï¼Œä½†æ˜¯è¯´å®è¯åŒ»é™¢é‡Œé¢åƒä½éƒ½ä¸æ–¹ä¾¿ï¼Œæ¯å¤©ä»æ—©åˆ°æ™šä¸èƒ½åœï¼Œèº«å¿ƒçš„æŸä¼¤çœŸçš„éå¸¸å¤§ï¼Œæˆ‘ä»¬å€’æ˜¯æƒ³ç­‰ä»–å¥½ä¸€ç‚¹ï¼Œæ¥å›å®¶å»æ…¢æ…¢ç–—å…»ï¼Œä¹Ÿè®©å‡ ä¸ªäººä¼‘æ¯ä¸€ä¸‹ã€‚</p>
<p>æœªå®Œå¾…ç»­â€¦</p>
]]></content>
      <categories>
        <category>éšæƒ³</category>
      </categories>
      <tags>
        <tag>Thoughts</tag>
      </tags>
  </entry>
</search>
